{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc7ddeaa-387a-4e9d-8160-f3014472bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: data_loader.py\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Callable, Union, Optional\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError, ParserError\n",
    "\n",
    "# ── internals ──────────────────────────────────────────────────────────\n",
    "def _hash(parts: Iterable[str | int | float]) -> str:\n",
    "    key = \"_\".join(str(p) for p in parts if p is not None)\n",
    "    return hashlib.md5(key.encode()).hexdigest()[:8]\n",
    "\n",
    "def _safe_load(path: Path) -> Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        return pd.read_parquet(path)\n",
    "    except (EmptyDataError, ParserError, OSError, ValueError):\n",
    "        path.unlink(missing_ok=True)          # drop corrupt file\n",
    "        return None\n",
    "\n",
    "# ── public API ────────────────────────────────────────────────────────\n",
    "def cache_read(\n",
    "    *,\n",
    "    key: Iterable[str | int | float],\n",
    "    loader: Callable[[], Union[pd.Series, pd.DataFrame]],\n",
    "    cache_dir: Union[str, Path] = \"cache\",\n",
    "    prefix: Optional[str] = None,\n",
    ") -> Union[pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns cached object if present, else computes via `loader()` and caches.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    series = cache_read(\n",
    "        key     = [\"SPY\", \"2020-01\", \"2024-06\"],\n",
    "        loader  = lambda: expensive_fetch(...),\n",
    "        cache_dir = \"cache_prices\",\n",
    "        prefix  = \"SPY\",\n",
    "    )\n",
    "    \"\"\"\n",
    "    cache_dir = Path(cache_dir).expanduser().resolve()\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fname = f\"{prefix or key[0]}_{_hash(key)}.parquet\"\n",
    "    path  = cache_dir / fname\n",
    "\n",
    "    if path.is_file():\n",
    "        df = _safe_load(path)\n",
    "        if df is not None:\n",
    "            return df.iloc[:, 0] if df.shape[1] == 1 else df\n",
    "\n",
    "    obj = loader()                                    # cache miss → compute\n",
    "    df  = obj.to_frame(name=obj.name or \"value\") if isinstance(obj, pd.Series) else obj\n",
    "    df.to_parquet(path, engine=\"pyarrow\", compression=\"zstd\", index=True)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def cache_write(\n",
    "    obj: Union[pd.Series, pd.DataFrame],\n",
    "    *,\n",
    "    key: Iterable[str | int | float],\n",
    "    cache_dir: Union[str, Path] = \"cache\",\n",
    "    prefix: Optional[str] = None,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Force-write `obj` under a key.  Returns the Path written.\n",
    "    \"\"\"\n",
    "    cache_dir = Path(cache_dir).expanduser().resolve()\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fname = f\"{prefix or key[0]}_{_hash(key)}.parquet\"\n",
    "    path  = cache_dir / fname\n",
    "    df    = obj.to_frame(name=obj.name or \"value\") if isinstance(obj, pd.Series) else obj\n",
    "    df.to_parquet(path, engine=\"pyarrow\", compression=\"zstd\", index=True)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c57b2a-d703-41f9-b5d6-8ba8c744f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: data_loader.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from typing import Optional, Union, List, Dict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file before accessing environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "FMP_API_KEY = os.getenv(\"FMP_API_KEY\")\n",
    "API_KEY  = FMP_API_KEY\n",
    "BASE_URL = \"https://financialmodelingprep.com/stable\"\n",
    "\n",
    "\n",
    "def fetch_monthly_close(\n",
    "    ticker: str,\n",
    "    start_date: Optional[Union[str, datetime]] = None,\n",
    "    end_date:   Optional[Union[str, datetime]] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fetch month-end closing prices for a given ticker from FMP.\n",
    "\n",
    "    Uses the `/stable/historical-price-eod/full` endpoint with optional\n",
    "    `from` and `to` parameters, then resamples to month-end.\n",
    "\n",
    "    Args:\n",
    "        ticker (str):       Stock or ETF symbol.\n",
    "        start_date (str|datetime, optional): Earliest date (inclusive).\n",
    "        end_date   (str|datetime, optional): Latest date (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Month-end close prices indexed by date.\n",
    "    \"\"\"\n",
    "    # ----- loader (runs only on cache miss) ------------------------------\n",
    "    def _api_pull() -> pd.Series:\n",
    "        params = {\"symbol\": ticker, \"apikey\": API_KEY, \"serietype\": \"line\"}\n",
    "        if start_date:\n",
    "            params[\"from\"] = pd.to_datetime(start_date).date().isoformat()\n",
    "        if end_date:\n",
    "            params[\"to\"]   = pd.to_datetime(end_date).date().isoformat()\n",
    "    \n",
    "        resp = requests.get(f\"{BASE_URL}/historical-price-eod/full\", params=params, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        raw  = resp.json()\n",
    "        data = raw if isinstance(raw, list) else raw.get(\"historical\", [])\n",
    "    \n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df.set_index(\"date\", inplace=True)\n",
    "        monthly = df.sort_index().resample(\"ME\")[\"close\"].last()\n",
    "        return monthly\n",
    "\n",
    "    # ----- call cache layer ---------------------------------------------\n",
    "    return cache_read(\n",
    "        key=[ticker, start_date or \"none\", end_date or \"none\"],\n",
    "        loader=_api_pull,\n",
    "        cache_dir=\"cache_prices\",\n",
    "        prefix=ticker,\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  RAM-cache wrapper  (add this at the very bottom of data_loader.py)\n",
    "# ----------------------------------------------------------------------\n",
    "from functools import lru_cache\n",
    "import pandas as pd                                 # already imported above\n",
    "\n",
    "# 1) private handle to the disk-cached version\n",
    "_fetch_monthly_close_disk = fetch_monthly_close     \n",
    "\n",
    "# 2) re-export the public name with an LRU layer\n",
    "@lru_cache(maxsize=256)          # tune size to taste\n",
    "def fetch_monthly_close(         # ← same name seen by callers\n",
    "    ticker: str,\n",
    "    start_date: str | None = None,\n",
    "    end_date:   str | None = None,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    RAM-cached → disk-cached → network price fetch.\n",
    "    Same signature and behaviour as the original function.\n",
    "    \"\"\"\n",
    "    return _fetch_monthly_close_disk(ticker, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dcbf60-9eed-45ef-910d-f61154b0a245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
