{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4702d644-d0f2-4992-a70d-94a1e8912885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: data_loader.py\n",
    "\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Callable, Union, Optional\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError, ParserError\n",
    "\n",
    "# ── internals ──────────────────────────────────────────────────────────\n",
    "def _hash(parts: Iterable[str | int | float]) -> str:\n",
    "    key = \"_\".join(str(p) for p in parts if p is not None)\n",
    "    return hashlib.md5(key.encode()).hexdigest()[:8]\n",
    "\n",
    "def _safe_load(path: Path) -> Optional[pd.DataFrame]:\n",
    "    try:\n",
    "        return pd.read_parquet(path)\n",
    "    except (EmptyDataError, ParserError, OSError, ValueError):\n",
    "        path.unlink(missing_ok=True)          # drop corrupt file\n",
    "        return None\n",
    "\n",
    "# ── public API ────────────────────────────────────────────────────────\n",
    "def cache_read(\n",
    "    *,\n",
    "    key: Iterable[str | int | float],\n",
    "    loader: Callable[[], Union[pd.Series, pd.DataFrame]],\n",
    "    cache_dir: Union[str, Path] = \"cache\",\n",
    "    prefix: Optional[str] = None,\n",
    ") -> Union[pd.Series, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns cached object if present, else computes via `loader()` and caches.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    series = cache_read(\n",
    "        key     = [\"SPY\", \"2020-01\", \"2024-06\"],\n",
    "        loader  = lambda: expensive_fetch(...),\n",
    "        cache_dir = \"cache_prices\",\n",
    "        prefix  = \"SPY\",\n",
    "    )\n",
    "    \"\"\"\n",
    "    cache_dir = Path(cache_dir).expanduser().resolve()\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fname = f\"{prefix or key[0]}_{_hash(key)}.parquet\"\n",
    "    path  = cache_dir / fname\n",
    "\n",
    "    if path.is_file():\n",
    "        df = _safe_load(path)\n",
    "        if df is not None:\n",
    "            return df.iloc[:, 0] if df.shape[1] == 1 else df\n",
    "\n",
    "    obj = loader()                                    # cache miss → compute\n",
    "    df  = obj.to_frame(name=obj.name or \"value\") if isinstance(obj, pd.Series) else obj\n",
    "    df.to_parquet(path, engine=\"pyarrow\", compression=\"zstd\", index=True)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def cache_write(\n",
    "    obj: Union[pd.Series, pd.DataFrame],\n",
    "    *,\n",
    "    key: Iterable[str | int | float],\n",
    "    cache_dir: Union[str, Path] = \"cache\",\n",
    "    prefix: Optional[str] = None,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Force-write `obj` under a key.  Returns the Path written.\n",
    "    \"\"\"\n",
    "    cache_dir = Path(cache_dir).expanduser().resolve()\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    fname = f\"{prefix or key[0]}_{_hash(key)}.parquet\"\n",
    "    path  = cache_dir / fname\n",
    "    df    = obj.to_frame(name=obj.name or \"value\") if isinstance(obj, pd.Series) else obj\n",
    "    df.to_parquet(path, engine=\"pyarrow\", compression=\"zstd\", index=True)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a9b57e6-df07-4b88-9e5a-cd6ce975400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: data_loader.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from typing import Optional, Union, List, Dict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file before accessing environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "FMP_API_KEY = os.getenv(\"FMP_API_KEY\")\n",
    "API_KEY  = FMP_API_KEY\n",
    "BASE_URL = \"https://financialmodelingprep.com/stable\"\n",
    "\n",
    "\n",
    "def fetch_monthly_close(\n",
    "    ticker: str,\n",
    "    start_date: Optional[Union[str, datetime]] = None,\n",
    "    end_date:   Optional[Union[str, datetime]] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fetch month-end closing prices for a given ticker from FMP.\n",
    "\n",
    "    Uses the `/stable/historical-price-eod/full` endpoint with optional\n",
    "    `from` and `to` parameters, then resamples to month-end.\n",
    "\n",
    "    Args:\n",
    "        ticker (str):       Stock or ETF symbol.\n",
    "        start_date (str|datetime, optional): Earliest date (inclusive).\n",
    "        end_date   (str|datetime, optional): Latest date (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Month-end close prices indexed by date.\n",
    "    \"\"\"\n",
    "    # ----- loader (runs only on cache miss) ------------------------------\n",
    "    def _api_pull() -> pd.Series:\n",
    "        params = {\"symbol\": ticker, \"apikey\": API_KEY, \"serietype\": \"line\"}\n",
    "        if start_date:\n",
    "            params[\"from\"] = pd.to_datetime(start_date).date().isoformat()\n",
    "        if end_date:\n",
    "            params[\"to\"]   = pd.to_datetime(end_date).date().isoformat()\n",
    "    \n",
    "        resp = requests.get(f\"{BASE_URL}/historical-price-eod/full\", params=params, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        raw  = resp.json()\n",
    "        data = raw if isinstance(raw, list) else raw.get(\"historical\", [])\n",
    "    \n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df.set_index(\"date\", inplace=True)\n",
    "        monthly = df.sort_index().resample(\"ME\")[\"close\"].last()\n",
    "        return monthly\n",
    "\n",
    "    # ----- call cache layer ---------------------------------------------\n",
    "    return cache_read(\n",
    "        key=[ticker, start_date or \"none\", end_date or \"none\"],\n",
    "        loader=_api_pull,\n",
    "        cache_dir=\"cache_prices\",\n",
    "        prefix=ticker,\n",
    "    )\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  RAM-cache wrapper  (add this at the very bottom of data_loader.py)\n",
    "# ----------------------------------------------------------------------\n",
    "from functools import lru_cache\n",
    "import pandas as pd                                 # already imported above\n",
    "\n",
    "# 1) private handle to the disk-cached version\n",
    "_fetch_monthly_close_disk = fetch_monthly_close     \n",
    "\n",
    "# 2) re-export the public name with an LRU layer\n",
    "@lru_cache(maxsize=256)          # tune size to taste\n",
    "def fetch_monthly_close(         # ← same name seen by callers\n",
    "    ticker: str,\n",
    "    start_date: str | None = None,\n",
    "    end_date:   str | None = None,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    RAM-cached → disk-cached → network price fetch.\n",
    "    Same signature and behaviour as the original function.\n",
    "    \"\"\"\n",
    "    return _fetch_monthly_close_disk(ticker, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13fda40-f6c9-4143-969d-f506e729bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  File: factor_utils.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from typing import Optional, Union, List, Dict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file before accessing environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "FMP_API_KEY = os.getenv(\"FMP_API_KEY\")\n",
    "API_KEY  = FMP_API_KEY\n",
    "BASE_URL = \"https://financialmodelingprep.com/stable\"\n",
    "\n",
    "\n",
    "def calc_monthly_returns(prices: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute percent-change monthly returns from price series.\n",
    "\n",
    "    Args:\n",
    "        prices (pd.Series): Month-end price series.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Monthly % change returns, NaNs dropped.\n",
    "    \"\"\"\n",
    "    return prices.pct_change().dropna()\n",
    "\n",
    "\n",
    "def compute_volatility(returns: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate monthly and annualized volatility from a returns series.\n",
    "\n",
    "    Args:\n",
    "        returns (pd.Series): Series of periodic returns.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"monthly_vol\": float,  # standard deviation of returns\n",
    "            \"annual_vol\":  float   # scaled by sqrt(12)\n",
    "        }\n",
    "    \"\"\"\n",
    "    vol_m = float(returns.std())\n",
    "    vol_a = vol_m * np.sqrt(12)\n",
    "    return {\"monthly_vol\": vol_m, \"annual_vol\": vol_a}\n",
    "\n",
    "\n",
    "def compute_regression_metrics(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Run OLS regression of stock returns vs. market returns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns [\"stock\", \"market\"].\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"beta\":      float,  # slope coefficient\n",
    "            \"alpha\":     float,  # intercept\n",
    "            \"r_squared\": float,  # model R²\n",
    "            \"idio_vol\":  float   # std deviation of residuals\n",
    "        }\n",
    "    \"\"\"\n",
    "    X     = sm.add_constant(df[\"market\"])\n",
    "    model = sm.OLS(df[\"stock\"], X).fit()\n",
    "    return {\n",
    "        \"beta\":      float(model.params[\"market\"]),\n",
    "        \"alpha\":     float(model.params[\"const\"]),\n",
    "        \"r_squared\": float(model.rsquared),\n",
    "        \"idio_vol_m\":  float(model.resid.std())\n",
    "    }\n",
    "\n",
    "\n",
    "def fetch_peer_median_monthly_returns(\n",
    "    tickers: List[str],\n",
    "    start_date: Optional[Union[str, datetime]] = None,\n",
    "    end_date:   Optional[Union[str, datetime]] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute the cross-sectional median of peer tickers' monthly returns.\n",
    "\n",
    "    Args:\n",
    "        tickers (List[str]): List of peer ticker symbols.\n",
    "        start_date (str|datetime, optional): Earliest date for fetch.\n",
    "        end_date   (str|datetime, optional): Latest date for fetch.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Median of monthly returns across peers.\n",
    "    \"\"\"\n",
    "    series_list = []\n",
    "    for t in tickers:\n",
    "        prices = fetch_monthly_close(t, start_date=start_date, end_date=end_date)\n",
    "        rets   = calc_monthly_returns(prices).rename(t)\n",
    "        series_list.append(rets)\n",
    "    df_peers = pd.concat(series_list, axis=1).dropna()\n",
    "    return df_peers.median(axis=1)\n",
    "\n",
    "\n",
    "def fetch_excess_return(\n",
    "    etf_ticker: str,\n",
    "    market_ticker: str = \"SPY\",\n",
    "    start_date: Optional[Union[str, datetime]] = None,\n",
    "    end_date: Optional[Union[str, datetime]] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute style-factor excess returns: ETF minus market, aligned by index.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Excess monthly returns (etf - market), aligned on date.\n",
    "    \"\"\"\n",
    "    etf_ret    = calc_monthly_returns(fetch_monthly_close(etf_ticker,    start_date, end_date))\n",
    "    market_ret = calc_monthly_returns(fetch_monthly_close(market_ticker, start_date, end_date))\n",
    "\n",
    "    # Force strict index alignment before subtraction\n",
    "    common_idx = etf_ret.index.intersection(market_ret.index)\n",
    "    etf_aligned    = etf_ret.loc[common_idx]\n",
    "    market_aligned = market_ret.loc[common_idx]\n",
    "\n",
    "    return etf_aligned - market_aligned\n",
    "\n",
    "def compute_factor_metrics(\n",
    "    stock_returns: pd.Series,\n",
    "    factor_dict: Dict[str, pd.Series]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs independent single-factor regressions of stock returns vs. each factor.\n",
    "\n",
    "    For each factor, calculates:\n",
    "      • beta (cov(stock, factor) / var(factor))\n",
    "      • R² (correlation squared)\n",
    "      • idiosyncratic volatility (monthly residual std deviation)\n",
    "\n",
    "    Args:\n",
    "        stock_returns (pd.Series): Monthly stock returns (datetime index).\n",
    "        factor_dict (Dict[str, pd.Series]): Dict of factor name to factor return series.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: One row per factor, columns: beta, r_squared, idio_vol_m\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for name, factor_series in factor_dict.items():\n",
    "        # Force exact alignment\n",
    "        common_idx = stock_returns.index.intersection(factor_series.index)\n",
    "        stock = stock_returns.loc[common_idx]\n",
    "        factor = factor_series.loc[common_idx]\n",
    "\n",
    "        if len(stock) < 2:\n",
    "            continue  # Skip if not enough data\n",
    "\n",
    "        # Calculate regression statistics\n",
    "        cov = stock.cov(factor)\n",
    "        var = factor.var()\n",
    "        beta = cov / var\n",
    "        alpha = stock.mean() - beta * factor.mean()\n",
    "        resid = stock - (alpha + beta * factor)\n",
    "        idio_vol_m = resid.std(ddof=1)\n",
    "        r_squared = stock.corr(factor) ** 2\n",
    "\n",
    "        results[name] = {\n",
    "            \"beta\":        float(beta),\n",
    "            \"r_squared\":   float(r_squared),\n",
    "            \"idio_vol_m\":  float(idio_vol_m)\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(results).T  # One row per factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a82a2a-b0b3-472c-b4f9-057259e8bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: risk_summary.py\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Dict, Union\n",
    "import pandas as pd\n",
    "\n",
    "def get_stock_risk_profile(\n",
    "    ticker: str,\n",
    "    start_date: Union[str, pd.Timestamp],\n",
    "    end_date: Union[str, pd.Timestamp],\n",
    "    benchmark: str = \"SPY\"\n",
    ") -> Dict[str, Union[float, Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Pulls monthly prices between given dates, computes returns, vol, and regression metrics.\n",
    "    Returns a dict:\n",
    "      {\n",
    "        \"vol_metrics\": {...},\n",
    "        \"risk_metrics\": {...}\n",
    "      }\n",
    "\n",
    "    Args:\n",
    "        ticker (str): Stock symbol.\n",
    "        start_date (str or pd.Timestamp): Start of analysis window.\n",
    "        end_date (str or pd.Timestamp): End of analysis window.\n",
    "        benchmark (str): Benchmark ticker for regression (default: \"SPY\").\n",
    "    \"\"\"\n",
    "    stock_prices  = fetch_monthly_close(ticker,    start_date=start_date, end_date=end_date)\n",
    "    market_prices = fetch_monthly_close(benchmark, start_date=start_date, end_date=end_date)\n",
    "\n",
    "    stock_ret  = calc_monthly_returns(stock_prices)\n",
    "    market_ret = calc_monthly_returns(market_prices)\n",
    "\n",
    "    df_ret = pd.DataFrame({\n",
    "        \"stock\":  stock_ret,\n",
    "        \"market\": market_ret\n",
    "    }).dropna()\n",
    "\n",
    "    vol_metrics  = compute_volatility(df_ret[\"stock\"])\n",
    "    risk_metrics = compute_regression_metrics(df_ret)\n",
    "\n",
    "    return {\n",
    "        \"vol_metrics\":  vol_metrics,\n",
    "        \"risk_metrics\": risk_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5550da34-fd66-480d-a7a8-42638634440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Volatility Metrics ===\n",
      "{'monthly_vol': 0.11725436729017498, 'annual_vol': np.float64(0.4061810431118506)}\n",
      "\n",
      "=== Regression Risk Metrics ===\n",
      "{'beta': 0.8641396333136843, 'alpha': 0.006838230799813837, 'r_squared': 0.1560675241898123, 'idio_vol_m': 0.10771665966441839}\n"
     ]
    }
   ],
   "source": [
    "# File: run_single_stock_profile.py\n",
    "\n",
    "#from risk_summary import get_stock_risk_profile  # only if it's in a separate .py file\n",
    "start = \"2019-04-30\"\n",
    "end   = \"2024-03-31\"\n",
    "\n",
    "# Example: Get 5-year risk profile for PCTY vs SPY\n",
    "result = get_stock_risk_profile(\"PCTY\", start_date=start, end_date=end, benchmark=\"SPY\")\n",
    "\n",
    "print(\"=== Volatility Metrics ===\")\n",
    "print(result[\"vol_metrics\"])\n",
    "\n",
    "print(\"\\n=== Regression Risk Metrics ===\")\n",
    "print(result[\"risk_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8941d264-9626-4cac-8f80-3b9ea1e4753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: risk_summary.py\n",
    "\n",
    "from typing import List, Dict, Optional, Union\n",
    "import pandas as pd\n",
    "\n",
    "def get_detailed_stock_factor_profile(\n",
    "    ticker: str,\n",
    "    start_date: Union[str, pd.Timestamp],\n",
    "    end_date: Union[str, pd.Timestamp],\n",
    "    factor_proxies: Dict[str, Union[str, List[str]]],\n",
    "    market_ticker: str = \"SPY\"\n",
    ") -> Dict[str, Union[pd.DataFrame, Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Computes full factor risk diagnostics for a stock over a given window,\n",
    "    using specified ETF proxies and peer sets.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): Stock ticker to analyze.\n",
    "        start_date (str or Timestamp): Start date for analysis window.\n",
    "        end_date (str or Timestamp): End date for analysis window.\n",
    "        factor_proxies (dict): Mapping of factor name → ETF or peer list.\n",
    "            Required keys: market, momentum, value, industry, subindustry\n",
    "        market_ticker (str): Market benchmark ticker (for excess returns).\n",
    "\n",
    "    Returns:\n",
    "        dict:\n",
    "            - vol_metrics: volatility stats\n",
    "            - regression_metrics: beta, alpha, R², idio vol (market only)\n",
    "            - factor_summary: DataFrame of beta / R² / idio vol per factor\n",
    "    \"\"\"\n",
    "    stock_prices  = fetch_monthly_close(ticker, start_date=start_date, end_date=end_date)\n",
    "    stock_returns = calc_monthly_returns(stock_prices)\n",
    "\n",
    "    def align(series: pd.Series) -> pd.Series:\n",
    "        return series.loc[stock_returns.index.intersection(series.index)]\n",
    "\n",
    "    # Fetch and align all factor return series\n",
    "    market_ret   = align(calc_monthly_returns(fetch_monthly_close(factor_proxies[\"market\"], start_date, end_date)))\n",
    "    momentum_ret = align(fetch_excess_return(factor_proxies[\"momentum\"], market_ticker, start_date, end_date))\n",
    "    value_ret    = align(fetch_excess_return(factor_proxies[\"value\"], market_ticker, start_date, end_date))\n",
    "\n",
    "    industry_ret = align(fetch_peer_median_monthly_returns(\n",
    "        factor_proxies[\"industry\"] if isinstance(factor_proxies[\"industry\"], list)\n",
    "        else [factor_proxies[\"industry\"]],\n",
    "        start_date, end_date\n",
    "    ))\n",
    "\n",
    "    subind_ret = align(fetch_peer_median_monthly_returns(\n",
    "        factor_proxies[\"subindustry\"] if isinstance(factor_proxies[\"subindustry\"], list)\n",
    "        else [factor_proxies[\"subindustry\"]],\n",
    "        start_date, end_date\n",
    "    ))\n",
    "\n",
    "    # Build combined factor dictionary\n",
    "    factor_dict = {\n",
    "        \"market\":      market_ret,\n",
    "        \"momentum\":    momentum_ret,\n",
    "        \"value\":       value_ret,\n",
    "        \"industry\":    industry_ret,\n",
    "        \"subindustry\": subind_ret\n",
    "    }\n",
    "\n",
    "    # Regression vs market only\n",
    "    df_reg = pd.DataFrame({\"stock\": stock_returns, \"market\": market_ret}).dropna()\n",
    "\n",
    "    return {\n",
    "        \"vol_metrics\": compute_volatility(df_reg[\"stock\"]),\n",
    "        \"regression_metrics\": compute_regression_metrics(df_reg),\n",
    "        \"factor_summary\": compute_factor_metrics(stock_returns, factor_dict)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3465fe70-e0f6-4a9f-a9ec-42f0168e213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Volatility ===\n",
      "{'monthly_vol': 0.11725436729017498, 'annual_vol': np.float64(0.4061810431118506)}\n",
      "\n",
      "=== Market Regression ===\n",
      "{'beta': 0.8641396333136843, 'alpha': 0.006838230799813837, 'r_squared': 0.1560675241898123, 'idio_vol_m': 0.10771665966441839}\n",
      "\n",
      "=== Factor Summary ===\n",
      "                 beta  r_squared  idio_vol_m\n",
      "market       0.864140   0.156068    0.107717\n",
      "momentum     0.647737   0.020661    0.116037\n",
      "value       -0.385407   0.003763    0.117034\n",
      "industry     0.882610   0.287141    0.098999\n",
      "subindustry  1.052589   0.512489    0.077785\n"
     ]
    }
   ],
   "source": [
    "# File: run_single_stock_profile.py\n",
    "\n",
    "#from risk_summary import get_detailed_stock_factor_profile  # only if it's in a separate .py file\n",
    "\n",
    "start = \"2019-04-30\"\n",
    "end   = \"2024-03-31\"\n",
    "\n",
    "profile = get_detailed_stock_factor_profile(\n",
    "    ticker=\"PCTY\",\n",
    "    start_date=start,\n",
    "    end_date=end,\n",
    "    factor_proxies={\n",
    "        \"market\": \"SPY\",\n",
    "        \"momentum\": \"MTUM\",\n",
    "        \"value\": \"IWD\",\n",
    "        \"industry\": \"XSW\",\n",
    "        \"subindustry\": [\"PAYC\", \"PYCR\", \"CDAY\", \"ADP\", \"PAYX\", \"WDAY\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"=== Volatility ===\")\n",
    "print(profile[\"vol_metrics\"])\n",
    "\n",
    "print(\"\\n=== Market Regression ===\")\n",
    "print(profile[\"regression_metrics\"])\n",
    "\n",
    "print(\"\\n=== Factor Summary ===\")\n",
    "print(profile[\"factor_summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b9ed565-a7f9-4c0d-a047-59a69e3f2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: portfolio_risk.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "def normalize_weights(weights: Dict[str, float], normalize: bool = True) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Ensure weights sum to 1. If normalize is False, returns as-is.\n",
    "    \"\"\"\n",
    "    if not normalize:\n",
    "        return weights\n",
    "    total = sum(weights.values())\n",
    "    if total == 0:\n",
    "        raise ValueError(\"Sum of weights is zero, cannot normalize.\")\n",
    "    return {t: w / total for t, w in weights.items()}\n",
    "\n",
    "def compute_portfolio_returns(\n",
    "    returns: pd.DataFrame,\n",
    "    weights: Dict[str, float]\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Given a DataFrame of individual asset returns (columns = tickers)\n",
    "    and a dict of weights, compute the weighted portfolio return series.\n",
    "    \"\"\"\n",
    "    w = normalize_weights(weights)\n",
    "    # align columns and weights\n",
    "    aligned = returns[list(w.keys())].dropna()\n",
    "    weight_vec = np.array([w[t] for t in aligned.columns])\n",
    "    # dot product row-wise\n",
    "    port_ret = aligned.values.dot(weight_vec)\n",
    "    return pd.Series(port_ret, index=aligned.index, name=\"portfolio\")\n",
    "\n",
    "def compute_covariance_matrix(\n",
    "    returns: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the sample covariance matrix of asset returns.\n",
    "    \"\"\"\n",
    "    return returns.cov()\n",
    "\n",
    "def compute_correlation_matrix(\n",
    "    returns: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the sample correlation matrix of asset returns.\n",
    "\n",
    "    Args:\n",
    "        returns (pd.DataFrame): DataFrame where each column is an asset's return series.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Correlation matrix between assets.\n",
    "    \"\"\"\n",
    "    return returns.corr()\n",
    "\n",
    "def compute_portfolio_volatility(\n",
    "    weights: Dict[str, float],\n",
    "    cov_matrix: pd.DataFrame\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute portfolio volatility = sqrt(w^T Σ w).\n",
    "    \"\"\"\n",
    "    w = normalize_weights(weights)\n",
    "    w_vec = np.array([w[t] for t in cov_matrix.index])\n",
    "    var_p = float(w_vec.T.dot(cov_matrix.values).dot(w_vec))\n",
    "    return np.sqrt(var_p)\n",
    "\n",
    "def compute_risk_contributions(\n",
    "    weights: Dict[str, float],\n",
    "    cov_matrix: pd.DataFrame\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute each asset’s risk contribution to total portfolio volatility.\n",
    "    RC_i = w_i * (Σ w)_i / σ_p\n",
    "    Returns a Series indexed by ticker.\n",
    "    \"\"\"\n",
    "    w = normalize_weights(weights)\n",
    "    w_vec = np.array([w[t] for t in cov_matrix.index])\n",
    "    sigma_p = compute_portfolio_volatility(weights, cov_matrix)\n",
    "    # marginal contributions = (Σ w)_i\n",
    "    marg = cov_matrix.values.dot(w_vec)\n",
    "    rc = w_vec * marg / sigma_p\n",
    "    return pd.Series(rc, index=cov_matrix.index, name=\"risk_contrib\")\n",
    "\n",
    "def compute_herfindahl(\n",
    "    weights: Dict[str, float]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the Herfindahl index = sum(w_i^2).\n",
    "    Indicates portfolio concentration (0 = fully diversified, 1 = single asset).\n",
    "    \"\"\"\n",
    "    w = normalize_weights(weights)\n",
    "    return float(sum([w_i ** 2 for w_i in w.values()]))\n",
    "\n",
    "# Example usage snippet (to paste in your notebook):\n",
    "#\n",
    "# import pandas as pd\n",
    "# from portfolio_risk import (\n",
    "#     compute_portfolio_returns,\n",
    "#     compute_covariance_matrix,\n",
    "#     compute_portfolio_volatility,\n",
    "#     compute_risk_contributions,\n",
    "#     compute_herfindahl\n",
    "# )\n",
    "#\n",
    "# # assume df_ret is a DataFrame of monthly returns for your universe\n",
    "# weights = {\"PCTY\": 0.4, \"AAPL\": 0.6}\n",
    "#\n",
    "# # 1) Portfolio returns\n",
    "# port_ret = compute_portfolio_returns(df_ret, weights)\n",
    "#\n",
    "# # 2) Covariance\n",
    "# cov = compute_covariance_matrix(df_ret)\n",
    "#\n",
    "# # 3) Portfolio volatility\n",
    "# vol = compute_portfolio_volatility(weights, cov)\n",
    "# print(\"Portfolio Volatility:\", vol)\n",
    "#\n",
    "# # 4) Risk contributions\n",
    "# rc = compute_risk_contributions(weights, cov)\n",
    "# print(\"Risk Contributions:\\n\", rc)\n",
    "#\n",
    "# # 5) Concentration (Herfindahl)\n",
    "# h = compute_herfindahl(weights)\n",
    "# print(\"Herfindahl Index:\", h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f668e3d-1c63-4c63-b10f-6ebdd1e9fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: factor_utils.py\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def compute_stock_factor_betas(\n",
    "    stock_ret: pd.Series,\n",
    "    factor_rets: Dict[str, pd.Series]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Wrapper that re-uses compute_factor_metrics to get betas for a single stock.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    stock_ret : pd.Series\n",
    "        The stock’s return series, indexed by date.\n",
    "    factor_rets : Dict[str, pd.Series]\n",
    "        Mapping {factor_name: factor_return_series}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        {factor_name: beta} pulled straight from compute_factor_metrics.\n",
    "    \"\"\"\n",
    "    # call the existing helper (must already be imported / defined in scope)\n",
    "    df_metrics = compute_factor_metrics(stock_ret, factor_rets)\n",
    "\n",
    "    # return only the β column as a plain dict\n",
    "    return df_metrics[\"beta\"].to_dict()\n",
    "\n",
    "def calc_factor_vols(\n",
    "    factor_dict: Dict[str, pd.Series],\n",
    "    annualize: bool = True\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Return annualised σ for every factor series supplied.\n",
    "\n",
    "    factor_dict  – {\"market\": Series, \"momentum\": Series, ...}\n",
    "    \"\"\"\n",
    "    k = 12 ** 0.5 if annualize else 1.0\n",
    "    return {name: float(series.std(ddof=1) * k) for name, series in factor_dict.items()}\n",
    "\n",
    "\n",
    "def calc_weighted_factor_variance(\n",
    "    weights: Dict[str, float],\n",
    "    betas_df: pd.DataFrame,\n",
    "    factor_vols: Dict[str, float]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Weighted factor variance for each (asset, factor):\n",
    "\n",
    "       w_i² · β_i,f² · σ_f²\n",
    "\n",
    "    weights      – {\"PCTY\": 0.15, ...}\n",
    "    betas_df     – DataFrame index=tickers, columns=factors, values=β\n",
    "    factor_vols  – {\"market\": 0.18, ...}  (annual σ, *not* %)\n",
    "\n",
    "    Returns DataFrame same shape as betas_df.\n",
    "    \"\"\"\n",
    "    w2 = pd.Series(weights).pow(2)\n",
    "    sigma2 = {f: v ** 2 for f, v in factor_vols.items()}\n",
    "    var_df = betas_df.pow(2) * pd.DataFrame(sigma2, index=[\"__tmp__\"]).T   # β² σ²\n",
    "    return var_df.mul(w2, axis=0)   # multiply each row by w_i²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5bccfa-342e-4bce-8c1d-c6eb3dc8438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: portfolio_risk.py\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "def compute_portfolio_variance_breakdown(\n",
    "    weights: Dict[str, float],\n",
    "    idio_var_dict: Dict[str, float],\n",
    "    weighted_factor_var: pd.DataFrame,\n",
    "    vol_m: float\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns a structured variance decomposition:\n",
    "      - total variance\n",
    "      - idiosyncratic variance + %\n",
    "      - factor variance + %\n",
    "      - per-factor variance + %\n",
    "    \"\"\"\n",
    "    w = pd.Series(weights)\n",
    "    w2 = w.pow(2)\n",
    "\n",
    "    # Idiosyncratic variance (sum of w_i² * σ²_idio_i)\n",
    "    idio_var_series = pd.Series(idio_var_dict).reindex(w.index).fillna(0.0)\n",
    "    idio_var = float((w2 * idio_var_series).sum())\n",
    "\n",
    "    # Factor variance (sum of weighted factor variance matrix)\n",
    "    factor_var_matrix = (\n",
    "        weighted_factor_var\n",
    "        .drop(columns=[\"industry\", \"subindustry\"], errors=\"ignore\")  # REMOVE\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "    \n",
    "    per_factor_var = factor_var_matrix.sum(axis=0)\n",
    "    factor_var = float(per_factor_var.sum())\n",
    "\n",
    "    # Total portfolio variance\n",
    "    port_var = factor_var + idio_var\n",
    "\n",
    "    # % shares\n",
    "    idio_pct   = idio_var   / port_var if port_var else 0.0\n",
    "    factor_pct = factor_var / port_var if port_var else 0.0\n",
    "\n",
    "    # Breakdown of factor variance by factor\n",
    "    per_factor_var = factor_var_matrix.sum(axis=0)\n",
    "    per_factor_pct = per_factor_var / port_var\n",
    "\n",
    "    return {\n",
    "        \"portfolio_variance\":      port_var,\n",
    "        \"idiosyncratic_variance\":  idio_var,\n",
    "        \"idiosyncratic_pct\":       idio_pct,\n",
    "        \"factor_variance\":         factor_var,\n",
    "        \"factor_pct\":              factor_pct,\n",
    "        \"factor_breakdown_var\":    per_factor_var.to_dict(),\n",
    "        \"factor_breakdown_pct\":    per_factor_pct.to_dict()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3776a61-d7bd-4baa-a5d3-759426ac1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: portfolio_risk.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "\n",
    "def get_returns_dataframe(\n",
    "    weights: Dict[str, float],\n",
    "    start_date: str,\n",
    "    end_date: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch and compute monthly returns for all tickers in the weights dictionary.\n",
    "\n",
    "    Args:\n",
    "        weights (Dict[str, float]): Portfolio weights (tickers as keys).\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Monthly return series for all tickers, aligned and cleaned.\n",
    "    \"\"\"\n",
    "    rets = {}\n",
    "    for t in weights:\n",
    "        prices = fetch_monthly_close(t, start_date=start_date, end_date=end_date)\n",
    "        rets[t] = calc_monthly_returns(prices)\n",
    "    return pd.DataFrame(rets).dropna()\n",
    "\n",
    "def compute_target_allocations(\n",
    "    weights: Dict[str, float],\n",
    "    expected_returns: Optional[Dict[str, float]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute target allocations based on expected returns and equal weight comparison.\n",
    "\n",
    "    Args:\n",
    "        weights (Dict[str, float]): Current portfolio weights.\n",
    "        expected_returns (Optional[Dict[str, float]]): Expected returns for tickers.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Allocation table with portfolio weight, equal weight, and proportional return targets.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        \"Portfolio Weight\": pd.Series(weights),\n",
    "        \"Equal Weight\":     pd.Series({t: 1/len(weights) for t in weights})\n",
    "    })\n",
    "    if expected_returns:\n",
    "        total = sum(expected_returns.values())\n",
    "        df[\"Prop Target\"] = pd.Series({t: expected_returns[t]/total for t in expected_returns})\n",
    "        df[\"Prop Diff\"]   = df[\"Portfolio Weight\"] - df[\"Prop Target\"]\n",
    "    df[\"Eq Diff\"] = df[\"Portfolio Weight\"] - df[\"Equal Weight\"]\n",
    "    return df\n",
    "    \n",
    "def build_portfolio_view(\n",
    "    weights: Dict[str, float],\n",
    "    start_date: str,\n",
    "    end_date:   str,\n",
    "    expected_returns: Optional[Dict[str, float]] = None,\n",
    "    stock_factor_proxies: Optional[Dict[str, Dict[str, Union[str, List[str]]]]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Builds a complete portfolio risk profile using historical returns, factor regressions,\n",
    "    and variance decomposition.\n",
    "\n",
    "    Performs:\n",
    "    - Aggregates returns, volatility, and correlation for the portfolio.\n",
    "    - Runs per-stock single-factor regressions to compute betas (market, momentum, value, industry, subindustry).\n",
    "    - Calculates idiosyncratic volatilities and annualized variances.\n",
    "    - Computes per-stock factor volatilities (σ_i,f) and weighted factor variance (w² · β² · σ²).\n",
    "    - Decomposes portfolio variance into idiosyncratic vs factor-driven.\n",
    "    - Aggregates per-industry ETF variance contributions (based on industry proxies).\n",
    "    - Computes portfolio-level factor betas and Herfindahl concentration.\n",
    "    - Summarizes per-industry group betas from weighted contributions of individual stock betas.\n",
    "\n",
    "    Args:\n",
    "        weights (Dict[str, float]):\n",
    "            Portfolio weights by ticker (not required to sum to 1).\n",
    "        start_date (str):\n",
    "            Historical window start date (format: YYYY-MM-DD).\n",
    "        end_date (str):\n",
    "            Historical window end date (format: YYYY-MM-DD).\n",
    "        expected_returns (Optional[Dict[str, float]]):\n",
    "            Optional target returns per ticker for allocation gap display.\n",
    "        stock_factor_proxies (Optional[Dict]):\n",
    "            Mapping of each stock to its factor proxies:\n",
    "                - \"market\": ETF ticker (e.g., SPY)\n",
    "                - \"momentum\": ETF ticker (e.g., MTUM)\n",
    "                - \"value\": ETF ticker (e.g., IWD)\n",
    "                - \"industry\": ETF ticker (e.g., SOXX)\n",
    "                - \"subindustry\": list of tickers (e.g., [\"PAYC\", \"CDAY\"])\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Portfolio diagnostics including:\n",
    "            - 'allocations': target vs actual vs expected returns\n",
    "            - 'portfolio_returns': aggregated monthly returns\n",
    "            - 'covariance_matrix': asset return covariances\n",
    "            - 'correlation_matrix': asset return correlations\n",
    "            - 'volatility_monthly': annualized volatility from monthly returns\n",
    "            - 'volatility_annual': total annual portfolio volatility\n",
    "            - 'risk_contributions': risk contribution by asset\n",
    "            - 'herfindahl': portfolio concentration score\n",
    "            - 'df_stock_betas': per-stock factor betas from regressions\n",
    "            - 'portfolio_factor_betas': weighted sum of factor exposures\n",
    "            - 'factor_vols': per-stock annualized factor volatilities\n",
    "            - 'weighted_factor_var': w² · β² · σ² contributions\n",
    "            - 'asset_vol_summary': asset-level volatility and idio stats\n",
    "            - 'variance_decomposition': total vs idio vs factor variance\n",
    "            - 'industry_variance': {\n",
    "                'absolute': variance by industry proxy,\n",
    "                'percent_of_portfolio': % variance per industry,\n",
    "                'per_industry_group_beta': weighted betas per industry ETF\n",
    "              }\n",
    "    \"\"\"\n",
    "    # ─── 0. Portfolio Return Setup ──────────────────────────────────────────────\n",
    "    df_ret   = get_returns_dataframe(weights, start_date, end_date)\n",
    "    df_alloc = compute_target_allocations(weights, expected_returns)\n",
    "\n",
    "    port_ret = compute_portfolio_returns(df_ret, weights)\n",
    "    cov_mat  = compute_covariance_matrix(df_ret)\n",
    "    corr_mat = compute_correlation_matrix(df_ret)\n",
    "\n",
    "    vol_m = compute_portfolio_volatility(weights, cov_mat)\n",
    "    vol_a = vol_m * np.sqrt(12)\n",
    "    rc    = compute_risk_contributions(weights, cov_mat)\n",
    "    hhi   = compute_herfindahl(weights)\n",
    "\n",
    "    w_series                = pd.Series(weights)\n",
    "\n",
    "    # ─── 1. Stock-Level Factor Exposures ────────────────────────────────────────\n",
    "    df_stock_betas = pd.DataFrame(index=weights.keys())\n",
    "    idio_var_dict  = {}\n",
    "\n",
    "    if stock_factor_proxies:\n",
    "        for ticker, proxies in stock_factor_proxies.items():\n",
    "            # Fetch stock returns\n",
    "            prices    = fetch_monthly_close(ticker, start_date=start_date, end_date=end_date)\n",
    "            stock_ret = calc_monthly_returns(prices)\n",
    "            idx       = stock_ret.index\n",
    "\n",
    "            # Build aligned factor series\n",
    "            fac_dict: Dict[str, pd.Series] = {}\n",
    "\n",
    "            mkt_t = proxies.get(\"market\")\n",
    "            if mkt_t:\n",
    "                mkt_ret = calc_monthly_returns(\n",
    "                    fetch_monthly_close(mkt_t, start_date=start_date, end_date=end_date)\n",
    "                ).reindex(idx).dropna()\n",
    "                fac_dict[\"market\"] = mkt_ret\n",
    "\n",
    "            mom_t = proxies.get(\"momentum\")\n",
    "            if mom_t and mkt_t:\n",
    "                mom_ret = fetch_excess_return(mom_t, mkt_t, start_date, end_date).reindex(idx).dropna()\n",
    "                fac_dict[\"momentum\"] = mom_ret\n",
    "\n",
    "            val_t = proxies.get(\"value\")\n",
    "            if val_t and mkt_t:\n",
    "                val_ret = fetch_excess_return(val_t, mkt_t, start_date, end_date).reindex(idx).dropna()\n",
    "                fac_dict[\"value\"] = val_ret\n",
    "\n",
    "            for facname in (\"industry\", \"subindustry\"):\n",
    "                proxy = proxies.get(facname)\n",
    "                if proxy:\n",
    "                    if isinstance(proxy, list):\n",
    "                        ser = fetch_peer_median_monthly_returns(proxy, start_date, end_date)\n",
    "                    else:\n",
    "                        ser = calc_monthly_returns(\n",
    "                            fetch_monthly_close(proxy, start_date=start_date, end_date=end_date)\n",
    "                        )\n",
    "                    fac_dict[facname] = ser.reindex(idx).dropna()\n",
    "\n",
    "            # drop rows with any NaN\n",
    "            factor_df  = pd.DataFrame(fac_dict).dropna(how=\"any\")\n",
    "            if factor_df.empty:\n",
    "                continue # Skip if no usable data\n",
    "        \n",
    "            aligned_s = stock_ret.reindex(factor_df.index)\n",
    "                    \n",
    "            # Run single-factor regression to get betas\n",
    "            betas = compute_stock_factor_betas(\n",
    "                aligned_s,                               # stock on same dates\n",
    "                {c: factor_df[c] for c in factor_df}     # factors on same dates\n",
    "            )\n",
    "            df_stock_betas.loc[ticker, betas.keys()] = pd.Series(betas)\n",
    "\n",
    "            # Idiosyncratic variance (monthly → annual)\n",
    "            X      = sm.add_constant(factor_df)\n",
    "            resid  = aligned_s - sm.OLS(aligned_s, X).fit().fittedvalues\n",
    "        \n",
    "            # Convert monthly residual variance to annual variance\n",
    "            monthly_idio_var = resid.var(ddof=1)\n",
    "            annual_idio_var = monthly_idio_var * 12\n",
    "            idio_var_dict[ticker] = float(annual_idio_var)\n",
    "\n",
    "    # ─── 2. Compute Factor Volatility & Weighted Variance ───────────────────────\n",
    "    df_factor_vols   = pd.DataFrame(index=df_stock_betas.index,\n",
    "                                    columns=df_stock_betas.columns)   # σ_i,f (annual)\n",
    "    weighted_factor_var = pd.DataFrame(index=df_stock_betas.index,\n",
    "                                       columns=df_stock_betas.columns) # w_i² β² σ²\n",
    "    \n",
    "    if stock_factor_proxies:                                           # ← guard\n",
    "        w2 = pd.Series(weights).pow(2)                                 # w_i²\n",
    "    \n",
    "        for tkr, proxies in stock_factor_proxies.items():\n",
    "    \n",
    "            # ----- rebuild this stock’s factor-return dict (same logic as above) --\n",
    "            idx_stock = calc_monthly_returns(\n",
    "                fetch_monthly_close(tkr, start_date, end_date)\n",
    "            ).index\n",
    "            fac_ret: Dict[str, pd.Series] = {}\n",
    "    \n",
    "            mkt = proxies.get(\"market\")\n",
    "            if mkt:\n",
    "                fac_ret[\"market\"] = calc_monthly_returns(\n",
    "                    fetch_monthly_close(mkt, start_date, end_date)\n",
    "                ).reindex(idx_stock).dropna()\n",
    "    \n",
    "            def _excess(etf: str) -> pd.Series:\n",
    "                return fetch_excess_return(etf, mkt, start_date, end_date\n",
    "                       ).reindex(idx_stock).dropna()\n",
    "    \n",
    "            if proxies.get(\"momentum\"):\n",
    "                fac_ret[\"momentum\"] = _excess(proxies[\"momentum\"])\n",
    "            if proxies.get(\"value\"):\n",
    "                fac_ret[\"value\"]    = _excess(proxies[\"value\"])\n",
    "    \n",
    "            for fac in (\"industry\", \"subindustry\"):\n",
    "                proxy = proxies.get(fac)\n",
    "                if proxy:\n",
    "                    ser = ( fetch_peer_median_monthly_returns(proxy, start_date, end_date)\n",
    "                            if isinstance(proxy, list)\n",
    "                            else calc_monthly_returns(\n",
    "                                    fetch_monthly_close(proxy, start_date, end_date) ) )\n",
    "                    fac_ret[fac] = ser.reindex(idx_stock).dropna()\n",
    "    \n",
    "            if not fac_ret:         # nothing to measure\n",
    "                continue\n",
    "    \n",
    "            # ----- annual σ_i,f ----------------------------------------------------\n",
    "            sigmas = pd.Series({f: r.std(ddof=1) * np.sqrt(12) for f, r in fac_ret.items()})\n",
    "            df_factor_vols.loc[tkr, sigmas.index] = sigmas\n",
    "    \n",
    "            # df_factor_vols  : σ-table (annual factor vols by stock)\n",
    "            df_factor_vols = (\n",
    "                df_factor_vols\n",
    "                    .apply(pd.to_numeric, errors=\"coerce\")  # force numeric, NaNs where bad\n",
    "                    .astype(\"float64\", copy=False)          # ensure float dtype, no copy if already\n",
    "                    .fillna(0.0)                           # now safe – no warning\n",
    "            )\n",
    "            \n",
    "            # betas_filled   : β-table with NaNs → 0.0\n",
    "            betas_filled = (\n",
    "                df_stock_betas\n",
    "                    .apply(pd.to_numeric, errors=\"coerce\")\n",
    "                    .astype(\"float64\", copy=False)\n",
    "                    .fillna(0.0)\n",
    "            )\n",
    "    \n",
    "        # ----- weighted factor variance  w_i² β_i,f² σ_i,f² -----------------------\n",
    "        weighted_factor_var = betas_filled.pow(2) * df_factor_vols.pow(2)\n",
    "        weighted_factor_var = weighted_factor_var.mul(w2, axis=0)\n",
    "\n",
    "\n",
    "    # ─── 3a. Aggregate Industry-Level Variance ───────────────────────────────────\n",
    "    industry_var_dict = {}\n",
    "    \n",
    "    # Step: reverse-map which stock maps to which industry ETF\n",
    "    for tkr, proxies in stock_factor_proxies.items():\n",
    "        ind = proxies.get(\"industry\")\n",
    "        if ind:\n",
    "            v = weighted_factor_var.loc[tkr, \"industry\"] if \"industry\" in weighted_factor_var.columns else 0.0\n",
    "            industry_var_dict[ind] = industry_var_dict.get(ind, 0.0) + v\n",
    "\n",
    "    # ─── 3b. Compute Per-Industry Group Beta (and max weighted exposure) ──────────────\n",
    "    industry_groups: Dict[str, float] = {}\n",
    "\n",
    "    for ticker in w_series.index:\n",
    "        proxy = stock_factor_proxies.get(ticker, {}).get(\"industry\")\n",
    "        beta = df_stock_betas.get(\"industry\", {}).get(ticker, 0.0)\n",
    "        weight = w_series[ticker]\n",
    "        if proxy:\n",
    "            industry_groups[proxy] = industry_groups.get(proxy, 0.0) + (weight * beta)\n",
    "    \n",
    "    # ─── 4. Final Portfolio Stats (Volatility, Idio, Betas) ─────────────────────\n",
    "    portfolio_factor_betas  = df_stock_betas.mul(w_series, axis=0).sum(skipna=True)\n",
    "\n",
    "    # 4a) per-asset annualised stats ----------------------------------------\n",
    "    asset_vol_a = df_ret.std(ddof=1) * np.sqrt(12)               # total σ_annual\n",
    "    asset_var_m = df_ret.var(ddof=1)                             # monthly σ²\n",
    "    w_series    = pd.Series(weights)\n",
    "    \n",
    "    # idiosyncratic\n",
    "    idio_var_a  = pd.Series(idio_var_dict).reindex(w_series.index)         # already annual\n",
    "    idio_vol_a  = idio_var_a.pow(0.5)                                       # √(annual var)\n",
    "    weighted_idio_var_model = w_series.pow(2) * idio_var_a  # w² · σ²_idio\n",
    "\n",
    "    # Manually compute (w × σ_idio)² for comparison\n",
    "    weighted_idio_vol = idio_vol_a * w_series\n",
    "    weighted_idio_var_manual = (weighted_idio_vol) ** 2\n",
    "    \n",
    "    df_asset = pd.DataFrame({\n",
    "        \"Vol A\":              asset_vol_a,                       # total annual σ\n",
    "        \"Weighted Vol A\":     asset_vol_a * w_series,\n",
    "        #\"Var M\":              asset_var_m,                       # monthly total σ² (for reference)\n",
    "        #\"Weighted Var M\":     asset_var_m * (w_series ** 2),\n",
    "        \"Idio Vol A\":         idio_vol_a,                        # idio annual σ\n",
    "        \"Weighted Idio Vol A\": weighted_idio_vol,\n",
    "        \"Weighted Idio Var\": weighted_idio_var_model,\n",
    "        #\"Manual Weighted Idio Var\": weighted_idio_var_manual\n",
    "        #\"Weighted IdioVar A\": idio_var_a * (w_series ** 2),\n",
    "    })\n",
    "\n",
    "    # ─── 5. Industry Variance % Contribution ────────────────────────────────────\n",
    "    total_port_var = (\n",
    "        compute_portfolio_variance_breakdown(\n",
    "            weights, idio_var_dict, weighted_factor_var, vol_m\n",
    "        )[\"portfolio_variance\"]\n",
    "    )\n",
    "    \n",
    "    industry_pct_dict = {\n",
    "        k: v / total_port_var if total_port_var else 0.0\n",
    "        for k, v in industry_var_dict.items()\n",
    "    }\n",
    "\n",
    "    # ─── 6. Assemble Final Output ───────────────────────────────────────────────\n",
    "    return {\n",
    "        \"allocations\":            df_alloc,\n",
    "        \"covariance_matrix\":      cov_mat,\n",
    "        \"correlation_matrix\":     corr_mat,\n",
    "        \"volatility_monthly\":     vol_m,\n",
    "        \"volatility_annual\":      vol_a,\n",
    "        \"risk_contributions\":     rc,\n",
    "        \"herfindahl\":             hhi,\n",
    "        \"df_stock_betas\":         df_stock_betas,\n",
    "        \"portfolio_factor_betas\": portfolio_factor_betas,\n",
    "        \"factor_vols\":            df_factor_vols,         \n",
    "        \"weighted_factor_var\":    weighted_factor_var, \n",
    "        \"asset_vol_summary\":      df_asset,\n",
    "        \"portfolio_returns\":      port_ret,\n",
    "        \"variance_decomposition\": compute_portfolio_variance_breakdown(\n",
    "        weights, idio_var_dict, weighted_factor_var, vol_m),\n",
    "        \"industry_variance\": {\n",
    "        \"absolute\": industry_var_dict,\n",
    "        \"percent_of_portfolio\": industry_pct_dict,\n",
    "        \"per_industry_group_beta\": industry_groups,\n",
    "    }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080f8590-fdb6-4d94-9707-e96a84656177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "from typing import Dict, Callable, Union\n",
    "\n",
    "def standardize_portfolio_input(\n",
    "    raw_input: Dict[str, Dict[str, Union[float, int]]],\n",
    "    price_fetcher: Callable[[str], float]\n",
    ") -> Dict[str, Union[Dict[str, float], float]]:\n",
    "    \"\"\"\n",
    "    Normalize portfolio input into weights using shares, dollar value, or direct weight.\n",
    "\n",
    "    Args:\n",
    "        raw_input (dict): Dict of ticker → {\"shares\": int}, {\"dollars\": float}, or {\"weight\": float}\n",
    "        price_fetcher (callable): Function to fetch latest price for a given ticker\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"weights\": Dict[ticker, normalized weight],\n",
    "            \"dollar_exposure\": Dict[ticker, dollar amount],\n",
    "            \"total_value\": float,\n",
    "            \"net_exposure\": float,\n",
    "            \"gross_exposure\": float,\n",
    "            \"leverage\": float\n",
    "        }\n",
    "    \"\"\"\n",
    "    dollar_exposure = {}\n",
    "\n",
    "    for ticker, entry in raw_input.items():\n",
    "        if \"weight\" in entry:\n",
    "            # Will normalize weights separately\n",
    "            continue\n",
    "        elif \"dollars\" in entry:\n",
    "            dollar_exposure[ticker] = float(entry[\"dollars\"])\n",
    "        elif \"shares\" in entry:\n",
    "            price = price_fetcher(ticker)\n",
    "            dollar_exposure[ticker] = float(entry[\"shares\"]) * price\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid input for {ticker}: must provide 'shares', 'dollars', or 'weight'.\")\n",
    "\n",
    "    # If any weights were specified, override dollar_exposure logic\n",
    "    if all(\"weight\" in entry for entry in raw_input.values()):\n",
    "        weights = {t: float(v[\"weight\"]) for t, v in raw_input.items()}\n",
    "        normalized_weights = normalize_weights(weights)\n",
    "\n",
    "        net_exposure = sum(weights.values())\n",
    "        gross_exposure = sum(abs(w) for w in weights.values())\n",
    "        leverage = gross_exposure / net_exposure if net_exposure != 0 else np.inf\n",
    "        \n",
    "        return {\n",
    "            \"weights\": normalized_weights,\n",
    "            \"dollar_exposure\": None,\n",
    "            \"total_value\": None,\n",
    "            \"net_exposure\": net_exposure,\n",
    "            \"gross_exposure\": gross_exposure,\n",
    "            \"leverage\": leverage\n",
    "        }\n",
    "\n",
    "    total_value = sum(dollar_exposure.values())\n",
    "    weights = {t: v / total_value for t, v in dollar_exposure.items()}\n",
    "\n",
    "    net_exposure = sum(weights.values())\n",
    "    gross_exposure = sum(abs(w) for w in weights.values())\n",
    "    leverage = gross_exposure / net_exposure if net_exposure else np.inf\n",
    "\n",
    "    return {\n",
    "        \"weights\": weights,\n",
    "        \"dollar_exposure\": dollar_exposure,\n",
    "        \"total_value\": total_value,\n",
    "        \"net_exposure\": net_exposure,\n",
    "        \"gross_exposure\": gross_exposure,\n",
    "        \"leverage\": leverage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8272f5d7-9623-4902-8811-787c904e1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "def latest_price(ticker: str) -> float:\n",
    "    \"\"\"\n",
    "    Fetches the latest available month-end closing price for a given ticker.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): Ticker symbol of the stock or ETF.\n",
    "\n",
    "    Returns:\n",
    "        float: Most recent non-NaN month-end closing price.\n",
    "    \"\"\"\n",
    "    prices = fetch_monthly_close(ticker)\n",
    "    return prices.dropna().iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ba4593-3590-4590-a8d3-f5a626475779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── run_portfolio_risk.py ────────────────────────────────────────────\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "from typing import Dict, Callable, Optional, Any\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 1) Pure-data loader  → returns a dict you can reuse programmatically\n",
    "# --------------------------------------------------------------------\n",
    "def load_portfolio_config(\n",
    "    filepath: str = \"portfolio.yaml\",\n",
    "    price_fetcher: Callable[[str], float] | None = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load the YAML and return a dict with parsed + normalised fields.\n",
    "    No printing, no side effects.\n",
    "    \"\"\"\n",
    "    from run_portfolio_risk import standardize_portfolio_input, latest_price  # local imports\n",
    "\n",
    "    price_fetcher = price_fetcher or latest_price\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        cfg_raw = yaml.safe_load(f)\n",
    "\n",
    "    # • Keep the original keys for downstream code\n",
    "    cfg: Dict[str, Any] = dict(cfg_raw)          # shallow copy\n",
    "    parsed = standardize_portfolio_input(cfg[\"portfolio_input\"], price_fetcher)\n",
    "\n",
    "    cfg.update(\n",
    "        weights           = parsed[\"weights\"],\n",
    "        dollar_exposure   = parsed[\"dollar_exposure\"],\n",
    "        total_value       = parsed[\"total_value\"],\n",
    "        net_exposure      = parsed[\"net_exposure\"],\n",
    "        gross_exposure    = parsed[\"gross_exposure\"],\n",
    "        leverage          = parsed[\"leverage\"],\n",
    "    )\n",
    "    return cfg\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2) Pretty-printer  → consumes the dict returned by loader\n",
    "# --------------------------------------------------------------------\n",
    "def display_portfolio_config(cfg: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Nicely print the fields produced by load_portfolio_config().\n",
    "    \"\"\"\n",
    "    print(\"=== Normalized Weights ===\")\n",
    "    print(cfg[\"weights\"])\n",
    "\n",
    "    print(\"\\n=== Dollar Exposure ===\")\n",
    "    print(cfg[\"dollar_exposure\"])\n",
    "\n",
    "    print(\"\\n=== Total Portfolio Value ===\")\n",
    "    print(cfg[\"total_value\"])\n",
    "\n",
    "    print(\"\\n=== Net Exposure (sum of weights) ===\")\n",
    "    print(cfg[\"net_exposure\"])\n",
    "\n",
    "    print(\"\\n=== Gross Exposure (sum of abs(weights)) ===\")\n",
    "    print(cfg[\"gross_exposure\"])\n",
    "\n",
    "    print(\"\\n=== Leverage (gross / net) ===\")\n",
    "    print(cfg[\"leverage\"])\n",
    "\n",
    "    print(\"\\n=== Expected Returns ===\")\n",
    "    pprint(cfg[\"expected_returns\"])\n",
    "\n",
    "    print(\"\\n=== Stock Factor Proxies ===\")\n",
    "    for ticker, proxies in cfg[\"stock_factor_proxies\"].items():\n",
    "        print(f\"\\n→ {ticker}\")\n",
    "        pprint(proxies)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 3) Convenience shim for legacy calls  (optional but zero-cost)\n",
    "# --------------------------------------------------------------------\n",
    "def load_and_display_portfolio_config(\n",
    "    filepath: str = \"portfolio.yaml\",\n",
    "    price_fetcher: Callable[[str], float] | None = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Drop-in replacement for the old monolithic helper.\n",
    "    Returns the same dict loader now provides.\n",
    "    \"\"\"\n",
    "    cfg = load_portfolio_config(filepath, price_fetcher)\n",
    "    display_portfolio_config(cfg)\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1ae4c3d-ea11-48e5-9895-b95210d54f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Normalized Weights ===\n",
      "{'TW': 0.15, 'MSCI': 0.15, 'NVDA': 0.17, 'PCTY': 0.15, 'AT.L': 0.28, 'SHV': 0.1}\n",
      "\n",
      "=== Dollar Exposure ===\n",
      "None\n",
      "\n",
      "=== Total Portfolio Value ===\n",
      "None\n",
      "\n",
      "=== Net Exposure (sum of weights) ===\n",
      "1.0\n",
      "\n",
      "=== Gross Exposure (sum of abs(weights)) ===\n",
      "1.0\n",
      "\n",
      "=== Leverage (gross / net) ===\n",
      "1.0\n",
      "\n",
      "=== Expected Returns ===\n",
      "{'AT.L': 0.25, 'MSCI': 0.16, 'NVDA': 0.2, 'PCTY': 0.17, 'TW': 0.15}\n",
      "\n",
      "=== Stock Factor Proxies ===\n",
      "\n",
      "→ TW\n",
      "{'industry': 'KCE',\n",
      " 'market': 'SPY',\n",
      " 'momentum': 'MTUM',\n",
      " 'subindustry': ['TW', 'MSCI', 'NVDA'],\n",
      " 'value': 'IWD'}\n",
      "\n",
      "→ MSCI\n",
      "{'industry': 'KCE',\n",
      " 'market': 'SPY',\n",
      " 'momentum': 'MTUM',\n",
      " 'subindustry': ['TW', 'MSCI', 'NVDA'],\n",
      " 'value': 'IWD'}\n",
      "\n",
      "→ NVDA\n",
      "{'industry': 'SOXX',\n",
      " 'market': 'SPY',\n",
      " 'momentum': 'MTUM',\n",
      " 'subindustry': ['SOXX', 'XSW', 'IXC'],\n",
      " 'value': 'IWD'}\n",
      "\n",
      "→ PCTY\n",
      "{'industry': 'XSW',\n",
      " 'market': 'SPY',\n",
      " 'momentum': 'MTUM',\n",
      " 'subindustry': ['PAYC', 'CDAY', 'ADP'],\n",
      " 'value': 'IWD'}\n",
      "\n",
      "→ AT.L\n",
      "{'industry': 'IXC',\n",
      " 'market': 'ACWX',\n",
      " 'momentum': 'IMTM',\n",
      " 'subindustry': ['IXC'],\n",
      " 'value': 'IVLU'}\n",
      "\n",
      "→ SHV\n",
      "{'industry': 'AGG',\n",
      " 'market': 'SPY',\n",
      " 'momentum': 'IMTM',\n",
      " 'subindustry': ['SHY'],\n",
      " 'value': 'IWD'}\n"
     ]
    }
   ],
   "source": [
    "# --- Load config silently (no prints) ---------------------------------\n",
    "config = load_portfolio_config(\"portfolio.yaml\")   # <- new loader\n",
    "\n",
    "# Everything you need is already in that dict\n",
    "start_date            = config[\"start_date\"]\n",
    "end_date              = config[\"end_date\"]\n",
    "expected_returns      = config[\"expected_returns\"]\n",
    "stock_factor_proxies  = config[\"stock_factor_proxies\"]\n",
    "weights               = config[\"weights\"]         \n",
    "\n",
    "# If you still want the nice console dump, call:\n",
    "display_portfolio_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e923a72-c769-451c-bcbc-bb6d0863f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "def display_portfolio_summary(summary: dict):\n",
    "    print(\"\\n=== Target Allocations ===\")\n",
    "    print(summary[\"allocations\"], \"\\n\")\n",
    "\n",
    "    print(\"=== Portfolio Returns (head) ===\")\n",
    "    print(summary[\"portfolio_returns\"].head(), \"\\n\")\n",
    "\n",
    "    print(\"=== Covariance Matrix ===\")\n",
    "    print(summary[\"covariance_matrix\"], \"\\n\")\n",
    "\n",
    "    print(\"=== Correlation Matrix ===\")\n",
    "    print(summary[\"correlation_matrix\"], \"\\n\")\n",
    "\n",
    "    print(f\"Monthly Volatility:  {summary['volatility_monthly']:.4%}\")\n",
    "    print(f\"Annual Volatility:   {summary['volatility_annual']:.4%}\\n\")\n",
    "\n",
    "    print(\"=== Risk Contributions ===\")\n",
    "    print(summary[\"risk_contributions\"], \"\\n\")\n",
    "\n",
    "    print(\"Herfindahl Index:\", summary[\"herfindahl\"], \"\\n\")\n",
    "\n",
    "    print(\"=== Per-Stock Factor Betas ===\")\n",
    "    print(summary[\"df_stock_betas\"], \"\\n\")\n",
    "\n",
    "    print(\"=== Portfolio-Level Factor Betas ===\")\n",
    "    print(summary[\"portfolio_factor_betas\"], \"\\n\")\n",
    "\n",
    "    print(\"=== Per-Asset Vol & Var ===\")\n",
    "    print(summary[\"asset_vol_summary\"], \"\\n\")\n",
    "\n",
    "    print(\"=== Factor Annual Volatilities (σ_i,f) ===\")\n",
    "    print(summary[\"factor_vols\"].round(4))\n",
    "\n",
    "    print(\"\\n=== Weighted Factor Variance   w_i² · β_i,f² · σ_i,f² ===\")\n",
    "    print(summary[\"weighted_factor_var\"].round(6), \"\\n\")\n",
    "\n",
    "    print(\"=== Portfolio Variance Decomposition ===\")\n",
    "    var_dec = summary[\"variance_decomposition\"]\n",
    "    print(f\"Portfolio Variance:          {var_dec['portfolio_variance']:.4f}\")\n",
    "    print(f\"Idiosyncratic Variance:      {var_dec['idiosyncratic_variance']:.4f}  ({var_dec['idiosyncratic_pct']:.0%})\")\n",
    "    print(f\"Factor Variance:             {var_dec['factor_variance']:.4f}  ({var_dec['factor_pct']:.0%})\\n\")\n",
    "\n",
    "    print(\"=== Factor Variance (absolute) ===\")\n",
    "    for k, v in var_dec[\"factor_breakdown_var\"].items():\n",
    "        print(f\"{k.title():<10} : {v:.5f}\")\n",
    "\n",
    "    filtered = {\n",
    "        k: v for k, v in var_dec[\"factor_breakdown_pct\"].items()\n",
    "        if k not in (\"industry\", \"subindustry\")\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== Factor Variance (% of Portfolio, excluding industry) ===\")\n",
    "    for k, v in filtered.items():\n",
    "        print(f\"{k.title():<10} : {v:.0%}\")\n",
    "\n",
    "    print(\"\\n=== Industry Variance (absolute) ===\")\n",
    "    for k, v in summary[\"industry_variance\"][\"absolute\"].items():\n",
    "        print(f\"{k:<10} : {v:.6f}\")\n",
    "\n",
    "    print(\"\\n=== Industry Variance (% of Portfolio) ===\")\n",
    "    for k, v in summary[\"industry_variance\"][\"percent_of_portfolio\"].items():\n",
    "        print(f\"{k:<10} : {v:.1%}\")\n",
    "\n",
    "    print(\"\\n=== Per-Industry Group Betas ===\")\n",
    "    per_group = summary[\"industry_variance\"].get(\"per_industry_group_beta\", {})\n",
    "    for k, v in sorted(per_group.items(), key=lambda kv: -abs(kv[1])):\n",
    "        print(f\"{k:<12} : {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9a67b73-6114-4df2-b79b-2a7f57ad6fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Target Allocations ===\n",
      "      Portfolio Weight  Equal Weight  Prop Target  Prop Diff   Eq Diff\n",
      "TW                0.15      0.166667     0.161290  -0.011290 -0.016667\n",
      "MSCI              0.15      0.166667     0.172043  -0.022043 -0.016667\n",
      "NVDA              0.17      0.166667     0.215054  -0.045054  0.003333\n",
      "PCTY              0.15      0.166667     0.182796  -0.032796 -0.016667\n",
      "AT.L              0.28      0.166667     0.268817   0.011183  0.113333\n",
      "SHV               0.10      0.166667          NaN        NaN -0.066667 \n",
      "\n",
      "=== Portfolio Returns (head) ===\n",
      "date\n",
      "2021-12-31    0.007033\n",
      "2022-01-31   -0.031146\n",
      "2022-02-28    0.013326\n",
      "2022-03-31    0.058049\n",
      "2022-04-30   -0.142590\n",
      "Freq: ME, Name: portfolio, dtype: float64 \n",
      "\n",
      "=== Covariance Matrix ===\n",
      "            TW      MSCI      NVDA      PCTY      AT.L       SHV\n",
      "TW    0.009487  0.005101  0.009622  0.003393  0.001614  0.000069\n",
      "MSCI  0.005101  0.008367  0.010594  0.003489 -0.000835  0.000047\n",
      "NVDA  0.009622  0.010594  0.032086  0.002860  0.000731  0.000123\n",
      "PCTY  0.003393  0.003489  0.002860  0.008971 -0.001475  0.000005\n",
      "AT.L  0.001614 -0.000835  0.000731 -0.001475  0.008150  0.000004\n",
      "SHV   0.000069  0.000047  0.000123  0.000005  0.000004  0.000002 \n",
      "\n",
      "=== Correlation Matrix ===\n",
      "            TW      MSCI      NVDA      PCTY      AT.L       SHV\n",
      "TW    1.000000  0.572521  0.551525  0.367828  0.183544  0.471808\n",
      "MSCI  0.572521  1.000000  0.646585  0.402662 -0.101124  0.345502\n",
      "NVDA  0.551525  0.646585  1.000000  0.168570  0.045188  0.460032\n",
      "PCTY  0.367828  0.402662  0.168570  1.000000 -0.172494  0.036811\n",
      "AT.L  0.183544 -0.101124  0.045188 -0.172494  1.000000  0.032444\n",
      "SHV   0.471808  0.345502  0.460032  0.036811  0.032444  1.000000 \n",
      "\n",
      "Monthly Volatility:  6.2491%\n",
      "Annual Volatility:   21.6474%\n",
      "\n",
      "=== Risk Contributions ===\n",
      "TW      0.011502\n",
      "MSCI    0.009879\n",
      "NVDA    0.024845\n",
      "PCTY    0.005885\n",
      "AT.L    0.010315\n",
      "SHV     0.000065\n",
      "Name: risk_contrib, dtype: float64 \n",
      "\n",
      "Herfindahl Index: 0.18480000000000002 \n",
      "\n",
      "=== Per-Stock Factor Betas ===\n",
      "        market  momentum     value  industry  subindustry\n",
      "TW    1.010741 -0.342585 -0.816838  0.719686     0.822384\n",
      "MSCI  1.061350 -0.169660 -1.251375  0.815987     0.763515\n",
      "NVDA  1.655942 -0.447170 -4.109790  1.287548     1.221280\n",
      "PCTY  0.906362  0.655298 -0.401259  0.904666     1.018291\n",
      "AT.L  0.375585 -0.570200 -0.557632 -0.014189    -0.014189\n",
      "SHV  -0.000061  0.007484 -0.020666  0.016485     0.112018 \n",
      "\n",
      "=== Portfolio-Level Factor Betas ===\n",
      "market         0.833436\n",
      "momentum      -0.213468\n",
      "value         -1.227288\n",
      "industry       0.582609\n",
      "subindustry    0.605475\n",
      "dtype: float64 \n",
      "\n",
      "=== Per-Asset Vol & Var ===\n",
      "         Vol A  Weighted Vol A  Idio Vol A  Weighted Idio Vol A  \\\n",
      "TW    0.337402        0.050610    0.224569             0.033685   \n",
      "MSCI  0.316872        0.047531    0.168330             0.025250   \n",
      "NVDA  0.620505        0.105486    0.249209             0.042365   \n",
      "PCTY  0.328099        0.049215    0.221095             0.033164   \n",
      "AT.L  0.312728        0.087564    0.301046             0.084293   \n",
      "SHV   0.005180        0.000518    0.003265             0.000327   \n",
      "\n",
      "      Weighted Idio Var  \n",
      "TW         1.134702e-03  \n",
      "MSCI       6.375391e-04  \n",
      "NVDA       1.794834e-03  \n",
      "PCTY       1.099863e-03  \n",
      "AT.L       7.105267e-03  \n",
      "SHV        1.066239e-07   \n",
      "\n",
      "=== Factor Annual Volatilities (σ_i,f) ===\n",
      "      market  momentum   value  industry  subindustry\n",
      "TW    0.1841    0.0887  0.0652    0.2472       0.3043\n",
      "MSCI  0.1841    0.0887  0.0652    0.2472       0.3043\n",
      "NVDA  0.1841    0.0887  0.0652    0.2986       0.2428\n",
      "PCTY  0.1841    0.0887  0.0652    0.2465       0.3352\n",
      "AT.L  0.1867    0.0693  0.0613    0.2692       0.2692\n",
      "SHV   0.1841    0.0818  0.0652    0.0623       0.0183\n",
      "\n",
      "=== Weighted Factor Variance   w_i² · β_i,f² · σ_i,f² ===\n",
      "        market  momentum     value  industry  subindustry\n",
      "TW    0.000779  0.000021  0.000064  0.000712     0.001409\n",
      "MSCI  0.000859  0.000005  0.000150  0.000915     0.001214\n",
      "NVDA  0.002685  0.000045  0.002074  0.004272     0.002542\n",
      "PCTY  0.000626  0.000076  0.000015  0.001119     0.002621\n",
      "AT.L  0.000385  0.000122  0.000092  0.000001     0.000001\n",
      "SHV   0.000000  0.000000  0.000000  0.000000     0.000000 \n",
      "\n",
      "=== Portfolio Variance Decomposition ===\n",
      "Portfolio Variance:          0.0198\n",
      "Idiosyncratic Variance:      0.0118  (60%)\n",
      "Factor Variance:             0.0080  (40%)\n",
      "\n",
      "=== Factor Variance (absolute) ===\n",
      "Market     : 0.00533\n",
      "Momentum   : 0.00027\n",
      "Value      : 0.00239\n",
      "\n",
      "=== Factor Variance (% of Portfolio, excluding industry) ===\n",
      "Market     : 27%\n",
      "Momentum   : 1%\n",
      "Value      : 12%\n",
      "\n",
      "=== Industry Variance (absolute) ===\n",
      "KCE        : 0.001627\n",
      "SOXX       : 0.004272\n",
      "XSW        : 0.001119\n",
      "IXC        : 0.000001\n",
      "AGG        : 0.000000\n",
      "\n",
      "=== Industry Variance (% of Portfolio) ===\n",
      "KCE        : 8.2%\n",
      "SOXX       : 21.6%\n",
      "XSW        : 5.7%\n",
      "IXC        : 0.0%\n",
      "AGG        : 0.0%\n",
      "\n",
      "=== Per-Industry Group Betas ===\n",
      "KCE          : 0.2304\n",
      "SOXX         : 0.2189\n",
      "XSW          : 0.1357\n",
      "IXC          : -0.0040\n",
      "AGG          : 0.0016\n"
     ]
    }
   ],
   "source": [
    "# File: risk_runner.py\n",
    "\n",
    "# 2) Call the high-level summary builder\n",
    "summary = build_portfolio_view(\n",
    "    weights,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    expected_returns=expected_returns,\n",
    "    stock_factor_proxies=stock_factor_proxies\n",
    ")\n",
    "display_portfolio_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40af6775-8cc6-4407-9fa9-4e48755ffaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: risk_helpers.py\n",
    "\n",
    "from typing import Dict, Union, List\n",
    "import pandas as pd\n",
    "\n",
    "def get_worst_monthly_factor_losses(\n",
    "    stock_factor_proxies: Dict[str, Dict[str, Union[str, List[str]]]],\n",
    "    start_date: str,\n",
    "    end_date: str\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    For each unique factor proxy (ETF or peer group), fetch monthly returns over a historical window,\n",
    "    and compute the worst single-month return (min).\n",
    "\n",
    "    Only includes factor types: market, momentum, value, and industry.\n",
    "\n",
    "    Args:\n",
    "        stock_factor_proxies (Dict): From portfolio.yaml — maps tickers to their factor proxies.\n",
    "        start_date (str): Start date for return window (YYYY-MM-DD).\n",
    "        end_date (str): End date for return window (YYYY-MM-DD).\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: {proxy: worst 1-month return}\n",
    "    \"\"\"\n",
    "    from data_loader import fetch_monthly_close\n",
    "    from factor_utils import calc_monthly_returns\n",
    "\n",
    "    allowed_factors = {\"market\", \"momentum\", \"value\", \"industry\"}\n",
    "    unique_proxies = set()\n",
    "\n",
    "    for proxy_map in stock_factor_proxies.values():\n",
    "        for k, v in proxy_map.items():\n",
    "            if k not in allowed_factors:\n",
    "                continue  # skip subindustry and others\n",
    "            if isinstance(v, list):\n",
    "                unique_proxies.update(v)\n",
    "            else:\n",
    "                unique_proxies.add(v)\n",
    "\n",
    "    worst_losses = {}\n",
    "\n",
    "    for proxy in sorted(unique_proxies):\n",
    "        try:\n",
    "            prices = fetch_monthly_close(proxy, start_date, end_date)\n",
    "            returns = calc_monthly_returns(prices)\n",
    "            if not returns.empty:\n",
    "                worst_losses[proxy] = float(returns.min())\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed for proxy {proxy}: {e}\")\n",
    "\n",
    "    return worst_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "360fb1ab-2690-4102-a5c1-c7b490e3ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: risk_helpers.py\n",
    "\n",
    "from typing import Dict, Union, List, Tuple\n",
    "\n",
    "def aggregate_worst_losses_by_factor_type(\n",
    "    stock_factor_proxies: Dict[str, Dict[str, Union[str, List[str]]]],\n",
    "    worst_losses: Dict[str, float]\n",
    ") -> Dict[str, Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Aggregate the worst 1-month return per factor type by scanning all proxies\n",
    "    assigned to each factor type across the portfolio and selecting the worst-performing one.\n",
    "\n",
    "    Args:\n",
    "        stock_factor_proxies (Dict): Mapping from tickers to their factor proxy assignments.\n",
    "        worst_losses (Dict): Precomputed worst monthly return per ETF or peer.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Tuple[str, float]]: {factor_type: (proxy, worst_return)}\n",
    "    \"\"\"\n",
    "    factor_types = [\"market\", \"momentum\", \"value\", \"industry\"]\n",
    "    factor_to_proxies: Dict[str, set] = {ftype: set() for ftype in factor_types}\n",
    "\n",
    "    for proxy_map in stock_factor_proxies.values():\n",
    "        for ftype in factor_types:\n",
    "            proxy = proxy_map.get(ftype)\n",
    "            if isinstance(proxy, list):\n",
    "                factor_to_proxies[ftype].update(proxy)\n",
    "            elif proxy:\n",
    "                factor_to_proxies[ftype].add(proxy)\n",
    "\n",
    "    factor_worst: Dict[str, Tuple[str, float]] = {}\n",
    "    for ftype, proxies in factor_to_proxies.items():\n",
    "        worst_proxy = None\n",
    "        worst_val = float(\"inf\")\n",
    "        for proxy in proxies:\n",
    "            val = worst_losses.get(proxy)\n",
    "            if val is not None and val < worst_val:\n",
    "                worst_val = val\n",
    "                worst_proxy = proxy\n",
    "        if worst_proxy is not None:\n",
    "            factor_worst[ftype] = (worst_proxy, worst_val)\n",
    "\n",
    "    return factor_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdd5998a-903c-4cb1-8bd8-da0b3744e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── risk_helpers.py ──────────────────────────────────────────────\n",
    "from typing import Dict, Tuple, List\n",
    "import pandas as pd\n",
    "\n",
    "def compute_max_betas(\n",
    "    proxies: Dict[str, Dict[str, List[str] | str]],\n",
    "    start_date: str,\n",
    "    end_date:   str,\n",
    "    loss_limit_pct: float,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Pure function – NO YAML reads, NO printing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    proxies : dict          # stock_factor_proxies section\n",
    "    start_date, end_date : str  # analysis window (YYYY-MM-DD)\n",
    "    loss_limit_pct : float      # e.g. -0.10\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    {factor_type: max_beta}\n",
    "    \"\"\"\n",
    "    from risk_helpers import (\n",
    "        get_worst_monthly_factor_losses,\n",
    "        aggregate_worst_losses_by_factor_type,\n",
    "    )\n",
    "\n",
    "    worst_losses   = get_worst_monthly_factor_losses(proxies, start_date, end_date)\n",
    "    worst_by_type  = aggregate_worst_losses_by_factor_type(proxies, worst_losses)\n",
    "\n",
    "    return {\n",
    "        ftype: float(\"inf\") if worst >= 0 else loss_limit_pct / worst\n",
    "        for ftype, (_, worst) in worst_by_type.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1f3bbe4-7b41-4c60-8e2f-d7e34b46f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── risk_helpers.py ─────────────────────────────────────────────────────────\n",
    "\n",
    "from typing import Dict, Tuple, List\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def calc_max_factor_betas(\n",
    "    portfolio_yaml: str = \"portfolio.yaml\",\n",
    "    risk_yaml: str = \"risk_limits.yaml\",\n",
    "    lookback_years: int = 10,\n",
    "    echo: bool = True,\n",
    ") -> Tuple[Dict[str, float], Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Derive max-allowable portfolio betas for each factor type and industry\n",
    "    from historical worst 1-month factor proxy returns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio_yaml : str\n",
    "        Path to the YAML file containing `stock_factor_proxies`.\n",
    "    risk_yaml : str\n",
    "        Path to YAML containing `max_single_factor_loss`.\n",
    "    lookback_years : int\n",
    "        Historical window length to scan (ending today).\n",
    "    echo : bool\n",
    "        If True, pretty-prints the intermediate tables to stdout.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Dict[str, float], Dict[str, float]]\n",
    "        - max_betas:         {factor_type: max_beta}\n",
    "        - max_betas_by_proxy: {industry_proxy: max_beta}\n",
    "    \"\"\"\n",
    "    # 1. --- load configs -----------------------------------------------------\n",
    "    with open(portfolio_yaml, \"r\") as f:\n",
    "        port_cfg = yaml.safe_load(f)\n",
    "    with open(risk_yaml, \"r\") as f:\n",
    "        risk_cfg = yaml.safe_load(f)\n",
    "\n",
    "    proxies = port_cfg[\"stock_factor_proxies\"]\n",
    "    loss_limit = risk_cfg[\"max_single_factor_loss\"]  # e.g. -0.10\n",
    "\n",
    "    # 2. --- date window ------------------------------------------------------\n",
    "    end_dt = datetime.today()\n",
    "    start_dt = end_dt - pd.DateOffset(years=lookback_years)\n",
    "    end_str, start_str = end_dt.strftime(\"%Y-%m-%d\"), start_dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # 3. --- worst per-proxy --------------------------------------------------\n",
    "    worst_per_proxy = get_worst_monthly_factor_losses(\n",
    "        proxies, start_str, end_str\n",
    "    )\n",
    "\n",
    "    # 4. --- worst per factor-type -------------------------------------------\n",
    "    worst_by_factor = aggregate_worst_losses_by_factor_type(\n",
    "        proxies, worst_per_proxy\n",
    "    )\n",
    "\n",
    "    # 5. --- max beta per factor type ----------------------------------------------------\n",
    "    max_betas = compute_max_betas(\n",
    "        proxies, start_str, end_str, loss_limit\n",
    "    )\n",
    "\n",
    "    # 6. Compute per-industry-proxy max betas\n",
    "    industry_proxies = set()\n",
    "    for proxy_map in proxies.values():\n",
    "        proxy = proxy_map.get(\"industry\")\n",
    "        if isinstance(proxy, list):\n",
    "            industry_proxies.update(proxy)\n",
    "        elif proxy:\n",
    "            industry_proxies.add(proxy)\n",
    "\n",
    "    max_betas_by_proxy = {}\n",
    "    for proxy in sorted(industry_proxies):\n",
    "        worst = worst_per_proxy.get(proxy)\n",
    "        if worst is None or worst >= 0:\n",
    "            max_betas_by_proxy[proxy] = float(\"inf\")\n",
    "        else:\n",
    "            max_betas_by_proxy[proxy] = loss_limit / worst\n",
    "\n",
    "    # --- pretty print block --------------------------------------------------\n",
    "    if echo:\n",
    "        print(\"\\n=== Worst Monthly Losses per Proxy ===\")\n",
    "        for p, v in sorted(worst_per_proxy.items(), key=lambda kv: kv[1]):\n",
    "            print(f\"{p:<12} : {v:.2%}\")\n",
    "\n",
    "        print(\"\\n=== Worst Monthly Losses per Factor Type ===\")\n",
    "        for ftype, (p, v) in worst_by_factor.items():\n",
    "            print(f\"{ftype:<10} → {p:<12} : {v:.2%}\")\n",
    "\n",
    "        print(f\"\\n=== Max Allowable Beta per Factor \"\n",
    "              f\"(Loss Limit = {loss_limit:.0%}) ===\")\n",
    "        for ftype, beta in max_betas.items():\n",
    "            print(f\"{ftype:<10} → β ≤ {beta:.2f}\")\n",
    "\n",
    "        print(\"\\n=== Max Beta per Industry Proxy ===\")\n",
    "        for p, b in sorted(max_betas_by_proxy.items()):\n",
    "            print(f\"{p:<12} → β ≤ {b:.2f}\")\n",
    "\n",
    "    return max_betas, max_betas_by_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff2f7b94-7b9c-4929-9780-32bb814658ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Worst Monthly Losses per Proxy ===\n",
      "IXC          : -30.35%\n",
      "IWD          : -18.13%\n",
      "SOXX         : -17.96%\n",
      "KCE          : -17.93%\n",
      "IVLU         : -17.37%\n",
      "XSW          : -17.08%\n",
      "ACWX         : -14.97%\n",
      "SPY          : -13.00%\n",
      "MTUM         : -12.68%\n",
      "IMTM         : -9.88%\n",
      "AGG          : -4.34%\n",
      "\n",
      "=== Worst Monthly Losses per Factor Type ===\n",
      "market     → ACWX         : -14.97%\n",
      "momentum   → MTUM         : -12.68%\n",
      "value      → IWD          : -18.13%\n",
      "industry   → IXC          : -30.35%\n",
      "\n",
      "=== Max Allowable Beta per Factor (Loss Limit = -10%) ===\n",
      "market     → β ≤ 0.67\n",
      "momentum   → β ≤ 0.79\n",
      "value      → β ≤ 0.55\n",
      "industry   → β ≤ 0.33\n",
      "\n",
      "=== Max Beta per Industry Proxy ===\n",
      "AGG          → β ≤ 2.30\n",
      "IXC          → β ≤ 0.33\n",
      "KCE          → β ≤ 0.56\n",
      "SOXX         → β ≤ 0.56\n",
      "XSW          → β ≤ 0.59\n"
     ]
    }
   ],
   "source": [
    "# File: risk_runner.py\n",
    "\n",
    "max_betas, max_betas_by_proxy = calc_max_factor_betas(\n",
    "    portfolio_yaml=\"portfolio.yaml\",\n",
    "    risk_yaml=\"risk_limits.yaml\",\n",
    "    lookback_years=10,\n",
    "    echo=True   # turn off if you only need the dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f45b64-8699-44a3-9857-87abd5dec8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional\n",
    "\n",
    "def evaluate_portfolio_beta_limits(\n",
    "    portfolio_factor_betas: pd.Series,\n",
    "    max_betas: Dict[str, float],\n",
    "    proxy_betas: Optional[Dict[str, float]] = None,\n",
    "    max_proxy_betas: Optional[Dict[str, float]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compares each factor's actual portfolio beta to the allowable max beta.\n",
    "    Also supports proxy-level checks like individual industry ETFs.\n",
    "    \n",
    "    If proxy-level data (e.g. per-industry ETF) is available, it skips\n",
    "    the aggregate 'industry' row to avoid double counting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio_factor_betas : pd.Series\n",
    "        e.g. {\"market\": 0.74, \"momentum\": 1.1, ...}\n",
    "    max_betas : dict\n",
    "        e.g. {\"market\": 0.80, \"momentum\": 1.56, ...}\n",
    "    proxy_betas : dict, optional\n",
    "        e.g. {\"SOXX\": 0.218, \"KCE\": 0.287}\n",
    "    max_proxy_betas : dict, optional\n",
    "        e.g. {\"SOXX\": 0.56, \"KCE\": 0.49}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Rows: factors and proxies. Columns: portfolio_beta, max_allowed_beta, pass, buffer.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    skip_industry = proxy_betas is not None and max_proxy_betas is not None\n",
    "\n",
    "    # ─── Factor-level checks ─────────────────────────────────\n",
    "    for factor, max_b in max_betas.items():\n",
    "        if skip_industry and factor == \"industry\":\n",
    "            continue  # skip aggregate industry if per-proxy provided\n",
    "\n",
    "        actual = portfolio_factor_betas.get(factor, 0.0)\n",
    "        rows.append({\n",
    "            \"factor\": factor,\n",
    "            \"portfolio_beta\": actual,\n",
    "            \"max_allowed_beta\": max_b,\n",
    "            \"pass\": abs(actual) <= max_b,\n",
    "            \"buffer\": max_b - abs(actual),\n",
    "        })\n",
    "\n",
    "    # ─── Proxy-level checks (e.g. SOXX, XSW) ─────────────────\n",
    "    if proxy_betas and max_proxy_betas:\n",
    "        for proxy, actual in proxy_betas.items():\n",
    "            max_b = max_proxy_betas.get(proxy, float(\"inf\"))\n",
    "            label = f\"industry_proxy::{proxy}\"\n",
    "            rows.append({\n",
    "                \"factor\": label,\n",
    "                \"portfolio_beta\": actual,\n",
    "                \"max_allowed_beta\": max_b,\n",
    "                \"pass\": abs(actual) <= max_b,\n",
    "                \"buffer\": max_b - abs(actual),\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows).set_index(\"factor\")\n",
    "    return df[[\"portfolio_beta\", \"max_allowed_beta\", \"pass\", \"buffer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95113a1c-a648-4c66-8a76-ff3c548f5278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Portfolio Factor Exposure Checks ===\n",
      "\n",
      "         portfolio_beta max_allowed_beta  pass buffer\n",
      "market            +0.83             0.67  FAIL  -0.17\n",
      "momentum          -0.21             0.79  PASS  +0.58\n",
      "value             -1.23             0.55  FAIL  -0.68\n",
      "\n",
      "=== Industry Exposure Checks ===\n",
      "\n",
      "     portfolio_beta max_allowed_beta  pass buffer\n",
      "KCE           +0.23             0.56  PASS  +0.33\n",
      "SOXX          +0.22             0.56  PASS  +0.34\n",
      "XSW           +0.14             0.59  PASS  +0.45\n",
      "IXC           -0.00             0.33  PASS  +0.33\n",
      "AGG           +0.00             2.30  PASS  +2.30\n"
     ]
    }
   ],
   "source": [
    "# File: risk_runner.py\n",
    "# Check portfolio beta limit checks\n",
    "\n",
    "df_beta_check = evaluate_portfolio_beta_limits(\n",
    "    portfolio_factor_betas = summary[\"portfolio_factor_betas\"],\n",
    "    max_betas              = max_betas,\n",
    "    proxy_betas            = summary[\"industry_variance\"].get(\"per_industry_group_beta\"),\n",
    "    max_proxy_betas        = max_betas_by_proxy\n",
    ")\n",
    "# Separate into two sections\n",
    "df_factors = df_beta_check[~df_beta_check.index.str.startswith(\"industry_proxy::\")]\n",
    "df_proxies = df_beta_check[df_beta_check.index.str.startswith(\"industry_proxy::\")].copy()\n",
    "\n",
    "# Clean up proxy labels\n",
    "df_proxies.index = df_proxies.index.str.replace(\"industry_proxy::\", \"\")\n",
    "\n",
    "# Print factor-level\n",
    "print(\"=== Portfolio Factor Exposure Checks ===\\n\")\n",
    "print(df_factors.to_string(\n",
    "    index_names=False,\n",
    "    formatters={\n",
    "        \"portfolio_beta\":   \"{:+.2f}\".format,\n",
    "        \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "        \"buffer\":           \"{:+.2f}\".format,\n",
    "        \"pass\":             lambda x: \"PASS\" if x else \"FAIL\"\n",
    "    }\n",
    "))\n",
    "\n",
    "# Add spacing between sections\n",
    "print(\"\\n=== Industry Exposure Checks ===\\n\")\n",
    "print(df_proxies.to_string(\n",
    "    index_names=False,\n",
    "    formatters={\n",
    "        \"portfolio_beta\":   \"{:+.2f}\".format,\n",
    "        \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "        \"buffer\":           \"{:+.2f}\".format,\n",
    "        \"pass\":             lambda x: \"PASS\" if x else \"FAIL\"\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8249e73e-8f34-48af-ac23-d33aa5996c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_portfolio_risk_limits(\n",
    "    summary: Dict[str, Any],\n",
    "    portfolio_limits: Dict[str, float],\n",
    "    concentration_limits: Dict[str, float],\n",
    "    variance_limits: Dict[str, float]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates portfolio risk metrics against configured limits.\n",
    "\n",
    "    Args:\n",
    "        summary (dict): Output from build_portfolio_view().\n",
    "        portfolio_limits (dict): {\"max_volatility\": float, \"max_loss\": float}\n",
    "        concentration_limits (dict): {\"max_single_stock_weight\": float}\n",
    "        variance_limits (dict): Keys include \"max_factor_contribution\", etc.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: One row per check with actual, limit, and pass/fail.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # 1. Volatility Check\n",
    "    actual_vol = summary[\"volatility_annual\"]\n",
    "    vol_limit = portfolio_limits[\"max_volatility\"]\n",
    "    results.append({\n",
    "        \"Metric\": \"Volatility\",\n",
    "        \"Actual\": actual_vol,\n",
    "        \"Limit\": vol_limit,\n",
    "        \"Pass\": actual_vol <= vol_limit\n",
    "    })\n",
    "\n",
    "    # 2. Concentration Check\n",
    "    weights = summary[\"allocations\"][\"Portfolio Weight\"]\n",
    "    max_weight = weights.abs().max()\n",
    "    weight_limit = concentration_limits[\"max_single_stock_weight\"]\n",
    "    results.append({\n",
    "        \"Metric\": \"Max Weight\",\n",
    "        \"Actual\": max_weight,\n",
    "        \"Limit\": weight_limit,\n",
    "        \"Pass\": max_weight <= weight_limit\n",
    "    })\n",
    "\n",
    "    # 3. Factor Variance Contribution\n",
    "    var_decomp = summary[\"variance_decomposition\"]\n",
    "    factor_pct = var_decomp[\"factor_pct\"]\n",
    "    factor_limit = variance_limits[\"max_factor_contribution\"]\n",
    "    results.append({\n",
    "        \"Metric\": \"Factor Var %\",\n",
    "        \"Actual\": factor_pct,\n",
    "        \"Limit\": factor_limit,\n",
    "        \"Pass\": factor_pct <= factor_limit\n",
    "    })\n",
    "\n",
    "    # 4. Market Variance Contribution\n",
    "    market_pct = var_decomp[\"factor_breakdown_pct\"].get(\"market\", 0.0)\n",
    "    market_limit = variance_limits[\"max_market_contribution\"]\n",
    "    results.append({\n",
    "        \"Metric\": \"Market Var %\",\n",
    "        \"Actual\": market_pct,\n",
    "        \"Limit\": market_limit,\n",
    "        \"Pass\": market_pct <= market_limit\n",
    "    })\n",
    "\n",
    "    # 5. Top Industry Exposure\n",
    "    industry_pct_dict = summary[\"industry_variance\"].get(\"percent_of_portfolio\", {})\n",
    "    max_industry_pct = max(industry_pct_dict.values()) if industry_pct_dict else 0.0\n",
    "    industry_limit = variance_limits[\"max_industry_contribution\"]\n",
    "    results.append({\n",
    "        \"Metric\": \"Max Industry Var %\",\n",
    "        \"Actual\": max_industry_pct,\n",
    "        \"Limit\": industry_limit,\n",
    "        \"Pass\": max_industry_pct <= industry_limit\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c86f3665-75a7-470b-a0bf-419f0bbe88d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Portfolio Risk Limit Checks ===\n",
      "Volatility             21.65%  ≤ 40.00%  → PASS\n",
      "Max Weight             28.00%  ≤ 40.00%  → PASS\n",
      "Factor Var %           40.46%  ≤ 30.00%  → FAIL\n",
      "Market Var %           26.98%  ≤ 30.00%  → PASS\n",
      "Max Industry Var %     21.61%  ≤ 30.00%  → PASS\n"
     ]
    }
   ],
   "source": [
    "# === Evaluate Portfolio vs. Limits ===\n",
    "\n",
    "# Step 0: Load Portfolio + Risk Config ────────────────────────────────────────\n",
    "with open(\"portfolio.yaml\", \"r\") as f:\n",
    "    portfolio_config = yaml.safe_load(f)\n",
    "\n",
    "with open(\"risk_limits.yaml\", \"r\") as f:\n",
    "    risk_config = yaml.safe_load(f)\n",
    "\n",
    "stock_factor_proxies = portfolio_config[\"stock_factor_proxies\"]\n",
    "LOSS_LIMIT = risk_config[\"max_single_factor_loss\"]  # e.g. -0.10\n",
    "\n",
    "# Step 1: Run risk limit evaluation\n",
    "df_risk = evaluate_portfolio_risk_limits(\n",
    "    summary,\n",
    "    risk_config[\"portfolio_limits\"],\n",
    "    risk_config[\"concentration_limits\"],\n",
    "    risk_config[\"variance_limits\"]\n",
    ")\n",
    "\n",
    "# Step 2: Pretty print results\n",
    "print(\"=== Portfolio Risk Limit Checks ===\")\n",
    "for _, row in df_risk.iterrows():\n",
    "    status = \"→ PASS\" if row[\"Pass\"] else \"→ FAIL\"\n",
    "    print(f\"{row['Metric']:<22} {row['Actual']:.2%}  ≤ {row['Limit']:.2%}  {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5561b6b-03ec-4690-8f34-d061228ae53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: portfolio_optimizer.py ──────────────────────────────────────────\n",
    "\"\"\"\n",
    "Light-weight optimisation helpers that bolt onto the existing risk-runner.\n",
    "\n",
    "Requires:\n",
    "    pip install cvxpy\n",
    "\n",
    "Functions\n",
    "---------\n",
    "simulate_portfolio_change(weights, edits, risk_cfg, start, end, proxies)\n",
    "    → returns (summary, df_risk, df_beta)\n",
    "\n",
    "solve_min_variance_with_risk_limits(weights, risk_cfg, start, end, proxies)\n",
    "    → returns new_weights OR raises ValueError if infeasible\n",
    "\"\"\"\n",
    "from typing import Dict, Any\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "def simulate_portfolio_change(\n",
    "    weights: Dict[str, float],\n",
    "    edits: Dict[str, float],\n",
    "    risk_cfg: Dict[str, Any],\n",
    "    start: str,\n",
    "    end: str,\n",
    "    proxies: Dict[str, Dict[str, Any]],\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a *new* summary after applying `edits` (delta-weights).\n",
    "    `edits` can add new tickers or override existing weights.\n",
    "\n",
    "    Example:\n",
    "        new_summary, df_risk, df_beta = simulate_portfolio_change(\n",
    "            weights,\n",
    "            edits={\"MSFT\": +0.05, \"AAPL\": -0.02},\n",
    "            ...\n",
    "        )\n",
    "    \"\"\"\n",
    "    # --- 1. rebuild weights -------------------------------------------------\n",
    "    new_w = deepcopy(weights)\n",
    "    for tkr, w in edits.items():\n",
    "        new_w[tkr] = new_w.get(tkr, 0.0) + w\n",
    "\n",
    "    # normalize\n",
    "    tot = sum(new_w.values())\n",
    "    new_w = {k: v / tot for k, v in new_w.items()}\n",
    "\n",
    "    # --- 2. fresh risk summary ---------------------------------------------\n",
    "    summary = build_portfolio_view(\n",
    "        new_w, start, end, expected_returns=None, stock_factor_proxies=proxies\n",
    "    )\n",
    "\n",
    "    # --- 3. risk-limit checker ---------------------------------------------\n",
    "    df_risk = evaluate_portfolio_risk_limits(\n",
    "        summary,\n",
    "        risk_cfg[\"portfolio_limits\"],\n",
    "        risk_cfg[\"concentration_limits\"],\n",
    "        risk_cfg[\"variance_limits\"],\n",
    "    )\n",
    "\n",
    "    # --- 4. dynamic β caps (factor) --------------------------------    \n",
    "    max_betas = compute_max_betas(\n",
    "        proxies, \n",
    "        start, \n",
    "        end, \n",
    "        loss_limit_pct=risk_cfg[\"max_single_factor_loss\"]\n",
    "    )\n",
    "    \n",
    "    df_beta = evaluate_portfolio_beta_limits(summary[\"portfolio_factor_betas\"], max_betas)\n",
    "\n",
    "    return summary, df_risk, df_beta\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "def solve_min_variance_with_risk_limits(\n",
    "    weights: Dict[str, float],\n",
    "    risk_cfg: Dict[str, Any],\n",
    "    start: str,\n",
    "    end: str,\n",
    "    proxies: Dict[str, Dict[str, Any]],\n",
    "    allow_short: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds the *smallest-variance* weights that satisfy **all** limits.\n",
    "    Keeps the current universe (no new tickers). If infeasible, raises.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float] : optimised weights (sum to 1)\n",
    "    \"\"\"\n",
    "    tickers = list(weights)\n",
    "    n       = len(tickers)\n",
    "\n",
    "    # Pre-compute covariance\n",
    "    base_summary = build_portfolio_view(weights, start, end, None, proxies)\n",
    "    Σ = base_summary[\"covariance_matrix\"].loc[tickers, tickers].values\n",
    "\n",
    "    # Limits for betas\n",
    "    max_betas = compute_max_betas(\n",
    "        proxies, \n",
    "        start, \n",
    "        end, \n",
    "        loss_limit_pct=risk_cfg[\"max_single_factor_loss\"]\n",
    "    )\n",
    "\n",
    "    # Variables\n",
    "    w = cp.Variable(n)\n",
    "\n",
    "    # Objective: minimise portfolio variance wᵀ Σ w\n",
    "    obj = cp.Minimize(cp.quad_form(w, Σ))\n",
    "\n",
    "    cons = []\n",
    "\n",
    "    # 1. Weights sum to 1 (fully invested)\n",
    "    cons += [cp.sum(w) == 1]\n",
    "\n",
    "    # 2. Concentration limit\n",
    "    max_weight = risk_cfg[\"concentration_limits\"][\"max_single_stock_weight\"]\n",
    "    cons += [cp.abs(w) <= max_weight]\n",
    "\n",
    "    if not allow_short:\n",
    "        cons += [w >= 0]\n",
    "\n",
    "    # 3. Factor beta limits\n",
    "    beta_mat = base_summary[\"df_stock_betas\"].fillna(0.0).loc[tickers]  # shape n × factors\n",
    "    for fac, max_b in max_betas.items():\n",
    "        if fac not in beta_mat:\n",
    "            continue\n",
    "        cons += [\n",
    "            cp.abs(beta_mat[fac].values @ w) <= max_b\n",
    "        ]\n",
    "\n",
    "    # 4. Gross volatility limit\n",
    "    max_vol = risk_cfg[\"portfolio_limits\"][\"max_volatility\"]\n",
    "    cons += [cp.quad_form(w, Σ) <= max_vol**2]\n",
    "\n",
    "    prob = cp.Problem(obj, cons)\n",
    "    prob.solve(solver=cp.ECOS, verbose=False)\n",
    "\n",
    "    if prob.status not in (\"optimal\", \"optimal_inaccurate\"):\n",
    "        raise ValueError(f\"Infeasible under current limits (status={prob.status})\")\n",
    "\n",
    "    new_w = {t: float(w.value[i]) for i, t in enumerate(tickers)}\n",
    "    return new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f444d366-8a7f-4354-b630-3e071a2e5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: helpers_display.py ──────────────────────────────────────────\n",
    "\n",
    "EXCLUDE_FACTORS = {\"industry\"}          # extend if you need to hide more later\n",
    "\n",
    "def _drop_factors(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove presentation-only factor rows (case / whitespace agnostic).\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    idx_mask = (\n",
    "        df.index.to_series()\n",
    "          .str.strip()\n",
    "          .str.lower()\n",
    "          .isin({f.lower() for f in EXCLUDE_FACTORS})\n",
    "    )\n",
    "    return df.loc[~idx_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32a21dac-1cc8-4cee-9ed2-ed9404b34328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: portfolio_optimizer.py ──────────────────────────────────────────\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "#  WHAT-IF helper\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "def run_what_if(\n",
    "    base_weights: pd.Series,\n",
    "    delta: Dict[str, float],\n",
    "    risk_cfg: Dict,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    factor_proxies: Dict[str, Dict],\n",
    "    *,           \n",
    "    verbose: bool = True,\n",
    ") -> Tuple[dict, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Apply absolute weight shifts (`delta`) to `base_weights`, evaluate the\n",
    "    resulting portfolio, and pretty-print a compact risk report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_weights : pd.Series\n",
    "        Current portfolio weights (summing to 1.0).\n",
    "    delta : dict\n",
    "        {ticker: +shift or –shift}.  Shifts are *absolute* (e.g. +0.05 = +5 ppts).\n",
    "    risk_cfg : dict\n",
    "        Parsed risk-limits YAML (needs `portfolio_limits`, `concentration_limits`,\n",
    "        `variance_limits`, `max_single_factor_loss`).\n",
    "    start_date, end_date : str\n",
    "        Analysis window (YYYY-MM-DD).\n",
    "    factor_proxies : dict\n",
    "        Mapping used by `simulate_portfolio_change`.\n",
    "    verbose : bool, default **True**\n",
    "    • **True**  → pretty-prints risk / beta tables (old behaviour).  \n",
    "    • **False** → no console output; function only returns data frames.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary : dict              # build_portfolio_view output\n",
    "    risk_df : pd.DataFrame      # risk-limit check table\n",
    "    beta_df : pd.DataFrame      # factor-beta check table\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) build new portfolio + tables\n",
    "    summary, risk_df, beta_df = simulate_portfolio_change(\n",
    "        base_weights, delta, risk_cfg,\n",
    "        start_date, end_date, factor_proxies\n",
    "    )\n",
    "\n",
    "    # 2) optionally pretty-print\n",
    "    if verbose:\n",
    "        \n",
    "        # --- fancy title --------------------------------------------------------\n",
    "        delta_str = \" / \".join(f\"{v:+.0%} {k}\" for k, v in delta.items())\n",
    "        print(f\"\\n📐  What-if Risk Checks ({delta_str})\\n\")\n",
    "    \n",
    "        # --- risk table ---------------------------------------------------------\n",
    "        pct = lambda x: f\"{x:.1%}\"\n",
    "        print(risk_df.to_string(index=False,\n",
    "                                formatters={\"Actual\": pct, \"Limit\": pct}))\n",
    "    \n",
    "        # --- beta table ---------------------------------------------------------\n",
    "        print(\"\\n📊  What-if Factor Betas\\n\")\n",
    "        beta_df_disp = _drop_factors(beta_df)\n",
    "    \n",
    "        print(beta_df_disp.to_string(formatters={\n",
    "            \"portfolio_beta\":    \"{:.2f}\".format,     # or \"{:.2f}\" if you prefer two decimals\n",
    "            \"max_allowed_beta\":  \"{:.2f}\".format,\n",
    "            \"buffer\":            \"{:.2f}\".format,\n",
    "            \"pass\":              lambda x: \"PASS\" if x else \"FAIL\"\n",
    "        }))\n",
    "\n",
    "    return summary, risk_df, beta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05610761-6e41-4879-8792-ab259daf5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: helpers_display.py ──────────────────────────────────────────\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def _fmt_pct(x: float) -> str:\n",
    "    return f\"{x:.1%}\"\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "def compare_risk_tables(old: pd.DataFrame, new: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Side-by-side diff for the risk-limit checker.\"\"\"\n",
    "    left  = old.rename(columns={\"Actual\": \"Old\",  \"Pass\": \"Old Pass\"})\n",
    "    right = new.rename(columns={\"Actual\": \"New\",  \"Pass\": \"New Pass\"})\n",
    "    out   = (\n",
    "        left.merge(right, on=[\"Metric\", \"Limit\"], how=\"outer\", sort=False)\n",
    "            .assign(Δ=lambda d: d[\"New\"] - d[\"Old\"])\n",
    "            .loc[:, [\"Metric\", \"Old\", \"New\", \"Δ\", \"Limit\", \"Old Pass\", \"New Pass\"]]\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "def compare_beta_tables(old: pd.DataFrame, new: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Diff for the factor-beta checker.\n",
    "      • Accepts either camel- or snake-case column names.\n",
    "      • Fills missing Max-Beta / Pass columns with sensible defaults.\n",
    "      • Index must be Factor for both inputs.\n",
    "    \"\"\"\n",
    "    def _clean(df: pd.DataFrame, tag: str) -> pd.DataFrame:\n",
    "        colmap = {\n",
    "            \"portfolio_beta\": \"Beta\",\n",
    "            \"max_allowed_beta\": \"Max Beta\",\n",
    "            \"max_beta\": \"Max Beta\",\n",
    "            \"pass\": \"Pass\",\n",
    "        }\n",
    "        df = df.rename(columns=colmap)\n",
    "        if \"Max Beta\" not in df.columns:\n",
    "            df[\"Max Beta\"] = 0.0\n",
    "        if \"Pass\" not in df.columns:\n",
    "            df[\"Pass\"] = False\n",
    "        df = df.rename(columns={\"Beta\": tag, \"Pass\": f\"{tag} Pass\"})\n",
    "        return df[[tag, \"Max Beta\", f\"{tag} Pass\"]]\n",
    "\n",
    "    left  = _clean(old.copy(), \"Old\")\n",
    "    right = _clean(new.copy(), \"New\")\n",
    "\n",
    "    merged = left.merge(\n",
    "        right,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how=\"outer\",\n",
    "        sort=False\n",
    "    )\n",
    "\n",
    "    # unify the duplicated Max Beta columns\n",
    "    merged[\"Max Beta\"] = merged[\"Max Beta_x\"].combine_first(merged[\"Max Beta_y\"])\n",
    "    merged = merged.drop(columns=[\"Max Beta_x\", \"Max Beta_y\"])\n",
    "\n",
    "    out = (\n",
    "        merged\n",
    "        .assign(Δ=lambda d: d[\"New\"] - d[\"Old\"])\n",
    "        .loc[:, [\"Old\", \"New\", \"Δ\", \"Max Beta\", \"Old Pass\", \"New Pass\"]]\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4fdb206-cd37-4192-afb6-6c947e160b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── portfolio_optimizer.py ───────────────────────\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "#  Risk evaluation portfolio helper\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "def evaluate_weights(\n",
    "    weights: Dict[str, float],\n",
    "    risk_cfg: Dict[str, Any],\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    proxies: Dict[str, Dict[str, Any]],\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Runs the standard risk + beta limit checks on a given weight dict.\n",
    "    Returns (df_risk, df_beta) – no printing.\n",
    "    \"\"\"\n",
    "    from portfolio_risk import build_portfolio_view\n",
    "    from run_portfolio_risk import (\n",
    "        evaluate_portfolio_risk_limits,\n",
    "        evaluate_portfolio_beta_limits,\n",
    "    )\n",
    "    from risk_helpers import compute_max_betas\n",
    "\n",
    "    summary = build_portfolio_view(\n",
    "        weights, start_date, end_date,\n",
    "        expected_returns=None, stock_factor_proxies=proxies\n",
    "    )\n",
    "\n",
    "    df_risk = evaluate_portfolio_risk_limits(\n",
    "        summary,\n",
    "        risk_cfg[\"portfolio_limits\"],\n",
    "        risk_cfg[\"concentration_limits\"],\n",
    "        risk_cfg[\"variance_limits\"],\n",
    "    )\n",
    "\n",
    "    max_betas = compute_max_betas(\n",
    "        proxies=proxies,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        loss_limit_pct=risk_cfg[\"max_single_factor_loss\"],\n",
    "    )\n",
    "\n",
    "    df_beta = evaluate_portfolio_beta_limits(\n",
    "        summary[\"portfolio_factor_betas\"],\n",
    "        max_betas,\n",
    "    )\n",
    "    return df_risk, df_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d3b6b3c-286d-4a0c-a01e-6f4a5d9c7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: helpers_input.py ──────────────────────────────────\n",
    "\"\"\"\n",
    "Helpers for ingesting *what-if* portfolio changes.\n",
    "\n",
    "parse_delta(...)\n",
    "    • Accepts a YAML file path (optional) and/or an in-memory shift dict.\n",
    "    • Returns a tuple: (delta_dict, new_weights_dict_or_None).\n",
    "\n",
    "Precedence rules\n",
    "----------------\n",
    "1. If YAML contains `new_weights:` → treat as full replacement; shift_dict ignored.\n",
    "2. Else, build a *delta* dict:     YAML `delta:` first, then merge/override\n",
    "   any overlapping keys from `shift_dict`.\n",
    "3. YAML missing or empty           → use shift_dict alone.\n",
    "\"\"\"\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "def _parse_shift(txt: str) -> float:\n",
    "    \"\"\"\n",
    "    Convert a human-friendly shift string to decimal.\n",
    "\n",
    "    \"+200bp\", \"-75bps\", \"1.5%\", \"-0.01\"  →  0.02, -0.0075, 0.015, -0.01\n",
    "    \"\"\"\n",
    "    t = txt.strip().lower().replace(\" \", \"\")\n",
    "    if t.endswith(\"%\"):\n",
    "        return float(t[:-1]) / 100\n",
    "    if t.endswith((\"bp\", \"bps\")):\n",
    "        return float(t.rstrip(\"ps\").rstrip(\"bp\")) / 10_000\n",
    "    return float(t)                       # already decimal\n",
    "\n",
    "def parse_delta(\n",
    "    yaml_path: Optional[str] = None,\n",
    "    literal_shift: Optional[Dict[str, str]] = None,\n",
    ") -> Tuple[Dict[str, float], Optional[Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Parse a what-if scenario.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yaml_path : str | None\n",
    "        Path to a YAML file that may contain `new_weights:` or `delta:`.\n",
    "    literal_shift : dict | None\n",
    "        In-memory dict of {ticker: shift_string}.  Overrides YAML deltas.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (delta_dict, new_weights_dict_or_None)\n",
    "    \"\"\"\n",
    "    delta: Dict[str, float] = {}\n",
    "    new_w: Optional[Dict[str, float]] = None\n",
    "\n",
    "    # ── YAML branch (only if file is present) ─────────────────────────\n",
    "    if yaml_path and Path(yaml_path).is_file():\n",
    "        cfg = yaml.safe_load(Path(yaml_path).read_text()) or {}\n",
    "        \n",
    "        # 1) full-replacement portfolio\n",
    "        if \"new_weights\" in cfg:               \n",
    "            w = {k: float(v) for k, v in cfg[\"new_weights\"].items()}\n",
    "            s = sum(w.values()) or 1.0\n",
    "            new_w = {k: v / s for k, v in w.items()}\n",
    "            return {}, new_w\n",
    "\n",
    "        # 2) incremental tweaks\n",
    "        if \"delta\" in cfg:                     \n",
    "            delta.update({k: _parse_shift(v) for k, v in cfg[\"delta\"].items()})\n",
    "\n",
    "    # ── literal shift branch (CLI / notebook) ────────────────────────\n",
    "    if literal_shift:\n",
    "        delta.update({k: _parse_shift(v) for k, v in literal_shift.items()})\n",
    "\n",
    "    # ── sanity check -------------------------------------------------------\n",
    "    if not delta and new_w is None:\n",
    "        raise ValueError(\n",
    "            \"No delta or new_weights provided (YAML empty and literal_shift is None)\"\n",
    "        )\n",
    "\n",
    "    return delta, new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9be24bcb-ba02-4b76-b0ed-e3f1f4b480fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: helpers_display.py ──────────────────────────────────────────\n",
    "\n",
    "def _print_single_portfolio(risk_df, beta_df, title: str = \"What-if\") -> None:\n",
    "    \"\"\"\n",
    "    Pretty-print risk-limit and factor-beta tables for a *single* portfolio\n",
    "    (new weights or what-if scenario).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    risk_df : pd.DataFrame\n",
    "        Output from `evaluate_portfolio_risk_limits` (or risk_new in run_what_if)\n",
    "        with columns [\"Metric\", \"Actual\", \"Limit\", \"Pass\"].\n",
    "    beta_df : pd.DataFrame\n",
    "        Output from `evaluate_portfolio_beta_limits` with columns\n",
    "        [\"portfolio_beta\", \"max_allowed_beta\", \"pass\", \"buffer\"] and the\n",
    "        factor name as index.\n",
    "    title : str, default \"What-if\"\n",
    "        Heading prefix used in the console output.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    • Percentages (`Actual`, `Limit`) are rendered with **one-decimal** precision.\n",
    "    • Betas, max-betas, and buffer columns are rendered to **four** decimals.\n",
    "    • Pass/fail booleans are mapped to the strings ``PASS`` / ``FAIL``.\n",
    "    • Prints directly to stdout; returns None.\n",
    "    \"\"\"\n",
    "    pct = lambda x: f\"{x:.1%}\"                # 1-decimal percentage\n",
    "\n",
    "    print(f\"\\n📐  {title} Risk Checks\\n\")\n",
    "    print(\n",
    "        risk_df.to_string(\n",
    "            index=False,\n",
    "            formatters={\"Actual\": pct, \"Limit\": pct}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"\\n📊  {title} Factor Betas\\n\")\n",
    "    beta_df = _drop_factors(beta_df)\n",
    "    print(\n",
    "        beta_df.to_string(\n",
    "            formatters={\n",
    "                \"portfolio_beta\":   \"{:.4f}\".format,\n",
    "                \"max_allowed_beta\": \"{:.4f}\".format,\n",
    "                \"buffer\":           \"{:.4f}\".format,\n",
    "                \"pass\":             lambda x: \"PASS\" if x else \"FAIL\",\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "854aa215-6875-405f-ae40-1a194f09d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: portfolio_optimizer.py ───────────────────────\n",
    "\n",
    "def print_what_if_report(\n",
    "    *,\n",
    "    summary_new: Dict[str, Any],\n",
    "    risk_new: pd.DataFrame,\n",
    "    beta_f_new: pd.DataFrame,\n",
    "    beta_p_new: pd.DataFrame,\n",
    "    cmp_risk: pd.DataFrame,\n",
    "    cmp_beta: pd.DataFrame,\n",
    "):\n",
    "    \"\"\"\n",
    "    Prints a CLI-friendly report for a what-if portfolio scenario.\n",
    "\n",
    "    Includes:\n",
    "        • New portfolio risk checks\n",
    "        • New factor and industry betas\n",
    "        • Before/after diffs for risk and factor exposures\n",
    "\n",
    "    All output is printed to stdout using fixed-width formatting.\n",
    "    \"\"\"\n",
    "    print(\"\\n📐  NEW Portfolio – Risk Checks\\n\")\n",
    "    print(risk_new.to_string(index=False, formatters={\n",
    "        \"Actual\": lambda x: f\"{x:.1%}\",\n",
    "        \"Limit\":  lambda x: f\"{x:.1%}\",\n",
    "    }))\n",
    "\n",
    "    print(\"\\n📊  NEW Aggregate Factor Exposures\\n\")\n",
    "    print(beta_f_new.to_string(index_names=False, formatters={\n",
    "        \"portfolio_beta\":   \"{:.2f}\".format,\n",
    "        \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "        \"buffer\":           \"{:.2f}\".format,\n",
    "        \"pass\":             lambda x: \"PASS\" if x else \"FAIL\",\n",
    "    }))\n",
    "\n",
    "    print(\"\\n📊  NEW Industry Exposure Checks\\n\")\n",
    "    print(beta_p_new.to_string(index_names=False, formatters={\n",
    "        \"portfolio_beta\":   \"{:.2f}\".format,\n",
    "        \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "        \"buffer\":           \"{:.2f}\".format,\n",
    "        \"pass\":             lambda x: \"PASS\" if x else \"FAIL\",\n",
    "    }))\n",
    "\n",
    "    print(\"\\n📐  Risk Limits — Before vs After\\n\")\n",
    "    print(cmp_risk.to_string(index=False, formatters={\n",
    "        \"Old\":   lambda x: f\"{x:.1%}\",\n",
    "        \"New\":   lambda x: f\"{x:.1%}\",\n",
    "        \"Δ\":     lambda x: f\"{x:.1%}\",\n",
    "        \"Limit\": lambda x: f\"{x:.1%}\",\n",
    "    }))\n",
    "\n",
    "    print(\"\\n📊  Factor Betas — Before vs After\\n\")\n",
    "    print(cmp_beta.to_string(index_names=False, formatters={\n",
    "        \"Old\":       \"{:.2f}\".format,\n",
    "        \"New\":       \"{:.2f}\".format,\n",
    "        \"Δ\":         \"{:.2f}\".format,\n",
    "        \"Max Beta\":  \"{:.2f}\".format,\n",
    "        \"Old Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "        \"New Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a33c1eb-6cea-4e39-9764-9ab4725e8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: portfolio_optimizer.py ───────────────────────\n",
    "\n",
    "# WHAT-IF DRIVER\n",
    "#\n",
    "# Input precedence\n",
    "# ----------------\n",
    "# 1. If `what_if_portfolio.yaml` contains a top-level `new_weights:` section\n",
    "#    → treat as a full-replacement portfolio.\n",
    "#      • `shift_dict` is ignored in this case.\n",
    "#\n",
    "# 2. Otherwise, build an incremental *delta* dict:\n",
    "#      • YAML `delta:` values are parsed first.\n",
    "#      • Any overlapping keys in `shift_dict` overwrite the YAML values.\n",
    "#\n",
    "# 3. Branch logic\n",
    "#      • full-replacement  → evaluate_weights(new_weights_yaml)\n",
    "#      • incremental tweak → run_what_if(base_weights, delta)\n",
    "#\n",
    "# 4. After computing the new portfolio’s risk/beta tables once,\n",
    "#    we also compute the baseline (unchanged) tables once, then\n",
    "#    show before-vs-after diffs.\n",
    "#\n",
    "# Note: No function ever writes back to the YAML file; all merges happen\n",
    "#       in memory.\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def run_what_if_scenario(\n",
    "    *,\n",
    "    base_weights: Dict[str, float],\n",
    "    config: Dict[str, Any],\n",
    "    risk_config: Dict[str, Any],\n",
    "    proxies: Dict[str, Any],\n",
    "    shift_dict: Optional[Dict[str, str]] = None,\n",
    "    scenario_yaml: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a portfolio what-if scenario and returns the full risk report.\n",
    "\n",
    "    Accepts either a YAML file or an inline delta dictionary to simulate portfolio changes,\n",
    "    then compares the updated risk profile to the current baseline. Outputs include\n",
    "    updated risk metrics, factor exposures, and before/after comparisons.\n",
    "\n",
    "    Input precedence:\n",
    "        1. If `scenario_yaml` contains a top-level `new_weights:` section,\n",
    "           it is treated as a full-replacement portfolio.\n",
    "        2. Otherwise, the function looks for a `delta:` section in the YAML.\n",
    "        3. If neither is found or YAML is missing keys, `shift_dict` is used as a fallback or override.\n",
    "\n",
    "    This function does not return any data. It prints:\n",
    "        • NEW portfolio risk checks (volatility, concentration, variance share)\n",
    "        • NEW factor and industry beta exposures (vs. max allowed betas)\n",
    "        • BEFORE vs AFTER comparison of key risk metrics\n",
    "        • BEFORE vs AFTER comparison of factor beta pass/fail status\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_weights : dict\n",
    "        Current portfolio weights (must sum to 1.0).\n",
    "    config : dict\n",
    "        Parsed contents of `portfolio.yaml`. Must include:\n",
    "        - start_date : str (YYYY-MM-DD)\n",
    "        - end_date   : str (YYYY-MM-DD)\n",
    "    risk_config : dict\n",
    "        Parsed contents of `risk_limits.yaml`, including:\n",
    "        - portfolio_limits\n",
    "        - concentration_limits\n",
    "        - variance_limits\n",
    "        - max_single_factor_loss\n",
    "    proxies : dict\n",
    "        Mapping from tickers to their factor proxies (from `portfolio.yaml`).\n",
    "    shift_dict : dict, optional\n",
    "        Inline dictionary of weight changes to apply. Format: {\"TICKER\": \"+500bp\"}.\n",
    "        Used as fallback if YAML is missing or incomplete.\n",
    "    scenario_yaml : str, optional\n",
    "        Path to a YAML file that contains either `new_weights:` or `delta:`. Overrides shift_dict if populated.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If neither `scenario_yaml` nor `shift_dict` provide any usable changes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary_new, risk_new, beta_new, cmp_risk, cmp_beta\n",
    "    \"\"\"\n",
    "    from helpers_input import parse_delta\n",
    "    from risk_helpers import calc_max_factor_betas\n",
    "    from helpers_display import (\n",
    "        compare_risk_tables,\n",
    "        compare_beta_tables,\n",
    "        _drop_factors,\n",
    "    )\n",
    "    from run_portfolio_risk import (\n",
    "        evaluate_portfolio_risk_limits,\n",
    "        evaluate_portfolio_beta_limits,\n",
    "    )\n",
    "    from portfolio_risk import build_portfolio_view, normalize_weights\n",
    "    from portfolio_optimizer import run_what_if\n",
    "\n",
    "    _fmt_pct = lambda x: f\"{x:.1%}\"\n",
    "    _fmt_beta = {\n",
    "        \"portfolio_beta\":   \"{:.2f}\".format,\n",
    "        \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "        \"buffer\":           \"{:.2f}\".format,\n",
    "        \"pass\":             lambda x: \"PASS\" if x else \"FAIL\",\n",
    "    }\n",
    "\n",
    "    # fallback-safe delta parse\n",
    "    delta, new_weights = parse_delta(yaml_path=scenario_yaml, literal_shift=shift_dict)\n",
    "\n",
    "    # get proxy-level beta caps\n",
    "    _, max_betas_by_proxy = calc_max_factor_betas(\n",
    "        portfolio_yaml=\"portfolio.yaml\",\n",
    "        risk_yaml=\"risk_limits.yaml\",\n",
    "        lookback_years=10,\n",
    "        echo=False\n",
    "    )\n",
    "\n",
    "    # construct summary_new\n",
    "    if new_weights:\n",
    "        new_weights = normalize_weights(new_weights)\n",
    "        summary_new = build_portfolio_view(\n",
    "            new_weights, config[\"start_date\"], config[\"end_date\"],\n",
    "            expected_returns=None, stock_factor_proxies=proxies\n",
    "        )\n",
    "    else:\n",
    "        summary_new, *_ = run_what_if(\n",
    "            base_weights, delta, risk_config,\n",
    "            config[\"start_date\"], config[\"end_date\"], proxies,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "    # construct summary_base\n",
    "    summary_base = build_portfolio_view(\n",
    "        base_weights, config[\"start_date\"], config[\"end_date\"],\n",
    "        expected_returns=None, stock_factor_proxies=proxies\n",
    "    )\n",
    "\n",
    "    # run risk tables\n",
    "    def get_risk(summary):\n",
    "        return evaluate_portfolio_risk_limits(\n",
    "            summary,\n",
    "            risk_config[\"portfolio_limits\"],\n",
    "            risk_config[\"concentration_limits\"],\n",
    "            risk_config[\"variance_limits\"]\n",
    "        )\n",
    "\n",
    "    def get_betas(summary):\n",
    "        from risk_helpers import compute_max_betas\n",
    "        max_betas = compute_max_betas(\n",
    "            proxies, config[\"start_date\"], config[\"end_date\"],\n",
    "            loss_limit_pct=risk_config[\"max_single_factor_loss\"]\n",
    "        )\n",
    "        return evaluate_portfolio_beta_limits(\n",
    "            summary[\"portfolio_factor_betas\"],\n",
    "            max_betas,\n",
    "            proxy_betas=summary[\"industry_variance\"][\"per_industry_group_beta\"],\n",
    "            max_proxy_betas=max_betas_by_proxy\n",
    "        )\n",
    "\n",
    "    risk_new  = get_risk(summary_new)\n",
    "    risk_base = get_risk(summary_base)\n",
    "    beta_new  = get_betas(summary_new)\n",
    "    beta_base = get_betas(summary_base)\n",
    "\n",
    "    # compare diffs\n",
    "    cmp_risk = (\n",
    "        compare_risk_tables(risk_base, risk_new)\n",
    "        .set_index(\"Metric\")\n",
    "        .loc[risk_new[\"Metric\"]]\n",
    "        .reset_index()\n",
    "    )\n",
    "    cmp_beta = compare_beta_tables(beta_base, beta_new)\n",
    "    cmp_beta = _drop_factors(cmp_beta)\n",
    "    cmp_beta = cmp_beta[~cmp_beta.index.str.startswith(\"industry_proxy::\")]\n",
    "\n",
    "    return summary_new, risk_new, beta_new, cmp_risk, cmp_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32c11693-0433-407d-b6bd-d5e7bc8b0210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📐  NEW Portfolio – Risk Checks\n",
      "\n",
      "            Metric Actual Limit  Pass\n",
      "        Volatility  25.2% 40.0%  True\n",
      "        Max Weight  25.0% 40.0%  True\n",
      "      Factor Var %  55.1% 30.0% False\n",
      "      Market Var %  34.5% 30.0% False\n",
      "Max Industry Var %  38.0% 30.0% False\n",
      "\n",
      "📊  NEW Aggregate Factor Exposures\n",
      "\n",
      "         portfolio_beta max_allowed_beta  pass buffer\n",
      "market             0.93             0.67  FAIL  -0.27\n",
      "momentum          -0.21             0.79  PASS   0.58\n",
      "value             -1.49             0.55  FAIL  -0.94\n",
      "\n",
      "📊  NEW Industry Exposure Checks\n",
      "\n",
      "     portfolio_beta max_allowed_beta  pass buffer\n",
      "KCE            0.23             0.56  PASS   0.33\n",
      "SOXX           0.32             0.56  PASS   0.23\n",
      "XSW            0.14             0.59  PASS   0.45\n",
      "IXC           -0.00             0.33  PASS   0.33\n",
      "AGG            0.00             2.30  PASS   2.30\n",
      "\n",
      "📐  Risk Limits — Before vs After\n",
      "\n",
      "            Metric   Old   New     Δ Limit  Old Pass  New Pass\n",
      "        Volatility 21.6% 25.2%  3.6% 40.0%      True      True\n",
      "        Max Weight 28.0% 25.0% -3.0% 40.0%      True      True\n",
      "      Factor Var % 40.5% 55.1% 14.7% 30.0%     False     False\n",
      "      Market Var % 27.0% 34.5%  7.6% 30.0%      True     False\n",
      "Max Industry Var % 21.6% 38.0% 16.4% 30.0%      True     False\n",
      "\n",
      "📊  Factor Betas — Before vs After\n",
      "\n",
      "           Old   New     Δ Max Beta Old Pass New Pass\n",
      "market    0.83  0.93  0.10     0.67     FAIL     FAIL\n",
      "momentum -0.21 -0.21  0.00     0.79     PASS     PASS\n",
      "value    -1.23 -1.49 -0.26     0.55     FAIL     FAIL\n"
     ]
    }
   ],
   "source": [
    "# === What-If Risk Calculations using Shift Inputs OR YAML file ===\n",
    "\n",
    "summary, risk_new, beta_new, cmp_risk, cmp_beta = run_what_if_scenario(\n",
    "    base_weights  = weights,\n",
    "    config        = config,\n",
    "    risk_config   = risk_config,\n",
    "    proxies       = stock_factor_proxies,\n",
    "    scenario_yaml = \"what_if_portfolio.yaml\",\n",
    "    shift_dict    = {\"TW\": \"+500bp\", \"PCTY\": \"-200bp\"},\n",
    ")\n",
    "\n",
    "# split beta table between factors and industry\n",
    "beta_f_new = beta_new[~beta_new.index.str.startswith(\"industry_proxy::\")]\n",
    "beta_p_new = beta_new[ beta_new.index.str.startswith(\"industry_proxy::\")].copy()\n",
    "beta_p_new.index = beta_p_new.index.str.replace(\"industry_proxy::\", \"\")\n",
    "\n",
    "# Print report\n",
    "print_what_if_report(\n",
    "    summary_new=summary,\n",
    "    risk_new=risk_new,\n",
    "    beta_f_new=beta_f_new,\n",
    "    beta_p_new=beta_p_new,\n",
    "    cmp_risk=cmp_risk,\n",
    "    cmp_beta=cmp_beta,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25e0abcc-e9b9-4f8a-a5f4-87e19a7ec953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: portfolio_optimizer.py ──────────────────────────────────\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "#  Minimum variance portfolio helper\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "def run_min_var_optimiser(\n",
    "    weights: Dict[str, float],\n",
    "    risk_cfg: Dict[str, Any],\n",
    "    start_date: str,\n",
    "    end_date:   str,\n",
    "    proxies: Dict[str, Dict[str, Any]],\n",
    "    echo: bool = True,\n",
    ") -> Tuple[Dict[str, float], pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Minimum-variance portfolio under firm-wide limits\n",
    "    ------------------------------------------------\n",
    "\n",
    "    Objective\n",
    "    ---------\n",
    "    **min wᵀ Σ w**  \n",
    "    Σ = monthly covariance estimated over *start_date*→*end_date*.\n",
    "\n",
    "    Constraints\n",
    "    -----------\n",
    "    1. ∑ wᵢ = 1  (fully invested)  \n",
    "    2. wᵢ ≥ 0  (long-only; see lower-level solver for shorts)  \n",
    "    3. |wᵢ| ≤ single-name cap from *risk_cfg*  \n",
    "    4. √12 · √(wᵀ Σ w) ≤ σ_cap  \n",
    "    5. |β_port,f| ≤ dynamic β_max,f (via `compute_max_betas`)\n",
    "\n",
    "    Convex QP solved with CVXPY + ECOS.  \n",
    "    Returns only the optimised weights; use `evaluate_weights(...)`\n",
    "    if you need PASS/FAIL tables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    weights : {ticker: weight} (sums ≈ 1)  \n",
    "    risk_cfg : parsed *risk_limits.yaml*  \n",
    "    start_date, end_date : YYYY-MM-DD window for Σ & betas  \n",
    "    proxies : `stock_factor_proxies` from portfolio YAML  \n",
    "    echo : print weights ≥ 0.01 % when True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float] – optimised weights (summing to 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ---------- solve ----------------------------------------------------\n",
    "    new_w = solve_min_variance_with_risk_limits(\n",
    "        weights,\n",
    "        risk_cfg,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        proxies,\n",
    "    )\n",
    "\n",
    "    # 2. ---------- optional console output ---------------------------------\n",
    "    if echo:\n",
    "        # 3a. pretty-print weights ≥ 0.01 %\n",
    "        print(\"\\n🎯  Target minimum-variance weights:\\n\")\n",
    "        (pd.Series(new_w, name=\"Weight\")\n",
    "           .loc[lambda s: s.abs() > 0.0001]\n",
    "           .sort_values(ascending=False)\n",
    "           .apply(lambda x: f\"{x:.2%}\")\n",
    "           .pipe(lambda s: print(s.to_string()))\n",
    "        )\n",
    "\n",
    "    return new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "672f9dda-034a-4500-bacb-c4906f279484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: portfolio_optimizer.py ──────────────────────────────────\n",
    "\n",
    "def run_min_var(\n",
    "    *,\n",
    "    base_weights: Dict[str, float],\n",
    "    config: Dict[str, Any],\n",
    "    risk_config: Dict[str, Any],\n",
    "    proxies: Dict[str, Any],\n",
    ") -> Tuple[Dict[str, float], pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Runs minimum-variance optimisation under risk constraints.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple of:\n",
    "        - optimised weights (dict)\n",
    "        - risk check DataFrame\n",
    "        - factor beta check DataFrame\n",
    "    \"\"\"\n",
    "    from portfolio_optimizer import run_min_var_optimiser, evaluate_weights\n",
    "\n",
    "    w_opt = run_min_var_optimiser(\n",
    "        weights    = base_weights,\n",
    "        risk_cfg   = risk_config,\n",
    "        start_date = config[\"start_date\"],\n",
    "        end_date   = config[\"end_date\"],\n",
    "        proxies    = proxies,\n",
    "        echo       = False,\n",
    "    )\n",
    "\n",
    "    risk_tbl, beta_tbl = evaluate_weights(\n",
    "        w_opt, risk_config,\n",
    "        config[\"start_date\"], config[\"end_date\"],\n",
    "        proxies\n",
    "    )\n",
    "    return w_opt, risk_tbl, beta_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d672fcb-faa3-429d-a69d-34912627490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── File: portfolio_optimizer.py ──────────────────────────────────\n",
    "\n",
    "def print_min_var_report(\n",
    "    *,\n",
    "    weights: Dict[str, float],\n",
    "    risk_tbl: pd.DataFrame,\n",
    "    beta_tbl: pd.DataFrame,\n",
    "    echo_weights: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Prints risk and factor exposure tables for a min-var portfolio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    weights : dict\n",
    "        Optimised portfolio weights (sum to 1).\n",
    "    risk_tbl : pd.DataFrame\n",
    "        Output from evaluate_portfolio_risk_limits.\n",
    "    beta_tbl : pd.DataFrame\n",
    "        Output from evaluate_portfolio_beta_limits.\n",
    "    echo_weights : bool\n",
    "        If True, prints weights ≥ 0.01%.\n",
    "    \"\"\"\n",
    "    from helpers_display import _drop_factors\n",
    "\n",
    "    if echo_weights:\n",
    "        print(\"\\n🎯  Target minimum-variance weights\\n\")\n",
    "        for t, w in sorted(weights.items(), key=lambda kv: -abs(kv[1])):\n",
    "            if abs(w) >= 0.0001:\n",
    "                print(f\"{t:<10} : {w:.2%}\")\n",
    "\n",
    "    print(\"\\n📐  Optimised Portfolio – Risk Checks\\n\")\n",
    "    pct = lambda x: f\"{x:.2%}\"\n",
    "    print(risk_tbl.to_string(index=False, formatters={\"Actual\": pct, \"Limit\": pct}))\n",
    "\n",
    "    print(\"\\n📊  Optimised Portfolio – Factor Betas\\n\")\n",
    "    beta_tbl = _drop_factors(beta_tbl)\n",
    "    print(beta_tbl.to_string(formatters={\n",
    "        \"Beta\":      \"{:.2f}\".format,\n",
    "        \"Max Beta\":  \"{:.2f}\".format,\n",
    "        \"Buffer\":    \"{:.2f}\".format,\n",
    "        \"Pass\":      lambda x: \"PASS\" if x else \"FAIL\",\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f88ab50-2145-4c08-98dd-c958bc5f15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯  Target minimum-variance weights\n",
      "\n",
      "SHV        : 40.00%\n",
      "AT.L       : 26.34%\n",
      "PCTY       : 17.64%\n",
      "MSCI       : 16.02%\n",
      "\n",
      "📐  Optimised Portfolio – Risk Checks\n",
      "\n",
      "            Metric Actual  Limit  Pass\n",
      "        Volatility 11.26% 40.00%  True\n",
      "        Max Weight 40.00% 40.00%  True\n",
      "      Factor Var % 23.88% 30.00%  True\n",
      "      Market Var % 19.49% 30.00%  True\n",
      "Max Industry Var % 13.79% 30.00%  True\n",
      "\n",
      "📊  Optimised Portfolio – Factor Betas\n",
      "\n",
      "          portfolio_beta  max_allowed_beta  pass    buffer\n",
      "factor                                                    \n",
      "market          0.428805          0.667873  True  0.239068\n",
      "momentum       -0.058808          0.788519  True  0.729711\n",
      "value          -0.426404          0.551434  True  0.125030\n"
     ]
    }
   ],
   "source": [
    "# === Optimizer: Lowest Variance Weights within Risk Limits ===\n",
    "\n",
    "w_min, risk_tbl, beta_tbl = run_min_var(\n",
    "    base_weights = weights,\n",
    "    config       = config,\n",
    "    risk_config  = risk_config,\n",
    "    proxies      = stock_factor_proxies,\n",
    ")\n",
    "\n",
    "print_min_var_report(\n",
    "    weights     = w_min,\n",
    "    risk_tbl    = risk_tbl,\n",
    "    beta_tbl    = beta_tbl,\n",
    "    echo_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9053731-c817-4ce5-b6e8-95f314c5362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: portfolio_optimizer.py\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Max-return portfolio subject to risk limits\n",
    "#   • Aggregate β caps: market, momentum, value\n",
    "#   • Per-proxy β caps: one for each industry ETF / peer basket\n",
    "# ---------------------------------------------------------------------\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Union, List\n",
    "\n",
    "def solve_max_return_with_risk_limits(\n",
    "    init_weights: Dict[str, float],\n",
    "    risk_cfg: Dict[str, Dict[str, float]],\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    stock_factor_proxies: Dict[str, Dict[str, Union[str, List[str]]]],\n",
    "    expected_returns: Dict[str, float],\n",
    "    allow_short: bool = False,\n",
    ") -> Dict[str, float]:\n",
    "    r\"\"\"Return the weight vector *w* that maximises expected portfolio return\n",
    "    subject to **all** firm-wide risk limits.\n",
    "\n",
    "    The problem is formulated as a convex quadratic programme (QP)::\n",
    "\n",
    "        maximise   \\sum_i w_i * µ_i\n",
    "        subject to  w  \\in  ℝⁿ\n",
    "                    \\sum_i w_i                = 1                 (fully-invested)\n",
    "                    0 ≤ w_i ≤ w_cap           ∀ i  (long-only + concentration cap)\n",
    "                    σ_p(w)                    ≤ σ_cap             (annual vol cap)\n",
    "                    |β_port,f(w)|             ≤ β_cap,f           f ∈ {market,momentum,value}\n",
    "                    |β_port,proxy(w)|         ≤ β_cap,proxy       ∀ industry proxies\n",
    "\n",
    "    where ::\n",
    "\n",
    "        µ_i       expected annual return of ticker *i* (``expected_returns``)\n",
    "        σ_p(w)    √(12 * wᵀ Σ_m w)   – annualised portfolio volatility\n",
    "        β_port,f  ∑_i w_i β_{i,f}    – portfolio beta to factor *f*\n",
    "        β_port,proxy  constructed similarly using each industry ETF / peer basket\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    init_weights\n",
    "        Current portfolio weights (need not sum to 1 – they’ll be re-normalised).\n",
    "    risk_cfg\n",
    "        Parsed ``risk_limits.yaml`` containing the three sub-dicts:\n",
    "        ``portfolio_limits``, ``concentration_limits``, ``variance_limits`` and\n",
    "        the scalar ``max_single_factor_loss``.\n",
    "    start_date, end_date\n",
    "        Historical window (YYYY-MM-DD) used for covariance and beta estimation.\n",
    "    stock_factor_proxies\n",
    "        Mapping ``{ticker: {market: 'SPY', momentum: 'MTUM', value: 'IWD',\n",
    "        industry: 'SOXX', …}}``.  Only *industry* proxies are used for the\n",
    "        per-proxy caps, but the full dict is passed for completeness.\n",
    "    expected_returns\n",
    "        Dict of expected **annual** returns (in decimals, eg 0.12 = 12 %).\n",
    "        Missing tickers default to 0.\n",
    "    allow_short\n",
    "        If ``True`` the lower-bound on *w* is removed (long/short optimisation).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        Optimised weight vector summing exactly to 1.  Keys match the order of\n",
    "        ``init_weights``.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        * If *expected_returns* is empty / all zeros.\n",
    "        * If the optimisation is infeasible under the supplied risk limits.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    *Factor & proxy beta caps*\n",
    "        The aggregate caps for **market**, **momentum** and **value** factors are\n",
    "        taken from :pyfunc:`risk_helpers.compute_max_betas`.  Per-industry caps\n",
    "        are derived by dividing the firm-wide *max_single_factor_loss* by each\n",
    "        proxy’s historical worst 1-month return (see\n",
    "        :pyfunc:`risk_helpers.get_worst_monthly_factor_losses`).\n",
    "    \"\"\"\n",
    "    from portfolio_risk import build_portfolio_view          # reuse: get Σ & betas\n",
    "    from risk_helpers   import compute_max_betas, get_worst_monthly_factor_losses\n",
    "\n",
    "    # ---------- 0. Pre-compute Σ (monthly) & stock-level betas -------------\n",
    "    tickers = list(init_weights)\n",
    "    view = build_portfolio_view(\n",
    "        init_weights, start_date, end_date,\n",
    "        expected_returns=None,\n",
    "        stock_factor_proxies=stock_factor_proxies,\n",
    "    )\n",
    "\n",
    "    Σ_m = view[\"covariance_matrix\"].loc[tickers, tickers].values          # Σ (monthly)\n",
    "    β_tbl = view[\"df_stock_betas\"].fillna(0.0).loc[tickers]               # n × factors\n",
    "\n",
    "    μ = np.array([expected_returns.get(t, 0.0) for t in tickers])\n",
    "    if np.allclose(μ, 0):\n",
    "        raise ValueError(\"expected_returns is empty or zeros – nothing to maximise\")\n",
    "\n",
    "    # ---------- 1. Build β caps -------------------------------------------\n",
    "    # 1a) Aggregate factors\n",
    "    all_caps = compute_max_betas(\n",
    "        stock_factor_proxies,\n",
    "        start_date, end_date,\n",
    "        loss_limit_pct=risk_cfg[\"max_single_factor_loss\"],\n",
    "    )\n",
    "    agg_caps = {k: all_caps[k] for k in (\"market\", \"momentum\", \"value\")}\n",
    "\n",
    "    # 1b) Per-industry proxy caps\n",
    "    loss_lim = risk_cfg[\"max_single_factor_loss\"]            # e.g. -0.10\n",
    "    worst_proxy_loss = get_worst_monthly_factor_losses(\n",
    "        stock_factor_proxies, start_date, end_date\n",
    "    )\n",
    "    proxy_caps = {\n",
    "        proxy: (np.inf if loss >= 0 else loss_lim / loss)\n",
    "        for proxy, loss in worst_proxy_loss.items()\n",
    "    }\n",
    "\n",
    "    # Build coefficient vectors c_proxy (length n) such that\n",
    "    #   β_port,proxy = Σ_i c_proxy[i] · w_i\n",
    "    coeff_proxy: Dict[str, np.ndarray] = {}\n",
    "    for proxy in proxy_caps:\n",
    "        coeff = []\n",
    "        for t in tickers:\n",
    "            this_proxy = stock_factor_proxies[t].get(\"industry\")\n",
    "            coeff.append(β_tbl.loc[t, \"industry\"] if this_proxy == proxy else 0.0)\n",
    "        coeff_proxy[proxy] = np.array(coeff)\n",
    "\n",
    "    # ---------- 2. CVXPY variables & objective ----------------------------\n",
    "    w = cp.Variable(len(tickers))\n",
    "    objective = cp.Maximize(μ @ w)\n",
    "\n",
    "    # ---------- 3. Constraints -------------------------------------------\n",
    "    cons = [cp.sum(w) == 1]                               # fully invested\n",
    "    if not allow_short:\n",
    "        cons += [w >= 0]\n",
    "\n",
    "    # single-name cap\n",
    "    cons += [w <= risk_cfg[\"concentration_limits\"][\"max_single_stock_weight\"]]\n",
    "\n",
    "    # portfolio vol cap (monthly Σ → annual σ)\n",
    "    σ_cap = risk_cfg[\"portfolio_limits\"][\"max_volatility\"]\n",
    "    cons += [cp.sqrt(cp.quad_form(w, Σ_m)) * np.sqrt(12) <= σ_cap]\n",
    "\n",
    "    # 3a) Aggregate β caps\n",
    "    for fac, cap in agg_caps.items():\n",
    "        if fac in β_tbl.columns:\n",
    "            cons += [cp.abs(β_tbl[fac].values @ w) <= cap]\n",
    "\n",
    "    # 3b) Per-proxy β caps\n",
    "    for proxy, cap in proxy_caps.items():\n",
    "        cons += [cp.abs(coeff_proxy[proxy] @ w) <= cap]\n",
    "\n",
    "    # ---------- 4. Solve --------------------------------------------------\n",
    "    prob = cp.Problem(objective, cons)\n",
    "    prob.solve(solver=cp.ECOS, qcp=True, verbose=False)\n",
    "\n",
    "    if prob.status not in (\"optimal\", \"optimal_inaccurate\"):\n",
    "        raise ValueError(f\"Solver status = {prob.status} (infeasible)\")\n",
    "\n",
    "    return {t: float(w.value[i]) for i, t in enumerate(tickers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27eb9b46-4ed8-4b89-9ebe-77cc57e94d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: portfolio_optimizer.py\n",
    "\n",
    "def run_max_return_portfolio(\n",
    "    *,\n",
    "    weights: Dict[str, float],\n",
    "    config: Dict[str, Any],\n",
    "    risk_config: Dict[str, Any],\n",
    "    proxies: Dict[str, Any],\n",
    ") -> Tuple[Dict[str, float], Dict[str, Any], pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Runs max-return optimisation under risk constraints and returns full output.\n",
    "\n",
    "    Returns:\n",
    "        - Optimised weights (dict)\n",
    "        - Portfolio summary (from build_portfolio_view)\n",
    "        - Risk check table\n",
    "        - Factor-level beta check table\n",
    "        - Proxy-level beta check table\n",
    "    \"\"\"\n",
    "    from portfolio_optimizer import solve_max_return_with_risk_limits\n",
    "    from portfolio_risk import build_portfolio_view\n",
    "    from run_portfolio_risk import (\n",
    "        evaluate_portfolio_beta_limits,\n",
    "        evaluate_portfolio_risk_limits,\n",
    "    )\n",
    "    from risk_helpers import compute_max_betas, calc_max_factor_betas\n",
    "\n",
    "    # 1. Optimise weights\n",
    "    w_opt = solve_max_return_with_risk_limits(\n",
    "        init_weights         = weights,\n",
    "        risk_cfg             = risk_config,\n",
    "        start_date           = config[\"start_date\"],\n",
    "        end_date             = config[\"end_date\"],\n",
    "        stock_factor_proxies = proxies,\n",
    "        expected_returns     = config[\"expected_returns\"],\n",
    "    )\n",
    "\n",
    "    # 2. Build full summary\n",
    "    summary = build_portfolio_view(\n",
    "        w_opt,\n",
    "        start_date           = config[\"start_date\"],\n",
    "        end_date             = config[\"end_date\"],\n",
    "        expected_returns     = None,\n",
    "        stock_factor_proxies = proxies,\n",
    "    )\n",
    "\n",
    "    # 3. Run risk checks\n",
    "    risk_tbl = evaluate_portfolio_risk_limits(\n",
    "        summary,\n",
    "        risk_config[\"portfolio_limits\"],\n",
    "        risk_config[\"concentration_limits\"],\n",
    "        risk_config[\"variance_limits\"],\n",
    "    )\n",
    "\n",
    "    # 4. Compute β caps\n",
    "    max_betas = compute_max_betas(\n",
    "        proxies,\n",
    "        config[\"start_date\"],\n",
    "        config[\"end_date\"],\n",
    "        loss_limit_pct = risk_config[\"max_single_factor_loss\"],\n",
    "    )\n",
    "    _, max_betas_by_proxy = calc_max_factor_betas(\n",
    "        portfolio_yaml = \"portfolio.yaml\",\n",
    "        risk_yaml      = \"risk_limits.yaml\",\n",
    "        lookback_years = 10,\n",
    "        echo = False,\n",
    "    )\n",
    "\n",
    "    # 5. Run beta check with proxy caps\n",
    "    df_beta_chk = evaluate_portfolio_beta_limits(\n",
    "        summary[\"portfolio_factor_betas\"],\n",
    "        max_betas,\n",
    "        proxy_betas     = summary[\"industry_variance\"][\"per_industry_group_beta\"],\n",
    "        max_proxy_betas = max_betas_by_proxy,\n",
    "    )\n",
    "\n",
    "    # 6. Split factor vs proxy\n",
    "    df_factors = df_beta_chk[~df_beta_chk.index.str.startswith(\"industry_proxy::\")]\n",
    "    df_proxies = df_beta_chk[df_beta_chk.index.str.startswith(\"industry_proxy::\")].copy()\n",
    "    df_proxies.index = df_proxies.index.str.replace(\"industry_proxy::\", \"\")\n",
    "\n",
    "    return w_opt, summary, risk_tbl, df_factors, df_proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6a8a09a-148d-40de-b0a1-fc2772c6143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: portfolio_optimizer.py\n",
    "\n",
    "def print_max_return_report(\n",
    "    *,\n",
    "    weights: Dict[str, float],\n",
    "    risk_tbl: pd.DataFrame,\n",
    "    df_factors: pd.DataFrame,\n",
    "    df_proxies: pd.DataFrame,\n",
    "    echo_weights: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Prints weights and all risk / beta check tables for max-return portfolio.\n",
    "    \"\"\"\n",
    "    if echo_weights:\n",
    "        print(\"\\n🎯  Target max-return, risk-constrained weights\\n\")\n",
    "        for k, v in sorted(weights.items(), key=lambda kv: -abs(kv[1])):\n",
    "            if abs(v) > 1e-4:\n",
    "                print(f\"{k:<10} : {v:.2%}\")\n",
    "\n",
    "    print(\"\\n📐  Max-return Portfolio – Risk Checks\\n\")\n",
    "    pct = lambda x: f\"{x:.2%}\"\n",
    "    print(risk_tbl.to_string(index=False, formatters={\"Actual\": pct, \"Limit\": pct}))\n",
    "\n",
    "    print(\"\\n📊  Aggregate Factor Exposures\\n\")\n",
    "    fmt = {\n",
    "        \"portfolio_beta\":   \"{:.2f}\".format,\n",
    "        \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "        \"buffer\":           \"{:.2f}\".format,\n",
    "        \"pass\":             lambda x: \"PASS\" if x else \"FAIL\",\n",
    "    }\n",
    "    print(df_factors.to_string(index_names=False, formatters=fmt))\n",
    "\n",
    "    if not df_proxies.empty:\n",
    "        print(\"\\n📊  Industry Exposure Checks\\n\")\n",
    "        print(df_proxies.to_string(index_names=False, formatters=fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9db1e72a-f5df-47e9-bbe1-7c483d080044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯  Target max-return, risk-constrained weights\n",
      "\n",
      "AT.L       : 40.00%\n",
      "PCTY       : 40.00%\n",
      "MSCI       : 10.53%\n",
      "SHV        : 5.18%\n",
      "TW         : 4.28%\n",
      "\n",
      "📐  Max-return Portfolio – Risk Checks\n",
      "\n",
      "            Metric Actual  Limit  Pass\n",
      "        Volatility 18.40% 40.00%  True\n",
      "        Max Weight 40.00% 40.00%  True\n",
      "      Factor Var % 23.28% 30.00%  True\n",
      "      Market Var % 19.33% 30.00%  True\n",
      "Max Industry Var % 26.85% 30.00%  True\n",
      "\n",
      "📊  Aggregate Factor Exposures\n",
      "\n",
      "         portfolio_beta max_allowed_beta  pass buffer\n",
      "market             0.67             0.67  PASS   0.00\n",
      "momentum           0.00             0.79  PASS   0.79\n",
      "value             -0.55             0.55  PASS   0.00\n",
      "\n",
      "📊  Industry Exposure Checks\n",
      "\n",
      "     portfolio_beta max_allowed_beta  pass buffer\n",
      "KCE            0.12             0.56  PASS   0.44\n",
      "SOXX           0.00             0.56  PASS   0.56\n",
      "XSW            0.36             0.59  PASS   0.22\n",
      "IXC           -0.01             0.33  PASS   0.32\n",
      "AGG            0.00             2.30  PASS   2.30\n"
     ]
    }
   ],
   "source": [
    "# === Optimizer: Highest Return Weights within Risk Limits ===\n",
    "\n",
    "w_max, summary, risk_tbl, beta_f, beta_p = run_max_return_portfolio(\n",
    "    weights      = weights,\n",
    "    config       = config,\n",
    "    risk_config  = risk_config,\n",
    "    proxies      = stock_factor_proxies,\n",
    ")\n",
    "\n",
    "print_max_return_report(\n",
    "    weights     = w_max,\n",
    "    risk_tbl    = risk_tbl,\n",
    "    df_factors  = beta_f,\n",
    "    df_proxies  = beta_p,\n",
    "    echo_weights = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255cf17f-819e-42d9-87c2-1e6eccaa7d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
