{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fa75b-2d2d-4dba-b028-f1cca807c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Test Block: Fixed Risk Calculations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Define exact window\n",
    "start = \"2019-04-30\"\n",
    "end   = \"2024-03-31\"\n",
    "\n",
    "# Fetch and compute stock returns\n",
    "stock_prices  = fetch_monthly_close(\"PCTY\", start_date=start, end_date=end)\n",
    "stock_returns = calc_monthly_returns(stock_prices)\n",
    "\n",
    "# Helper: align any factor return series to stock_returns\n",
    "def stable_align(series: pd.Series) -> pd.Series:\n",
    "    return series.loc[stock_returns.index.intersection(series.index)]\n",
    "\n",
    "# Fetch and persist factor return series over the same window\n",
    "spy_prices      = fetch_monthly_close(\"SPY\", start_date=start, end_date=end)\n",
    "spy_returns     = calc_monthly_returns(spy_prices)\n",
    "\n",
    "momentum_raw    = fetch_excess_return(\n",
    "    \"MTUM\", \"SPY\", start_date=start, end_date=end\n",
    ")\n",
    "value_raw       = fetch_excess_return(\n",
    "    \"IWD\",  \"SPY\", start_date=start, end_date=end\n",
    ")\n",
    "industry_raw    = fetch_peer_median_monthly_returns(\n",
    "    [\"XSW\"], start_date=start, end_date=end\n",
    ")\n",
    "subindustry_raw = fetch_peer_median_monthly_returns(\n",
    "    [\"PAYC\",\"PYCR\",\"CDAY\",\"ADP\",\"PAYX\",\"WDAY\" ], start_date=start, end_date=end\n",
    ")\n",
    "\n",
    "# Align all series to stock_returns\n",
    "market_returns    = stable_align(spy_returns)\n",
    "momentum_returns  = stable_align(momentum_raw)\n",
    "value_returns     = stable_align(value_raw)\n",
    "industry_returns  = stable_align(industry_raw)\n",
    "subind_returns    = stable_align(subindustry_raw)\n",
    "\n",
    "# Build DataFrame for base market regression\n",
    "df_ret = pd.DataFrame({\n",
    "    \"stock\":  stock_returns,\n",
    "    \"market\": market_returns\n",
    "}).dropna()\n",
    "\n",
    "# Run and print base risk stats\n",
    "print(\"n_obs:\", len(df_ret))\n",
    "print(\"Volatility Metrics:\", compute_volatility(df_ret[\"stock\"]))\n",
    "print(\"Risk Metrics:\",       compute_regression_metrics(df_ret))\n",
    "\n",
    "# Build factor dictionary and run single-factor regressions\n",
    "factor_dict = {\n",
    "    \"market\":      market_returns,\n",
    "    \"momentum\":    momentum_returns,\n",
    "    \"value\":       value_returns,\n",
    "    \"industry\":    industry_returns,\n",
    "    \"subindustry\": subind_returns\n",
    "}\n",
    "\n",
    "df_factors_summary = compute_factor_metrics(stock_returns, factor_dict)\n",
    "print(\"Single-Factor Regression Summary:\\n\", df_factors_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b2358-6ec3-4a63-b6c4-f08776a5ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define window, weights, expected returns, and per-stock factor proxies\n",
    "start_date = \"2019-05-31\"\n",
    "end_date   = \"2024-03-31\"\n",
    "\n",
    "#weights    = {\"TW\":0.15, \"MSCI\":0.15, \"NVDA\":0.17, \"PCTY\":0.15, \"AT.L\":0.28}\n",
    "weights=parsed[\"weights\"]\n",
    "\n",
    "expected_returns = {\"TW\":0.15,\"MSCI\":0.16,\"NVDA\":0.20,\"PCTY\":0.17,\"AT.L\":0.25,\"SHV\":0}\n",
    "\n",
    "# stock_factor_proxies maps each ticker to the ETFs/peerâ€lists you want to use:\n",
    "stock_factor_proxies = {\n",
    "    \"TW\":   {\"market\":\"SPY\",\"momentum\":\"MTUM\",\"value\":\"IWD\",\"industry\":\"KCE\",\"subindustry\":[\"TW\",\"MSCI\",\"NVDA\"]},\n",
    "    \"MSCI\": {\"market\":\"SPY\",\"momentum\":\"MTUM\",\"value\":\"IWD\",\"industry\":\"KCE\",\"subindustry\":[\"TW\",\"MSCI\",\"NVDA\"]},\n",
    "    \"NVDA\": {\"market\":\"SPY\",\"momentum\":\"MTUM\",\"value\":\"IWD\",\"industry\":\"SOXX\",\"subindustry\":[\"SOXX\",\"XSW\",\"IXC\"]},\n",
    "    \"PCTY\": {\"market\":\"SPY\",\"momentum\":\"MTUM\",\"value\":\"IWD\",\"industry\":\"XSW\",\"subindustry\":[\"PAYC\",\"CDAY\",\"ADP\"]},\n",
    "    \"AT.L\": {\"market\":\"ACWX\",\"momentum\":\"IMTM\",\"value\":\"IVLU\",\"industry\":\"IXC\",\"subindustry\":[\"IXC\"]},\n",
    "    \"SHV\": {\"market\":\"SPY\",\"momentum\":\"IMTM\",\"value\":\"IWD\",\"industry\":\"AGG\",\"subindustry\":[\"SHY\"]}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8c836-2cae-41b7-8a92-34cf9dee0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "# Portfolio inputs\n",
    "\n",
    "# 1) Define window, weights, expected returns, and per-stock factor proxies\n",
    "start_date = \"2019-05-31\"\n",
    "end_date   = \"2024-03-31\"\n",
    "\n",
    "portfolio_input = {\n",
    "    \"TW\":   {\"weight\": 0.15},\n",
    "    \"MSCI\": {\"weight\": 0.15},\n",
    "    \"NVDA\": {\"weight\": 0.17},\n",
    "    \"PCTY\": {\"weight\": 0.15},\n",
    "    \"AT.L\": {\"weight\":0.28},\n",
    "    \"SHV\": {\"weight\":0.10} #proxy for cash\n",
    "}\n",
    "\n",
    "#portfolio_input = {\n",
    "#    \"TW\":   {\"shares\": 100},\n",
    "#    \"MSCI\": {\"dollars\": 15000},\n",
    "#    \"NVDA\": {\"shares\": 50},\n",
    "#    \"PCTY\": {\"dollars\": 10000},\n",
    "#    \"AT.L\": {\"shares\": 300}\n",
    "#}\n",
    "\n",
    "parsed = standardize_portfolio_input(portfolio_input, latest_price)\n",
    "\n",
    "#weights    = {\"TW\":0.15, \"MSCI\":0.15, \"NVDA\":0.17, \"PCTY\":0.15, \"AT.L\":0.28}\n",
    "weights=parsed[\"weights\"]\n",
    "\n",
    "print(\"=== Normalized Weights ===\")\n",
    "print(parsed[\"weights\"])\n",
    "\n",
    "print(\"\\n=== Dollar Exposure ===\")\n",
    "print(parsed[\"dollar_exposure\"])\n",
    "\n",
    "print(\"\\n=== Total Portfolio Value ===\")\n",
    "print(parsed[\"total_value\"])\n",
    "\n",
    "print(\"\\n=== Net Exposure (sum of weights) ===\")\n",
    "print(parsed[\"net_exposure\"])\n",
    "\n",
    "print(\"\\n=== Gross Exposure (sum of abs(weights)) ===\")\n",
    "print(parsed[\"gross_exposure\"])\n",
    "\n",
    "print(\"\\n=== Leverage (gross / net) ===\")\n",
    "print(parsed[\"leverage\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095bbeb-6079-45e9-9d98-2d4e8fe30ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "# YAML File Loader for Expectations and Factor Proxies\n",
    "import yaml\n",
    "from pprint import pprint  # cleaner multiline dict printing\n",
    "\n",
    "# Load YAML config\n",
    "with open(\"portfolio.yaml\", \"r\") as f:\n",
    "    expectations = yaml.safe_load(f)\n",
    "\n",
    "expected_returns = expectations[\"expected_returns\"]\n",
    "stock_factor_proxies = expectations[\"stock_factor_proxies\"]\n",
    "\n",
    "print(\"=== Expected Returns ===\")\n",
    "pprint(expected_returns)\n",
    "\n",
    "print(\"\\n=== Stock Factor Proxies ===\")\n",
    "for ticker, proxies in stock_factor_proxies.items():\n",
    "    print(f\"\\nâ†’ {ticker}\")\n",
    "    pprint(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c506bf-caf0-4007-9bdd-fe9a86dcef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "# Load YAML config\n",
    "with open(\"portfolio.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract inputs\n",
    "start_date            = config[\"start_date\"]\n",
    "end_date              = config[\"end_date\"]\n",
    "portfolio_input       = config[\"portfolio_input\"]\n",
    "expected_returns      = config[\"expected_returns\"]\n",
    "stock_factor_proxies  = config[\"stock_factor_proxies\"]\n",
    "\n",
    "# Standardize inputs\n",
    "parsed  = standardize_portfolio_input(portfolio_input, latest_price)\n",
    "weights = parsed[\"weights\"]\n",
    "\n",
    "# Output\n",
    "print(\"=== Normalized Weights ===\")\n",
    "print(weights)\n",
    "\n",
    "print(\"\\n=== Dollar Exposure ===\")\n",
    "print(parsed[\"dollar_exposure\"])\n",
    "\n",
    "print(\"\\n=== Total Portfolio Value ===\")\n",
    "print(parsed[\"total_value\"])\n",
    "\n",
    "print(\"\\n=== Net Exposure (sum of weights) ===\")\n",
    "print(parsed[\"net_exposure\"])\n",
    "\n",
    "print(\"\\n=== Gross Exposure (sum of abs(weights)) ===\")\n",
    "print(parsed[\"gross_exposure\"])\n",
    "\n",
    "print(\"\\n=== Leverage (gross / net) ===\")\n",
    "print(parsed[\"leverage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496b0bd-4ddf-46dd-b033-723e443c7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "# â”€â”€â”€ Run Portfolio View â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 2) Call the high-level summary builder\n",
    "summary = build_portfolio_view(\n",
    "    weights,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    expected_returns=expected_returns,\n",
    "    stock_factor_proxies=stock_factor_proxies\n",
    ")\n",
    "\n",
    "# 3) Unpack and print what you need\n",
    "print(\"=== Target Allocations ===\")\n",
    "print(summary[\"allocations\"], \"\\n\")\n",
    "\n",
    "print(\"=== Portfolio Returns (head) ===\")\n",
    "print(summary[\"portfolio_returns\"].head(), \"\\n\")\n",
    "\n",
    "print(\"=== Covariance Matrix ===\")\n",
    "print(summary[\"covariance_matrix\"], \"\\n\")\n",
    "\n",
    "print(\"=== Correlation Matrix ===\")\n",
    "print(summary[\"correlation_matrix\"], \"\\n\")\n",
    "\n",
    "print(f\"Monthly Volatility:  {summary['volatility_monthly']:.4%}\")\n",
    "print(f\"Annual Volatility:   {summary['volatility_annual']:.4%}\\n\")\n",
    "\n",
    "print(\"=== Risk Contributions ===\")\n",
    "print(summary[\"risk_contributions\"], \"\\n\")\n",
    "\n",
    "print(\"Herfindahl Index:\", summary[\"herfindahl\"], \"\\n\")\n",
    "\n",
    "print(\"=== Per-Stock Factor Betas ===\")\n",
    "print(summary[\"df_stock_betas\"], \"\\n\")\n",
    "\n",
    "print(\"=== Portfolio-Level Factor Betas ===\")\n",
    "print(summary[\"portfolio_factor_betas\"], \"\\n\")\n",
    "\n",
    "print(\"=== Per-Asset Vol & Var ===\")\n",
    "print(summary[\"asset_vol_summary\"], \"\\n\")\n",
    "\n",
    "# â”€â”€ NEW: factor-level diagnostics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=== Factor Annual Volatilities (Ïƒ_i,f) ===\")\n",
    "print(summary[\"factor_vols\"].round(4))          # pretty table in Jupyter\n",
    "\n",
    "print(\"\\n=== Weighted Factor Variance   w_iÂ² Â· Î²_i,fÂ² Â· Ïƒ_i,fÂ² ===\")\n",
    "print(summary[\"weighted_factor_var\"].round(6), \"\\n\")\n",
    "\n",
    "print(\"=== Portfolio Variance Decomposition ===\")\n",
    "var_dec = summary[\"variance_decomposition\"]\n",
    "\n",
    "print(f\"Portfolio Variance:          {var_dec['portfolio_variance']:.4f}\")\n",
    "print(f\"Idiosyncratic Variance:      {var_dec['idiosyncratic_variance']:.4f}  ({var_dec['idiosyncratic_pct']:.0%})\")\n",
    "print(f\"Factor Variance:             {var_dec['factor_variance']:.4f}  ({var_dec['factor_pct']:.0%})\\n\")\n",
    "\n",
    "print(\"=== Factor Variance (absolute) ===\")\n",
    "for k, v in var_dec[\"factor_breakdown_var\"].items():\n",
    "    print(f\"{k.title():<10} : {v:.5f}\")\n",
    "\n",
    "# Optional: exclude 'industry' and 'subindustry' from factor breakdown\n",
    "filtered = {\n",
    "    k: v for k, v in var_dec[\"factor_breakdown_pct\"].items()\n",
    "    if k not in (\"industry\", \"subindustry\")\n",
    "    }\n",
    "\n",
    "#print(\"\\n=== Factor Variance (% of Portfolio) ===\")\n",
    "#for k, v in var_dec[\"factor_breakdown_pct\"].items():\n",
    "    #print(f\"{k.title():<10} : {v:.0%}\")\n",
    "\n",
    "print(\"\\n=== Factor Variance (% of Portfolio, excluding industry) ===\")\n",
    "for k, v in filtered.items():\n",
    "    print(f\"{k.title():<10} : {v:.0%}\")\n",
    "\n",
    "print(\"\\n=== Industry Variance (absolute) ===\")\n",
    "for k, v in summary[\"industry_variance\"][\"absolute\"].items():\n",
    "    print(f\"{k:<10} : {v:.6f}\")\n",
    "\n",
    "print(\"\\n=== Industry Variance (% of Portfolio) ===\")\n",
    "for k, v in summary[\"industry_variance\"][\"percent_of_portfolio\"].items():\n",
    "    print(f\"{k:<10} : {v:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15175e4-9ccb-45ad-b989-69b6c97f2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "# â”€â”€â”€ Load Portfolio Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with open(\"portfolio.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract inputs\n",
    "start_date            = config[\"start_date\"]\n",
    "end_date              = config[\"end_date\"]\n",
    "portfolio_input       = config[\"portfolio_input\"]\n",
    "expected_returns      = config[\"expected_returns\"]\n",
    "stock_factor_proxies  = config[\"stock_factor_proxies\"]\n",
    "\n",
    "# â”€â”€â”€ Standardize Portfolio Weights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "parsed  = standardize_portfolio_input(portfolio_input, latest_price)\n",
    "weights = parsed[\"weights\"]\n",
    "\n",
    "# â”€â”€â”€ Display Inputs and Exposures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=== Normalized Weights ===\")\n",
    "print(weights)\n",
    "\n",
    "print(\"\\n=== Dollar Exposure ===\")\n",
    "print(parsed[\"dollar_exposure\"])\n",
    "\n",
    "print(\"\\n=== Total Portfolio Value ===\")\n",
    "print(parsed[\"total_value\"])\n",
    "\n",
    "print(\"\\n=== Net Exposure (sum of weights) ===\")\n",
    "print(parsed[\"net_exposure\"])\n",
    "\n",
    "print(\"\\n=== Gross Exposure (sum of abs(weights)) ===\")\n",
    "print(parsed[\"gross_exposure\"])\n",
    "\n",
    "print(\"\\n=== Leverage (gross / net) ===\")\n",
    "print(parsed[\"leverage\"])\n",
    "\n",
    "# â”€â”€â”€ Display Expectations and Factor Proxies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n=== Expected Returns ===\")\n",
    "pprint(expected_returns)\n",
    "\n",
    "print(\"\\n=== Stock Factor Proxies ===\")\n",
    "for ticker, proxies in stock_factor_proxies.items():\n",
    "    print(f\"\\nâ†’ {ticker}\")\n",
    "    pprint(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163e608-ad6f-4d3e-891e-304bf00405f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_portfolio(filepath: str):\n",
    "    \"\"\"\n",
    "    Loads a YAML portfolio config file, standardizes weights,\n",
    "    builds risk profile, and prints key decomposition.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    weights = standardize_portfolio_input(config[\"portfolio_input\"], latest_price)[\"weights\"]\n",
    "\n",
    "    summary = build_portfolio_view(\n",
    "        weights,\n",
    "        config[\"start_date\"],\n",
    "        config[\"end_date\"],\n",
    "        config.get(\"expected_returns\"),\n",
    "        config.get(\"stock_factor_proxies\")\n",
    "    )\n",
    "\n",
    "    display_portfolio_summary(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb9739-f25d-4d13-92a5-0d2c1fcf3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluate Portfolio Risk Limits ===\n",
    "from pprint import pprint\n",
    "\n",
    "# Load limits from YAML\n",
    "vol_limit   = risk_config[\"portfolio_limits\"][\"max_volatility\"]\n",
    "loss_limit  = risk_config[\"portfolio_limits\"][\"max_loss\"]\n",
    "weight_limit = risk_config[\"concentration_limits\"][\"max_single_stock_weight\"]\n",
    "var_limits = risk_config[\"variance_limits\"]\n",
    "\n",
    "# Extract data from summary\n",
    "annual_vol = summary[\"volatility_annual\"]\n",
    "weights    = summary[\"allocations\"][\"Portfolio Weight\"]\n",
    "variance_decomp = summary[\"variance_decomposition\"]\n",
    "\n",
    "# 1. Volatility\n",
    "vol_pass = annual_vol <= vol_limit\n",
    "\n",
    "# 2. Loss Limit â€“ placeholder (depends on expected drawdown modeling)\n",
    "loss_pass = True  # not implemented yet\n",
    "\n",
    "# 3. Concentration\n",
    "max_weight = weights.abs().max()\n",
    "weight_pass = max_weight <= weight_limit\n",
    "\n",
    "# 4. Variance Contributions\n",
    "factor_var_pct = variance_decomp[\"factor_pct\"]\n",
    "market_var_pct = variance_decomp[\"factor_breakdown_pct\"].get(\"market\", 0.0)\n",
    "\n",
    "industry_pct_dict = summary[\"industry_variance\"][\"percent_of_portfolio\"]\n",
    "industry_pct_max  = max(industry_pct_dict.values()) if industry_pct_dict else 0.0\n",
    "\n",
    "factor_pass  = factor_var_pct  <= var_limits[\"max_factor_contribution\"]\n",
    "market_pass  = market_var_pct  <= var_limits[\"max_market_contribution\"]\n",
    "industry_pass = industry_pct_max <= var_limits[\"max_industry_contribution\"]\n",
    "\n",
    "# === Summary Output ===\n",
    "print(\"=== Portfolio Risk Limit Checks ===\")\n",
    "print(f\"Volatility:             {annual_vol:.2%}  â‰¤ {vol_limit:.2%}     â†’ {'PASS' if vol_pass else 'FAIL'}\")\n",
    "print(f\"Max Weight:             {max_weight:.2%}  â‰¤ {weight_limit:.2%}  â†’ {'PASS' if weight_pass else 'FAIL'}\")\n",
    "print(f\"Factor Var %:           {factor_var_pct:.2%}  â‰¤ {var_limits['max_factor_contribution']:.2%} â†’ {'PASS' if factor_pass else 'FAIL'}\")\n",
    "print(f\"Market Var %:           {market_var_pct:.2%}  â‰¤ {var_limits['max_market_contribution']:.2%} â†’ {'PASS' if market_pass else 'FAIL'}\")\n",
    "print(f\"Top Industry Var %:     {industry_pct_max:.2%}  â‰¤ {var_limits['max_industry_contribution']:.2%} â†’ {'PASS' if industry_pass else 'FAIL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d83de-390f-4618-8e2f-05c72fba1410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: risk_helpers.py\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def infer_max_betas_from_losses(\n",
    "    worst_factor_losses: Dict[str, Tuple[str, float]],\n",
    "    loss_limit_pct: float\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Infers max allowable beta per factor to stay within portfolio loss limit.\n",
    "\n",
    "    Args:\n",
    "        worst_factor_losses (Dict[str, Tuple[str, float]]): \n",
    "            {factor_type: (proxy, worst_loss)}, e.g. {'market': ('SPY', -0.13)}\n",
    "        loss_limit_pct (float): Target portfolio loss limit in decimal (e.g., 0.10 for -10%)\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: {factor_type: max_beta}\n",
    "    \"\"\"\n",
    "    max_betas = {}\n",
    "\n",
    "    for factor, (_, worst_return) in worst_factor_losses.items():\n",
    "        if worst_return == 0:\n",
    "            continue\n",
    "        max_beta = loss_limit_pct / abs(worst_return)\n",
    "        max_betas[factor] = round(max_beta, 3)\n",
    "\n",
    "    return max_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc60510-3d4a-4620-9d55-2b0d4161f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_risk.py\n",
    "\n",
    "# === TEST: Calculate Max Beta Limits ===\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "# â”€â”€â”€ 1. Load Portfolio + Risk Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with open(\"portfolio.yaml\", \"r\") as f:\n",
    "    portfolio_config = yaml.safe_load(f)\n",
    "\n",
    "with open(\"risk_limits.yaml\", \"r\") as f:\n",
    "    risk_config = yaml.safe_load(f)\n",
    "\n",
    "stock_factor_proxies = portfolio_config[\"stock_factor_proxies\"]\n",
    "LOSS_LIMIT = risk_config[\"max_single_factor_loss\"]  # e.g. -0.10\n",
    "\n",
    "# â”€â”€â”€ 2. Set 10-Year Window â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "end_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "start_date = (datetime.today() - pd.DateOffset(years=10)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# â”€â”€â”€ 3. Compute Worst Per-Proxy Losses â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=== Worst Monthly Losses per Proxy ===\")\n",
    "worst_losses = get_worst_monthly_factor_losses(stock_factor_proxies, start_date, end_date)\n",
    "for proxy, loss in sorted(worst_losses.items(), key=lambda x: x[1]):\n",
    "    print(f\"{proxy:<12} : {loss:.2%}\")\n",
    "\n",
    "# â”€â”€â”€ 4. Aggregate to Worst per Factor Type â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n=== Worst Monthly Losses per Factor Type ===\")\n",
    "worst_by_factor_type = aggregate_worst_losses_by_factor_type(stock_factor_proxies, worst_losses)\n",
    "for factor_type, (proxy, loss) in worst_by_factor_type.items():\n",
    "    print(f\"{factor_type:<10} â†’ {proxy:<12} : {loss:.2%}\")\n",
    "\n",
    "# â”€â”€â”€ 5. Compute Max Allowable Beta per Factor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\n=== Max Allowable Beta per Factor Type (Loss Limit = {LOSS_LIMIT:.0%}) ===\")\n",
    "for factor_type, (_, worst_return) in worst_by_factor_type.items():\n",
    "    if worst_return >= 0:\n",
    "        max_beta = float('inf')  # No loss â†’ unrestricted\n",
    "    else:\n",
    "        max_beta = LOSS_LIMIT / worst_return\n",
    "    print(f\"{factor_type:<10} â†’ Î² â‰¤ {max_beta:.2f}\")\n",
    "\n",
    "max_betas_dict = {\n",
    "    factor: float('inf') if worst_ret >= 0 else LOSS_LIMIT / worst_ret\n",
    "    for factor, (_, worst_ret) in worst_by_factor_type.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6180eed-2f61-4f77-9aa6-8419532fba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_portfolio(filepath: str):\n",
    "    \"\"\"\n",
    "    High-level â€œone-clickâ€ entry-point for a full portfolio risk run.\n",
    "\n",
    "    It ties together **all** of the moving pieces youâ€™ve built so far:\n",
    "\n",
    "        1.  Loads the portfolio YAML file (positions, dates, factor proxies).\n",
    "        2.  Loads the firm-wide risk-limits YAML.\n",
    "        3.  Standardises the raw position inputs into weights, then calls\n",
    "            `build_portfolio_view` to produce the master `summary` dictionary\n",
    "            (returns, vol, correlation, factor betas, variance decomposition, â€¦).\n",
    "        4.  Pretty-prints the standard risk summary via `display_portfolio_summary`.\n",
    "        5.  Derives *dynamic* max-beta limits:\n",
    "                â€¢ looks back over the analysis window,\n",
    "                â€¢ finds worst 1-month drawdowns for every unique factor proxy,\n",
    "                â€¢ converts those losses into a per-factor Î² ceiling\n",
    "                  using the global `max_single_factor_loss`.\n",
    "        6.  Runs two rule-checkers\n",
    "                â€¢ `evaluate_portfolio_risk_limits`   â†’   Vol, concentration, factor %\n",
    "                â€¢ `evaluate_portfolio_beta_limits`   â†’   Actual Î² vs. max Î²\n",
    "        7.  Prints both tables in a compact â€œPASS/FAILâ€ console report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        Path to the *portfolio* YAML ( **not** the risk-limits file ).\n",
    "        The function expects the YAML schema you have been using\n",
    "        (`start_date`, `end_date`, `portfolio_input`, `stock_factor_proxies`, â€¦).\n",
    "\n",
    "    Side-effects\n",
    "    ------------\n",
    "    â€¢ Prints a formatted risk report to stdout.\n",
    "    â€¢ Does **not** return anything; everything is handled inline.\n",
    "      (If you need the raw DataFrames, simply return `summary`, `df_risk`,\n",
    "      and `df_beta` at the end.)\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> run_portfolio(\"portfolio.yaml\")\n",
    "    === Target Allocations ===\n",
    "    â€¦                                 # summary table\n",
    "    === Portfolio Risk Limit Checks ===\n",
    "    Volatility:             21.65%  â‰¤ 40.00%     â†’ PASS\n",
    "    â€¦\n",
    "    === Beta Exposure Checks ===\n",
    "    market       Î² = 0.74  â‰¤ 0.80  â†’ PASS\n",
    "    â€¦\n",
    "    \"\"\"\n",
    "    import yaml\n",
    "    import pandas as pd\n",
    "    from run_portfolio_risk import (\n",
    "        standardize_portfolio_input,\n",
    "        latest_price,\n",
    "        display_portfolio_summary,\n",
    "        evaluate_portfolio_beta_limits,\n",
    "        evaluate_portfolio_risk_limits,\n",
    "    )\n",
    "    from portfolio_risk import build_portfolio_view\n",
    "    from risk_helpers import (\n",
    "        get_worst_monthly_factor_losses,\n",
    "        aggregate_worst_losses_by_factor_type\n",
    "    )\n",
    "\n",
    "    # â”€â”€â”€ 1. Load YAML Inputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    with open(filepath, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    with open(\"risk_limits.yaml\", \"r\") as f:\n",
    "        risk_config = yaml.safe_load(f)\n",
    "\n",
    "    weights = standardize_portfolio_input(config[\"portfolio_input\"], latest_price)[\"weights\"]\n",
    "    summary = build_portfolio_view(\n",
    "        weights,\n",
    "        config[\"start_date\"],\n",
    "        config[\"end_date\"],\n",
    "        config.get(\"expected_returns\"),\n",
    "        config.get(\"stock_factor_proxies\")\n",
    "    )\n",
    "\n",
    "    # â”€â”€â”€ 2. Display Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    display_portfolio_summary(summary)\n",
    "\n",
    "    # â”€â”€â”€ 3. Compute Beta Limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    start_date = config[\"start_date\"]\n",
    "    end_date   = config[\"end_date\"]\n",
    "    proxies    = config[\"stock_factor_proxies\"]\n",
    "    loss_limit = risk_config[\"max_single_factor_loss\"]\n",
    "\n",
    "    worst_losses = get_worst_monthly_factor_losses(proxies, start_date, end_date)\n",
    "    worst_by_type = aggregate_worst_losses_by_factor_type(proxies, worst_losses)\n",
    "\n",
    "    max_betas = {\n",
    "        factor: float('inf') if loss >= 0 else loss_limit / loss\n",
    "        for factor, (_, loss) in worst_by_type.items()\n",
    "    }\n",
    "\n",
    "    # â”€â”€â”€ 4. Evaluate Portfolio Risk Rules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n=== Portfolio Risk Limit Checks ===\")\n",
    "    df_risk = evaluate_portfolio_risk_limits(\n",
    "        summary,\n",
    "        risk_config[\"portfolio_limits\"],\n",
    "        risk_config[\"concentration_limits\"],\n",
    "        risk_config[\"variance_limits\"]\n",
    "    )\n",
    "    for _, row in df_risk.iterrows():\n",
    "        status = \"â†’ PASS\" if row[\"Pass\"] else \"â†’ FAIL\"\n",
    "        print(f\"{row['Metric']:<22} {row['Actual']:.2%}  â‰¤ {row['Limit']:.2%}  {status}\")\n",
    "\n",
    "    # â”€â”€â”€ 5. Evaluate Beta Limits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\n=== Beta Exposure Checks ===\")\n",
    "    df_beta = evaluate_portfolio_beta_limits(\n",
    "        summary[\"portfolio_factor_betas\"],\n",
    "        max_betas\n",
    "    )\n",
    "    \n",
    "    for factor, row in df_beta.iterrows():\n",
    "        status = \"â†’ PASS\" if row[\"Pass\"] else \"â†’ FAIL\"      # â† capital P\n",
    "        print(f\"{factor:<12} Î² = {row['Beta']:.2f}  â‰¤ {row['Max Beta']:.2f}  {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eed25b-acf5-4b3c-96f6-76e31e6dff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ risk_helpers.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "from __future__ import annotations\n",
    "from typing import Dict, Tuple, List\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def calc_max_factor_betas(\n",
    "    portfolio_yaml: str = \"portfolio.yaml\",\n",
    "    risk_yaml: str = \"risk_limits.yaml\",\n",
    "    lookback_years: int = 10,\n",
    "    echo: bool = True,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Derive max-allowable portfolio betas for each factor type from\n",
    "    historical worst 1-month factor proxy returns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    portfolio_yaml : str\n",
    "        Path to the YAML file containing `stock_factor_proxies`.\n",
    "    risk_yaml : str\n",
    "        Path to YAML containing `max_single_factor_loss`.\n",
    "    lookback_years : int\n",
    "        Historical window length to scan (ending today).\n",
    "    echo : bool\n",
    "        If True, pretty-prints the intermediate tables to stdout.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, float]\n",
    "        {factor_type: max_beta}.  Example:\n",
    "        {'market': 0.67, 'momentum': 0.79, ...}\n",
    "    \"\"\"\n",
    "    # 1. --- load configs -----------------------------------------------------\n",
    "    with open(portfolio_yaml, \"r\") as f:\n",
    "        port_cfg = yaml.safe_load(f)\n",
    "    with open(risk_yaml, \"r\") as f:\n",
    "        risk_cfg = yaml.safe_load(f)\n",
    "\n",
    "    proxies = port_cfg[\"stock_factor_proxies\"]\n",
    "    loss_limit = risk_cfg[\"max_single_factor_loss\"]  # e.g. -0.10\n",
    "\n",
    "    # 2. --- date window ------------------------------------------------------\n",
    "    end_dt = datetime.today()\n",
    "    start_dt = end_dt - pd.DateOffset(years=lookback_years)\n",
    "    end_str, start_str = end_dt.strftime(\"%Y-%m-%d\"), start_dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # 3. --- worst per-proxy --------------------------------------------------\n",
    "    worst_per_proxy = get_worst_monthly_factor_losses(\n",
    "        proxies, start_str, end_str\n",
    "    )\n",
    "\n",
    "    # 4. --- worst per factor-type -------------------------------------------\n",
    "    worst_by_factor = aggregate_worst_losses_by_factor_type(\n",
    "        proxies, worst_per_proxy\n",
    "    )\n",
    "\n",
    "    # 5. --- max beta calc ----------------------------------------------------\n",
    "    max_betas = {\n",
    "        ftype: float(\"inf\") if worst >= 0 else loss_limit / worst\n",
    "        for ftype, (_, worst) in worst_by_factor.items()\n",
    "    }\n",
    "\n",
    "    # --- pretty print block --------------------------------------------------\n",
    "    if echo:\n",
    "        print(\"=== Worst Monthly Losses per Proxy ===\")\n",
    "        for p, v in sorted(worst_per_proxy.items(), key=lambda kv: kv[1]):\n",
    "            print(f\"{p:<12} : {v:.2%}\")\n",
    "\n",
    "        print(\"\\n=== Worst Monthly Losses per Factor Type ===\")\n",
    "        for ftype, (p, v) in worst_by_factor.items():\n",
    "            print(f\"{ftype:<10} â†’ {p:<12} : {v:.2%}\")\n",
    "\n",
    "        print(f\"\\n=== Max Allowable Beta per Factor \"\n",
    "              f\"(Loss Limit = {loss_limit:.0%}) ===\")\n",
    "        for ftype, beta in max_betas.items():\n",
    "            print(f\"{ftype:<10} â†’ Î² â‰¤ {beta:.2f}\")\n",
    "\n",
    "    return max_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e906c-3865-4b63-b761-04475b03443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === What-If Risk Calculations with New Weights ===\n",
    "\n",
    "# assuming `weights`, `risk_config`, `config`, `stock_factor_proxies` in scope\n",
    "\n",
    "delta = {\"TW\": 0.05, \"PCTY\": -0.02}      # +5 ppts TW, âˆ’2 ppts PCTY\n",
    "summary_what, risk_what, beta_what = run_what_if(\n",
    "    weights, delta,\n",
    "    risk_config,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    stock_factor_proxies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4b35c-ea5c-498e-80e8-4355a4ed1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optimizer: Minimum Variance Weights ===\n",
    "\n",
    "new_w, risk_tbl, beta_tbl = run_min_var_optimiser(\n",
    "    weights,\n",
    "    risk_config,\n",
    "    config[\"start_date\"],\n",
    "    config[\"end_date\"],\n",
    "    stock_factor_proxies,\n",
    "    echo=True,          # turn off to suppress prints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149b810-21c7-4af6-af08-061be7b67533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === What-If Risk Calculations with New Weights & Before / After Risk ===\n",
    "\n",
    "# 1) What-if run --------------------------------------------------\n",
    "delta = {\"TW\": +0.05, \"PCTY\": -0.02}     # +5 ppts TW, âˆ’2 ppts PCTY\n",
    "\n",
    "summary_new, risk_new, beta_new = run_what_if(\n",
    "    weights,\n",
    "    delta,\n",
    "    risk_config,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    stock_factor_proxies\n",
    ")\n",
    "\n",
    "# --- 2) Baseline (unchanged portfolio) -------------------------------\n",
    "risk_base, beta_base = evaluate_weights(\n",
    "    weights, risk_config,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    stock_factor_proxies\n",
    ")\n",
    "\n",
    "# --- 3) Diff & pretty-print -----------------------------------------\n",
    "cmp_risk = (compare_risk_tables(risk_base, risk_new)\n",
    "              .set_index(\"Metric\")\n",
    "              .loc[risk_base[\"Metric\"].tolist()]        # keep original row order\n",
    "              .reset_index()\n",
    "           )\n",
    "\n",
    "cmp_beta = (compare_beta_tables(beta_base, beta_new)\n",
    "                .reindex(beta_base.index)  \n",
    "           )\n",
    "            \n",
    "print(\"\\nğŸ“  Risk Limits â€” Before vs After\\n\")\n",
    "print(cmp_risk.to_string(index=False,\n",
    "                         formatters={\"Old\": _fmt_pct, \"New\": _fmt_pct,\n",
    "                                     \"Î”\": _fmt_pct, \"Limit\": _fmt_pct}))\n",
    "\n",
    "print(\"\\nğŸ“Š  Factor Betas â€” Before vs After\\n\")\n",
    "print(\n",
    "    cmp_beta.to_string(\n",
    "        formatters={\n",
    "            \"Old\":       \"{:.2f}\".format,   # two-decimals, e.g. 0.5830\n",
    "            \"New\":       \"{:.2f}\".format,\n",
    "            \"Î”\":         \"{:.2f}\".format,\n",
    "            \"Max Beta\":  \"{:.2f}\".format,   # keep two-decimals on Max Beta if you like\n",
    "            \"Old Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "            \"New Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000eff1-771b-4141-b622-e35cc5d2968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def evaluate_portfolio_beta_limits(\n",
    "    portfolio_factor_betas: pd.Series,\n",
    "    max_betas: Dict[str, float]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compares each factor's actual portfolio beta to the allowable max beta.\n",
    "\n",
    "    Args:\n",
    "        portfolio_factor_betas (pd.Series): e.g. {\"market\": 0.74, \"momentum\": 1.1, ...}\n",
    "        max_betas (Dict[str, float]): e.g. {\"market\": 0.80, \"momentum\": 1.56, ...}\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Table with actual vs. max beta and pass/fail status.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for factor, max_b in max_betas.items():\n",
    "        actual = portfolio_factor_betas.get(factor, 0.0)\n",
    "        result = {\n",
    "            \"factor\": factor,\n",
    "            \"portfolio_beta\": actual,\n",
    "            \"max_allowed_beta\": max_b,\n",
    "            \"pass\": abs(actual) <= max_b,\n",
    "            \"buffer\": max_b - abs(actual)\n",
    "        }\n",
    "        data.append(result)\n",
    "\n",
    "    df = pd.DataFrame(data).set_index(\"factor\")\n",
    "    return df[[\"portfolio_beta\", \"max_allowed_beta\", \"pass\", \"buffer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4cbcd0-64c6-454e-8f58-89e0929bac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: risk_runner.py\n",
    "# Check portfolio beta limit checks \n",
    "\n",
    "df_beta_check = evaluate_portfolio_beta_limits(\n",
    "    summary[\"portfolio_factor_betas\"],\n",
    "    max_betas\n",
    ")\n",
    "print(\"=== Portfolio Exposure Limit Checks ===\\n\")\n",
    "print(df_beta_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f30c7-691f-4bb3-8df6-5ae45de96c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: risk_runner.py\n",
    "# Check portfolio beta limit checks\n",
    "\n",
    "df_beta_check = evaluate_portfolio_beta_limits(\n",
    "    portfolio_factor_betas = summary[\"portfolio_factor_betas\"],\n",
    "    max_betas              = max_betas,\n",
    "    proxy_betas            = summary[\"industry_variance\"].get(\"per_industry_group_beta\"),\n",
    "    max_proxy_betas        = max_betas_by_proxy\n",
    ")\n",
    "\n",
    "print(\"=== Portfolio Exposure Limit Checks ===\\n\")\n",
    "print(df_beta_check.to_string(formatters={\n",
    "    \"portfolio_beta\":   \"{:.2f}\".format,\n",
    "    \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "    \"buffer\":           \"{:.2f}\".format,\n",
    "    \"pass\":             lambda x: \"PASS\" if x else \"FAIL\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43d148-ee65-462b-a82a-6d8d841495fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€ 2b. Top Factor Variance Contributors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "wfv = summary[\"weighted_factor_var\"]\n",
    "total_var = summary[\"variance_decomposition\"][\"portfolio_variance\"]\n",
    "\n",
    "top_contrib = (\n",
    "    wfv.stack()\n",
    "       .sort_values(ascending=False)\n",
    "       .head(10)\n",
    "       .rename_axis(index=[\"Ticker\", \"Factor\"])\n",
    "       .reset_index(name=\"wÂ²Â·Î²Â²Â·ÏƒÂ²\")\n",
    ")\n",
    "\n",
    "top_contrib[\"% of Total Var\"] = top_contrib[\"wÂ²Â·Î²Â²Â·ÏƒÂ²\"] / total_var\n",
    "\n",
    "print(\"\\n=== Top 10 Factor Variance Contributors (stock Ã— factor) ===\")\n",
    "print(top_contrib.to_string(index=False, formatters={\n",
    "    \"wÂ²Â·Î²Â²Â·ÏƒÂ²\": \"{:.6f}\".format,\n",
    "    \"% of Total Var\": \"{:.1%}\".format\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7efed-0eba-4247-971d-722ae449cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: portfolio_optimizer.py\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Max-return subject to risk limits\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Union, List\n",
    "\n",
    "def solve_max_return_with_risk_limits(\n",
    "    init_weights: Dict[str, float],\n",
    "    risk_cfg: Dict[str, Dict[str, float]],\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    stock_factor_proxies: Dict[str, Dict[str, Union[str, List[str]]]],\n",
    "    expected_returns: Dict[str, float],\n",
    "    allow_short: bool = False\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Max-return portfolio subject to firm-wide limits.\n",
    "\n",
    "    Objective\n",
    "    ---------\n",
    "    Maximise Î£ w_iÂ·Î¼_i   (Î¼ = expected annual return in decimals)\n",
    "    subject to ALL risk limits defined in `risk_cfg`.\n",
    "\n",
    "    Risk Constraints\n",
    "    -----------\n",
    "    1. Î£ wáµ¢ = 1                               (fully invested)  \n",
    "    2. wáµ¢ â‰¥ 0  if ``allow_short`` is False    (long-only)  \n",
    "    3. wáµ¢ â‰¤ single-name cap                   (concentration limit)  \n",
    "    4. âˆš(12 Â· wáµ€Î£w) â‰¤ Ïƒ_cap                   (annual vol cap)  \n",
    "       â€“ Î£ is the monthly covariance from *start_date*â€“*end_date*.\n",
    "\n",
    "    This is a convex quadratic program solved with CVXPY + ECOS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    init_weights          : current {ticker: weight}.\n",
    "    risk_cfg              : parsed risk_limits.yaml (needs the three sub-dicts).\n",
    "    start_date / end_date : window used to build covariance & factor tables.\n",
    "    stock_factor_proxies  : same structure used elsewhere in your toolkit.\n",
    "    expected_returns      : {ticker: annual exp return}.  **Required**.\n",
    "    allow_short           : set True if negatives are allowed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict {ticker: new_weight}.  Sums to 1 by construction.\n",
    "    \"\"\"\n",
    "    # ---- 1. Build Î£ (monthly) with your existing helper ----------------\n",
    "    from portfolio_risk import build_portfolio_view   # re-use, keeps code DRY\n",
    "\n",
    "    tickers = list(init_weights.keys())\n",
    "    view = build_portfolio_view(\n",
    "        init_weights, start_date, end_date,\n",
    "        expected_returns=None,           # we only need cov matrix\n",
    "        stock_factor_proxies=stock_factor_proxies\n",
    "    )\n",
    "    Î£_m = view[\"covariance_matrix\"].loc[tickers, tickers].values\n",
    "    Î¼    = np.array([expected_returns.get(t, 0.0) for t in tickers])\n",
    "\n",
    "    if np.allclose(Î¼, 0):\n",
    "        raise ValueError(\"expected_returns is empty or zeros â€“ nothing to maximise\")\n",
    "\n",
    "    # ---- 2. CVXPY variables & objective --------------------------------\n",
    "    w = cp.Variable(len(tickers))\n",
    "    objective = cp.Maximize(Î¼ @ w)     # linear objective\n",
    "\n",
    "    # ---- 3. Constraints -------------------------------------------------\n",
    "    cons = []\n",
    "\n",
    "    # fully invested\n",
    "    cons += [cp.sum(w) == 1]\n",
    "\n",
    "    # long-only?\n",
    "    if not allow_short:\n",
    "        cons += [w >= 0]\n",
    "\n",
    "    # single-name cap\n",
    "    w_cap = risk_cfg[\"concentration_limits\"][\"max_single_stock_weight\"]\n",
    "    cons += [w <= w_cap]\n",
    "\n",
    "    # volatility cap  (monthly Î£ â†’ annual Ïƒ = âˆš12Â·sqrt(wáµ€Î£w))\n",
    "    Ïƒ_cap = risk_cfg[\"portfolio_limits\"][\"max_volatility\"]\n",
    "    cons += [cp.sqrt(cp.quad_form(w, Î£_m)) * np.sqrt(12) <= Ïƒ_cap]\n",
    "\n",
    "    # You can add more factor / industry caps here if you want them\n",
    "    # (reuse values already in risk_cfg).\n",
    "\n",
    "    # ---- 4. Solve -------------------------------------------------------\n",
    "    prob = cp.Problem(objective, cons)\n",
    "    prob.solve(solver=cp.ECOS, qcp=True, verbose=False)\n",
    "\n",
    "    if prob.status not in (\"optimal\", \"optimal_inaccurate\"):\n",
    "        raise ValueError(f\"Solver returned status {prob.status}\")\n",
    "\n",
    "    return {t: float(v) for t, v in zip(tickers, w.value)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00f2dc-e6c1-43fe-86d1-8247fa61a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optimizer: Highest Return Weights within Risk Limits ===\n",
    "\n",
    "# 1. run optimiser â†’ weights only\n",
    "w_opt = solve_max_return_with_risk_limits(\n",
    "    weights,                    # current allocation\n",
    "    risk_config,                # parsed risk_limits.yaml\n",
    "    config[\"start_date\"],\n",
    "    config[\"end_date\"],\n",
    "    stock_factor_proxies,\n",
    "    expected_returns=config[\"expected_returns\"]  # MUST be present\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¯  Target max-return, risk-constrained weights:\\n\")\n",
    "for k,v in sorted(w_opt.items(), key=lambda kv: -kv[1]):\n",
    "    if abs(v) > 1e-4:\n",
    "        print(f\"{k:<8} : {v:.2%}\")\n",
    "\n",
    "# 2. whenever you want: evaluate & pretty-print\n",
    "risk_tbl, beta_tbl = evaluate_weights(\n",
    "    w_opt, risk_config,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    stock_factor_proxies\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“  Max-return Portfolio â€“ Risk Checks\\n\")\n",
    "pct = lambda x: f\"{x:.2%}\"\n",
    "print(risk_tbl.to_string(index=False, formatters={\"Actual\": pct, \"Limit\": pct}))\n",
    "\n",
    "print(\"\\nğŸ“Š  Max-return Portfolio â€“ Factor Betas\\n\")\n",
    "beta_tbl = _drop_factors(beta_tbl)\n",
    "print(beta_tbl.to_string(formatters={\n",
    "    \"Beta\": \"{:.2f}\".format, \"Max Beta\": \"{:.2f}\".format,\n",
    "    \"Buffer\": \"{:.2f}\".format, \"Pass\": lambda x: \"PASS\" if x else \"FAIL\"\n",
    "}))\n",
    "\n",
    "# 3)  Aggregate-vs-Industry exposure checks\n",
    "from portfolio_risk          import build_portfolio_view\n",
    "from run_portfolio_risk      import evaluate_portfolio_beta_limits\n",
    "\n",
    "# rebuild a summary on the optimised weights so we can grab per-industry betas\n",
    "summary_opt = build_portfolio_view(\n",
    "    w_opt,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    expected_returns=None,\n",
    "    stock_factor_proxies=stock_factor_proxies\n",
    ")\n",
    "\n",
    "df_beta_chk = evaluate_portfolio_beta_limits(\n",
    "    portfolio_factor_betas = summary_opt[\"portfolio_factor_betas\"],\n",
    "    max_betas              = max_betas,                       # already computed earlier\n",
    "    proxy_betas            = summary_opt[\"industry_variance\"][\"per_industry_group_beta\"],\n",
    "    max_proxy_betas        = max_betas_by_proxy               # already computed earlier\n",
    ")\n",
    "\n",
    "df_factors = df_beta_chk[~df_beta_chk.index.str.startswith(\"industry_proxy::\")]\n",
    "df_proxies = (df_beta_chk\n",
    "              .loc[df_beta_chk.index.str.startswith(\"industry_proxy::\")]\n",
    "              .copy())\n",
    "df_proxies.index = df_proxies.index.str.replace(\"industry_proxy::\", \"\")\n",
    "\n",
    "fmt = {\n",
    "    \"portfolio_beta\":   \"{:+.2f}\".format,\n",
    "    \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "    \"buffer\":           \"{:+.2f}\".format,\n",
    "    \"pass\":             lambda x: \"PASS\" if x else \"FAIL\"\n",
    "}\n",
    "\n",
    "print(\"\\n=== Industry Exposure Checks ===\\n\")\n",
    "print(df_proxies.to_string(index_names=False, formatters=fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e36628-37ca-4354-a125-d7090b9a21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optimizer: Highest Return Weights within Risk Limits ===\n",
    "\n",
    "# 1. run optimiser â†’ weights only\n",
    "w_opt = solve_max_return_with_risk_limits(\n",
    "    weights,                    # current allocation\n",
    "    risk_config,                # parsed risk_limits.yaml\n",
    "    config[\"start_date\"],\n",
    "    config[\"end_date\"],\n",
    "    stock_factor_proxies,\n",
    "    expected_returns=config[\"expected_returns\"]  # MUST be present\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¯  Target max-return, risk-constrained weights:\\n\")\n",
    "for k,v in sorted(w_opt.items(), key=lambda kv: -kv[1]):\n",
    "    if abs(v) > 1e-4:\n",
    "        print(f\"{k:<8} : {v:.2%}\")\n",
    "\n",
    "\n",
    "# 2) main risk / factor tables (aggregate betas only)\n",
    "risk_tbl, beta_tbl = evaluate_weights(\n",
    "    w_opt, risk_config,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    stock_factor_proxies,\n",
    ")\n",
    "\n",
    "# 3) industry-proxy table\n",
    "summary_opt = build_portfolio_view(\n",
    "    w_opt, config[\"start_date\"], config[\"end_date\"],\n",
    "    expected_returns=None,\n",
    "    stock_factor_proxies=stock_factor_proxies\n",
    ")\n",
    "\n",
    "df_beta_chk = evaluate_portfolio_beta_limits(\n",
    "    portfolio_factor_betas = summary_opt[\"portfolio_factor_betas\"],\n",
    "    max_betas              = max_betas,   # already computed earlier\n",
    "    proxy_betas            = summary_opt[\"industry_variance\"][\"per_industry_group_beta\"],\n",
    "    max_proxy_betas        = max_betas_by_proxy,\n",
    ")\n",
    "\n",
    "# --- pretty-print ---------------------------------------------------------\n",
    "fmt = {\n",
    "    \"portfolio_beta\":   \"{:+.2f}\".format,\n",
    "    \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "    \"buffer\":           \"{:+.2f}\".format,\n",
    "    \"pass\":             lambda x: \"PASS\" if x else \"FAIL\",\n",
    "}\n",
    "\n",
    "df_factors  = df_beta_chk[~df_beta_chk.index.str.startswith(\"industry_proxy::\")]\n",
    "df_proxies  = df_beta_chk[ df_beta_chk.index.str.startswith(\"industry_proxy::\")].copy()\n",
    "df_proxies.index = df_proxies.index.str.replace(\"industry_proxy::\", \"\")\n",
    "\n",
    "print(\"\\nğŸ“  Max-return Portfolio â€“ Risk Checks\\n\")\n",
    "pct = lambda x: f\"{x:.2%}\"\n",
    "print(risk_tbl.to_string(index=False, formatters={\"Actual\": pct, \"Limit\": pct}))\n",
    "\n",
    "print(\"\\nğŸ“Š  Aggregate Factor Exposures\\n\")\n",
    "print(df_factors.to_string(index_names=False, formatters=fmt))\n",
    "\n",
    "print(\"\\nğŸ“Š  Industry Exposure Checks\\n\")\n",
    "print(df_proxies.to_string(index_names=False, formatters=fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839a05d-f59f-40a4-bf6b-f6651a7c9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === What-If Risk Calculations using Inputs for New Weights with Before / After Risk ===\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# WHAT-IF DRIVER\n",
    "#\n",
    "# Input precedence\n",
    "# ----------------\n",
    "# 1. If `what_if_portfolio.yaml` contains a top-level `new_weights:` section\n",
    "#    â†’ treat as a full-replacement portfolio.\n",
    "#      â€¢ `shift_dict` is ignored in this case.\n",
    "#\n",
    "# 2. Otherwise, build an incremental *delta* dict:\n",
    "#      â€¢ YAML `delta:` values are parsed first.\n",
    "#      â€¢ Any overlapping keys in `shift_dict` overwrite the YAML values.\n",
    "#\n",
    "# 3. Branch logic\n",
    "#      â€¢ full-replacement  â†’ evaluate_weights(new_weights_yaml)\n",
    "#      â€¢ incremental tweak â†’ run_what_if(base_weights, delta)\n",
    "#\n",
    "# 4. After computing the new portfolioâ€™s risk/beta tables once,\n",
    "#    we also compute the baseline (unchanged) tables once, then\n",
    "#    show before-vs-after diffs.\n",
    "#\n",
    "# Note: No function ever writes back to the YAML file; all merges happen\n",
    "#       in memory.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1) Parse input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "delta, new_weights_yaml = parse_delta(\n",
    "    yaml_path=\"what_if_portfolio.yaml\",      # or None\n",
    "    literal_shift=shift_dict       # None or {\"TW\": \"+500bp\", â€¦}\n",
    ")\n",
    "\n",
    "# 2) Build the *new* portfolio once â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if new_weights_yaml:                # full-replacement supplied in YAML\n",
    "    risk_new, beta_new = evaluate_weights(\n",
    "        new_weights_yaml, risk_config,\n",
    "        config[\"start_date\"], config[\"end_date\"],\n",
    "        stock_factor_proxies\n",
    "    )\n",
    "    _print_single_portfolio(risk_new, beta_new, title=\"New Portfolio What-if\")   \n",
    "    \n",
    "else:                              # incremental tweak path (delta shift)\n",
    "    summary_new, risk_new, beta_new = run_what_if(\n",
    "        base_weights=weights,\n",
    "        delta=delta,\n",
    "        risk_cfg=risk_config,\n",
    "        start_date=config[\"start_date\"],\n",
    "        end_date=config[\"end_date\"],\n",
    "        factor_proxies=stock_factor_proxies\n",
    "    )\n",
    "\n",
    "# 3) Baseline portfolio (unchanged) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "risk_base, beta_base = evaluate_weights(\n",
    "    weights, risk_config,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    stock_factor_proxies\n",
    ")\n",
    "\n",
    "# 4) Diff & pretty-print â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cmp_risk = (compare_risk_tables(risk_base, risk_new)\n",
    "              .set_index(\"Metric\")\n",
    "              .loc[risk_base[\"Metric\"].tolist()]        # keep original row order\n",
    "              .reset_index()\n",
    "           )\n",
    "\n",
    "cmp_beta = (compare_beta_tables(beta_base, beta_new)\n",
    "                .reindex(beta_base.index)  \n",
    "           )\n",
    "\n",
    "cmp_beta = _drop_factors(cmp_beta)\n",
    "\n",
    "print(\"\\nğŸ“  Risk Limits â€” Before vs After\\n\")\n",
    "print(cmp_risk.to_string(index=False,\n",
    "                         formatters={\"Old\": _fmt_pct, \"New\": _fmt_pct,\n",
    "                                     \"Î”\": _fmt_pct, \"Limit\": _fmt_pct}))\n",
    "\n",
    "print(\"\\nğŸ“Š  Factor Betas â€” Before vs After\\n\")\n",
    "print(\n",
    "    cmp_beta.to_string(\n",
    "        formatters={\n",
    "            \"Old\":       \"{:.2f}\".format,   # two-decimals, e.g. 0.5830\n",
    "            \"New\":       \"{:.2f}\".format,\n",
    "            \"Î”\":         \"{:.2f}\".format,\n",
    "            \"Max Beta\":  \"{:.2f}\".format,   # keep two-decimals on Max Beta if you like\n",
    "            \"Old Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "            \"New Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5546df-1367-4199-8748-0a473274865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add right after you build df_proxies_new\n",
    "\n",
    "# --- baseline proxy betas -----------------------------------------\n",
    "df_beta_chk_base = evaluate_portfolio_beta_limits(\n",
    "    portfolio_factor_betas = summary_base[\"portfolio_factor_betas\"],\n",
    "    max_betas              = max_betas,\n",
    "    proxy_betas            = summary_base[\"industry_variance\"][\"per_industry_group_beta\"],\n",
    "    max_proxy_betas        = max_betas_by_proxy,\n",
    ").loc[df_proxies_new.index]        # align rows to new\n",
    "\n",
    "cmp_proxy = pd.DataFrame({\n",
    "    \"Old\":    df_beta_chk_base[\"portfolio_beta\"],\n",
    "    \"New\":    df_proxies_new[\"portfolio_beta\"],\n",
    "    \"Î”\":      df_proxies_new[\"portfolio_beta\"] - df_beta_chk_base[\"portfolio_beta\"],\n",
    "    \"Max Beta\": df_proxies_new[\"max_allowed_beta\"],\n",
    "    \"Old Pass\": df_beta_chk_base[\"pass\"],\n",
    "    \"New Pass\": df_proxies_new[\"pass\"],\n",
    "})\n",
    "\n",
    "print(\"\\nğŸ“Š  Industry Betas â€” Before vs After\\n\")\n",
    "print(cmp_proxy.to_string(formatters=_fmt_beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eba06e-84dd-4ed1-9cf9-0994afc07e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === What-If Risk Calculations using Inputs for New Weights with Before / After Risk ===\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# WHAT-IF DRIVER\n",
    "#\n",
    "# Input precedence\n",
    "# ----------------\n",
    "# 1. If `what_if_portfolio.yaml` contains a top-level `new_weights:` section\n",
    "#    â†’ treat as a full-replacement portfolio.\n",
    "#      â€¢ `shift_dict` is ignored in this case.\n",
    "#\n",
    "# 2. Otherwise, build an incremental *delta* dict:\n",
    "#      â€¢ YAML `delta:` values are parsed first.\n",
    "#      â€¢ Any overlapping keys in `shift_dict` overwrite the YAML values.\n",
    "#\n",
    "# 3. Branch logic\n",
    "#      â€¢ full-replacement  â†’ evaluate_weights(new_weights_yaml)\n",
    "#      â€¢ incremental tweak â†’ run_what_if(base_weights, delta)\n",
    "#\n",
    "# 4. After computing the new portfolioâ€™s risk/beta tables once,\n",
    "#    we also compute the baseline (unchanged) tables once, then\n",
    "#    show before-vs-after diffs.\n",
    "#\n",
    "# Note: No function ever writes back to the YAML file; all merges happen\n",
    "#       in memory.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "from run_portfolio_risk import evaluate_portfolio_beta_limits, evaluate_portfolio_risk_limits\n",
    "from risk_helpers       import compute_max_betas\n",
    "from portfolio_risk     import build_portfolio_view\n",
    "\n",
    "# ------------------------------------------------------------------ 1) Parse\n",
    "delta, new_weights_yaml = parse_delta(\n",
    "    yaml_path=\"what_if_portfolio.yaml\",\n",
    "    literal_shift=shift_dict,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------ 2) NEW portfolio\n",
    "if new_weights_yaml:                 # full-replacement path\n",
    "    risk_new, beta_new = evaluate_weights(\n",
    "        new_weights_yaml, risk_config,\n",
    "        config[\"start_date\"], config[\"end_date\"],\n",
    "        stock_factor_proxies,\n",
    "    )\n",
    "    summary_new = build_portfolio_view(\n",
    "        new_weights_yaml,\n",
    "        config[\"start_date\"], config[\"end_date\"],\n",
    "        expected_returns=None,\n",
    "        stock_factor_proxies=stock_factor_proxies,\n",
    "    )\n",
    "    _print_single_portfolio(risk_new, beta_new, title=\"New Portfolio What-if\")\n",
    "\n",
    "else:                                # delta-shift path\n",
    "    summary_new, risk_new, beta_new = run_what_if(\n",
    "        base_weights   = weights,\n",
    "        delta          = delta,\n",
    "        risk_cfg       = risk_config,\n",
    "        start_date     = config[\"start_date\"],\n",
    "        end_date       = config[\"end_date\"],\n",
    "        factor_proxies = stock_factor_proxies,\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------- 2-b) Î² tables (factor + proxy) â€“ NEW only\n",
    "max_betas = compute_max_betas(             # <-- single return value\n",
    "    stock_factor_proxies,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    loss_limit_pct = risk_config[\"max_single_factor_loss\"],\n",
    ")\n",
    "\n",
    "# `max_betas_by_proxy` was already computed earlier via `calc_max_factor_betas`.\n",
    "# If that cell hasnâ€™t been executed yet, run it once before this block.\n",
    "\n",
    "df_beta_chk_new = evaluate_portfolio_beta_limits(\n",
    "    portfolio_factor_betas = summary_new[\"portfolio_factor_betas\"],\n",
    "    max_betas              = max_betas,\n",
    "    proxy_betas            = summary_new[\"industry_variance\"][\"per_industry_group_beta\"],\n",
    "    max_proxy_betas        = max_betas_by_proxy,\n",
    ")\n",
    "\n",
    "df_factors_new = df_beta_chk_new[~df_beta_chk_new.index.str.startswith(\"industry_proxy::\")]\n",
    "df_proxies_new = df_beta_chk_new[ df_beta_chk_new.index.str.startswith(\"industry_proxy::\")].copy()\n",
    "df_proxies_new.index = df_proxies_new.index.str.replace(\"industry_proxy::\", \"\")\n",
    "\n",
    "_fmt_beta = {\n",
    "    \"portfolio_beta\":   \"{:+.2f}\".format,\n",
    "    \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "    \"buffer\":           \"{:+.2f}\".format,\n",
    "    \"pass\":             lambda x: \"PASS\" if x else \"FAIL\",\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ“Š  Industry Exposure Checks\\n\")\n",
    "print(df_proxies_new.to_string(index_names=False, formatters=_fmt_beta))\n",
    "\n",
    "# ------------------------------------------------------------------ 3) BASELINE portfolio\n",
    "risk_base, beta_base = evaluate_weights(\n",
    "    weights, risk_config,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    stock_factor_proxies,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------ 4) DIFF & pretty-print\n",
    "cmp_risk = (\n",
    "    compare_risk_tables(risk_base, risk_new)\n",
    "    .set_index(\"Metric\")\n",
    "    .loc[risk_base[\"Metric\"].tolist()]       # keep original row order\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "cmp_beta = (\n",
    "    compare_beta_tables(beta_base, beta_new)\n",
    "    .reindex(beta_base.index)\n",
    ")\n",
    "cmp_beta = _drop_factors(cmp_beta)\n",
    "\n",
    "print(\"\\nğŸ“  Risk Limits â€” Before vs After\\n\")\n",
    "print(\n",
    "    cmp_risk.to_string(\n",
    "        index=False,\n",
    "        formatters={\n",
    "            \"Old\": _fmt_pct,\n",
    "            \"New\": _fmt_pct,\n",
    "            \"Î”\":   _fmt_pct,\n",
    "            \"Limit\": _fmt_pct,\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š  Factor Betas â€” Before vs After\\n\")\n",
    "print(\n",
    "    cmp_beta.to_string(\n",
    "        formatters={\n",
    "            \"Old\":       \"{:.2f}\".format,\n",
    "            \"New\":       \"{:.2f}\".format,\n",
    "            \"Î”\":         \"{:.2f}\".format,\n",
    "            \"Max Beta\":  \"{:.2f}\".format,\n",
    "            \"Old Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "            \"New Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf039567-d2aa-486b-aaa5-047da29bb70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === What-If Risk Calculations using Shift Inputs ===\n",
    "\n",
    "shift_dict = {\"TW\": \"+500bp\", \"PCTY\": \"-200bp\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1f7cc-a7a8-4ea8-b928-6fb4b0c8c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === What-If Risk Calculations (Before / After) ============================\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# WHAT-IF DRIVER\n",
    "#\n",
    "# Input precedence\n",
    "# ----------------\n",
    "# 1. If `what_if_portfolio.yaml` contains a top-level `new_weights:` section\n",
    "#    â†’ treat as a full-replacement portfolio.\n",
    "#      â€¢ `shift_dict` is ignored in this case.\n",
    "#\n",
    "# 2. Otherwise, build an incremental *delta* dict:\n",
    "#      â€¢ YAML `delta:` values are parsed first.\n",
    "#      â€¢ Any overlapping keys in `shift_dict` overwrite the YAML values.\n",
    "#\n",
    "# 3. Branch logic\n",
    "#      â€¢ full-replacement  â†’ evaluate_weights(new_weights_yaml)\n",
    "#      â€¢ incremental tweak â†’ run_what_if(base_weights, delta)\n",
    "#\n",
    "# 4. After computing the new portfolioâ€™s risk/beta tables once,\n",
    "#    we also compute the baseline (unchanged) tables once, then\n",
    "#    show before-vs-after diffs.\n",
    "#\n",
    "# Note: No function ever writes back to the YAML file; all merges happen\n",
    "#       in memory.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "from run_portfolio_risk import (\n",
    "    evaluate_portfolio_risk_limits,\n",
    "    evaluate_portfolio_beta_limits,\n",
    ")\n",
    "from risk_helpers   import compute_max_betas\n",
    "from portfolio_risk import build_portfolio_view\n",
    "\n",
    "_FMT_PCT  = lambda x: f\"{x:.1%}\"\n",
    "_FMT_BETA = {\n",
    "    \"portfolio_beta\":   \"{:.2f}\".format,\n",
    "    \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "    \"buffer\":           \"{:.2f}\".format,\n",
    "    \"pass\":             lambda x: \"PASS\" if x else \"FAIL\",\n",
    "}\n",
    "\n",
    "# â”€â”€ 0) make sure we have per-proxy Î² caps in memory ------------------------\n",
    "try:\n",
    "    max_betas_by_proxy                           # noqa: F821 if not yet defined\n",
    "except NameError:\n",
    "    # run once, silent\n",
    "    _, max_betas_by_proxy = calc_max_factor_betas(\n",
    "        portfolio_yaml = \"portfolio.yaml\",\n",
    "        risk_yaml      = \"risk_limits.yaml\",\n",
    "        lookback_years = 10,\n",
    "        echo           = False,      # â† no console spam\n",
    "    )\n",
    "\n",
    "# â”€â”€ 1) Parse scenario ------------------------------------------------------\n",
    "delta, new_weights_yaml = parse_delta(\n",
    "    yaml_path   = \"what_if_portfolio.yaml\",   # â†™ or None\n",
    "    literal_shift = shift_dict,               # â†™ or None\n",
    ")\n",
    "\n",
    "# â”€â”€ 2) Build NEW summary / tables -----------------------------------------\n",
    "if new_weights_yaml:     \n",
    "    # full-replacement branch\n",
    "    # --- guard: re-normalise just in case the YAML doesnâ€™t sum to 1.0 ----------\n",
    "    new_weights_yaml = normalize_weights(new_weights_yaml)\n",
    "    summary_new = build_portfolio_view(\n",
    "        new_weights_yaml,\n",
    "        config[\"start_date\"], config[\"end_date\"],\n",
    "        expected_returns=None,\n",
    "        stock_factor_proxies=stock_factor_proxies,\n",
    "    )\n",
    "else:\n",
    "    # incremental tweaks\n",
    "    summary_new, *_ = run_what_if(\n",
    "        base_weights   = weights,\n",
    "        delta          = delta,\n",
    "        risk_cfg       = risk_config,\n",
    "        start_date     = config[\"start_date\"],\n",
    "        end_date       = config[\"end_date\"],\n",
    "        factor_proxies = stock_factor_proxies,\n",
    "        verbose        = False,   \n",
    "    )\n",
    "\n",
    "# Risk table (NEW)\n",
    "risk_new = evaluate_portfolio_risk_limits(\n",
    "    summary_new,\n",
    "    risk_config[\"portfolio_limits\"],\n",
    "    risk_config[\"concentration_limits\"],\n",
    "    risk_config[\"variance_limits\"],\n",
    ")\n",
    "\n",
    "# Î² caps\n",
    "max_betas = compute_max_betas(\n",
    "    stock_factor_proxies,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    loss_limit_pct = risk_config[\"max_single_factor_loss\"],\n",
    ")\n",
    "# max_betas_by_proxy was produced earlier by calc_max_factor_betas\n",
    "beta_new = evaluate_portfolio_beta_limits(\n",
    "    summary_new[\"portfolio_factor_betas\"],\n",
    "    max_betas,\n",
    "    proxy_betas     = summary_new[\"industry_variance\"][\"per_industry_group_beta\"],\n",
    "    max_proxy_betas = max_betas_by_proxy,\n",
    ")\n",
    "\n",
    "# Split Î² table â†’ factors / proxies\n",
    "beta_f_new = beta_new[~beta_new.index.str.startswith(\"industry_proxy::\")]\n",
    "beta_p_new = beta_new[  beta_new.index.str.startswith(\"industry_proxy::\")].copy()\n",
    "beta_p_new.index = beta_p_new.index.str.replace(\"industry_proxy::\", \"\")\n",
    "\n",
    "# â”€â”€ 3) Baseline (unchanged) -----------------------------------------------\n",
    "summary_base = build_portfolio_view(\n",
    "    weights,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    expected_returns=None,\n",
    "    stock_factor_proxies=stock_factor_proxies,\n",
    ")\n",
    "risk_base = evaluate_portfolio_risk_limits(\n",
    "    summary_base,\n",
    "    risk_config[\"portfolio_limits\"],\n",
    "    risk_config[\"concentration_limits\"],\n",
    "    risk_config[\"variance_limits\"],\n",
    ")\n",
    "beta_base = evaluate_portfolio_beta_limits(\n",
    "    summary_base[\"portfolio_factor_betas\"],\n",
    "    max_betas,\n",
    "    proxy_betas     = summary_base[\"industry_variance\"][\"per_industry_group_beta\"],\n",
    "    max_proxy_betas = max_betas_by_proxy,\n",
    ")\n",
    "\n",
    "# â”€â”€ 4) Diffs ---------------------------------------------------------------\n",
    "cmp_risk  = compare_risk_tables(risk_base,  risk_new)\n",
    "cmp_beta  = compare_beta_tables(beta_base,  beta_new)\n",
    "cmp_beta  = _drop_factors(cmp_beta)         # suppress â€œindustryâ€ agg row\n",
    "cmp_beta  = cmp_beta[~cmp_beta.index.str.startswith(\"industry_proxy::\")] # suppress proxy rows\n",
    " \n",
    "# after you build cmp_risk - match table order\n",
    "order = risk_new[\"Metric\"].tolist()          # or risk_tbl if that is the one you printed\n",
    "cmp_risk = (\n",
    "    cmp_risk\n",
    "    .set_index(\"Metric\")                     # make 'Metric' the index\n",
    "    .loc[order]                              # re-order rows\n",
    "    .reset_index()                           # back to column form\n",
    ")\n",
    "\n",
    "# â”€â”€ 5) Pretty-print --------------------------------------------------------\n",
    "print(\"\\nğŸ“  NEW Portfolio â€“ Risk Checks\\n\")\n",
    "print(risk_new.to_string(index=False, formatters={\"Actual\": _FMT_PCT, \"Limit\": _FMT_PCT}))\n",
    "\n",
    "print(\"\\nğŸ“Š  NEW Aggregate Factor Exposures\\n\")\n",
    "print(beta_f_new.to_string(index_names=False, formatters=_FMT_BETA))\n",
    "\n",
    "print(\"\\nğŸ“Š  NEW Industry Exposure Checks\\n\")\n",
    "print(beta_p_new.to_string(index_names=False, formatters=_FMT_BETA))\n",
    "\n",
    "print(\"\\nğŸ“  Risk Limits â€” Before vs After\\n\")\n",
    "print(cmp_risk.to_string(index=False, formatters={\"Old\": _FMT_PCT, \"New\": _FMT_PCT,\n",
    "                                                  \"Î”\": _FMT_PCT,  \"Limit\": _FMT_PCT}))\n",
    "\n",
    "print(\"\\nğŸ“Š  Factor Betas â€” Before vs After\\n\")\n",
    "print(\n",
    "    cmp_beta.to_string(\n",
    "        index_names=False,          # â† hide the â€œfactorâ€ header\n",
    "        formatters={\n",
    "    \"Old\":       \"{:.2f}\".format,\n",
    "    \"New\":       \"{:.2f}\".format,\n",
    "    \"Î”\":         \"{:.2f}\".format,\n",
    "    \"Max Beta\":  \"{:.2f}\".format,\n",
    "    \"Old Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "    \"New Pass\":  lambda x: \"PASS\" if x else \"FAIL\",\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb10862-1928-471b-b418-ab76e4e33099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optimizer: Lowest Variance Weights within Risk Limits ===\n",
    "\n",
    "# 1. get the weights\n",
    "w_min = run_min_var_optimiser(\n",
    "    weights,\n",
    "    risk_config,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    stock_factor_proxies,\n",
    "    echo=True          # or False if you donâ€™t want the quick print-out\n",
    ")\n",
    "\n",
    "# 2. when you actually need the risk tables â†“\n",
    "risk_tbl, beta_tbl = evaluate_weights(\n",
    "    w_min, risk_config,\n",
    "    config[\"start_date\"], config[\"end_date\"],\n",
    "    stock_factor_proxies\n",
    ")\n",
    "\n",
    "# 3a. risk table\n",
    "print(\"\\nğŸ“  Optimised Portfolio â€“ Risk Checks\\n\")\n",
    "pct = lambda x: f\"{x:.2%}\"\n",
    "print(risk_tbl.to_string(index=False,\n",
    "                        formatters={\"Actual\": pct, \"Limit\": pct}))\n",
    "\n",
    "# 3b. beta table\n",
    "print(\"\\nğŸ“Š  Optimised Portfolio â€“ Factor Betas\\n\")\n",
    "beta_tbl = _drop_factors(beta_tbl)\n",
    "print(beta_tbl.to_string(formatters={\n",
    "    \"Beta\":      \"{:.2f}\".format,\n",
    "    \"Max Beta\":  \"{:.2f}\".format,\n",
    "    \"Buffer\":    \"{:.2f}\".format,\n",
    "    \"Pass\":      lambda x: \"PASS\" if x else \"FAIL\",\n",
    "}))\n",
    "# â€¦then display / log those tables however you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb0ebe-0435-4d56-afb8-f35ce4b52eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Optimizer: Highest Return Weights within Risk Limits ===\n",
    "\n",
    "# 1. run optimiser â†’ weights only\n",
    "w_opt = solve_max_return_with_risk_limits(\n",
    "    weights,                    # current allocation\n",
    "    risk_config,                # parsed risk_limits.yaml\n",
    "    config[\"start_date\"],\n",
    "    config[\"end_date\"],\n",
    "    stock_factor_proxies,\n",
    "    expected_returns=config[\"expected_returns\"]  # MUST be present\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ¯  Target max-return, risk-constrained weights:\\n\")\n",
    "for k,v in sorted(w_opt.items(), key=lambda kv: -kv[1]):\n",
    "    if abs(v) > 1e-4:\n",
    "        print(f\"{k:<8} : {v:.1%}\")\n",
    "\n",
    "# 2) main risk / factor tables\n",
    "\n",
    "# single summary build\n",
    "summary_opt = build_portfolio_view(\n",
    "    w_opt, config[\"start_date\"], config[\"end_date\"],\n",
    "    expected_returns=None,\n",
    "    stock_factor_proxies=stock_factor_proxies,\n",
    ")\n",
    "\n",
    "# risk table\n",
    "risk_tbl = evaluate_portfolio_risk_limits(\n",
    "    summary_opt,\n",
    "    risk_config[\"portfolio_limits\"],\n",
    "    risk_config[\"concentration_limits\"],\n",
    "    risk_config[\"variance_limits\"],\n",
    ")\n",
    "\n",
    "# beta tables (aggregate + proxy)\n",
    "beta_tbl_agg = evaluate_portfolio_beta_limits(\n",
    "    summary_opt[\"portfolio_factor_betas\"],\n",
    "    max_betas,           # factor caps\n",
    ")\n",
    "\n",
    "df_beta_chk = evaluate_portfolio_beta_limits(\n",
    "    summary_opt[\"portfolio_factor_betas\"],\n",
    "    max_betas,\n",
    "    proxy_betas     = summary_opt[\"industry_variance\"][\"per_industry_group_beta\"],\n",
    "    max_proxy_betas = max_betas_by_proxy,\n",
    ")\n",
    "\n",
    "# --- pretty-print ---------------------------------------------------------\n",
    "fmt = {\n",
    "    \"portfolio_beta\":   \"{:.2f}\".format,\n",
    "    \"max_allowed_beta\": \"{:.2f}\".format,\n",
    "    \"buffer\":           \"{:.2f}\".format,\n",
    "    \"pass\":             lambda x: \"PASS\" if x else \"FAIL\",\n",
    "}\n",
    "\n",
    "df_factors  = df_beta_chk[~df_beta_chk.index.str.startswith(\"industry_proxy::\")]\n",
    "df_proxies  = df_beta_chk[ df_beta_chk.index.str.startswith(\"industry_proxy::\")].copy()\n",
    "df_proxies.index = df_proxies.index.str.replace(\"industry_proxy::\", \"\")\n",
    "\n",
    "print(\"\\nğŸ“  Max-return Portfolio â€“ Risk Checks\\n\")\n",
    "pct = lambda x: f\"{x:.2%}\"\n",
    "print(risk_tbl.to_string(index=False, formatters={\"Actual\": pct, \"Limit\": pct}))\n",
    "\n",
    "print(\"\\nğŸ“Š  Aggregate Factor Exposures\\n\")\n",
    "print(df_factors.to_string(index_names=False, formatters=fmt))\n",
    "\n",
    "print(\"\\nğŸ“Š  Industry Exposure Checks\\n\")\n",
    "print(df_proxies.to_string(index_names=False, formatters=fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751a546-5f2f-411b-be52-fce121025dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: data_loader.py\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from typing import Optional, Union, List, Dict\n",
    "\n",
    "# Configuration\n",
    "API_KEY  = \"0ZDOD7zoxCPQLDOyDw5e1tE8bwEFfKWk\"\n",
    "BASE_URL = \"https://financialmodelingprep.com/stable\"\n",
    "\n",
    "\n",
    "def fetch_monthly_close(\n",
    "    ticker: str,\n",
    "    start_date: Optional[Union[str, datetime]] = None,\n",
    "    end_date:   Optional[Union[str, datetime]] = None\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Fetch month-end closing prices for a given ticker from FMP.\n",
    "\n",
    "    Uses the `/stable/historical-price-eod/full` endpoint with optional\n",
    "    `from` and `to` parameters, then resamples to month-end.\n",
    "\n",
    "    Args:\n",
    "        ticker (str):       Stock or ETF symbol.\n",
    "        start_date (str|datetime, optional): Earliest date (inclusive).\n",
    "        end_date   (str|datetime, optional): Latest date (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Month-end close prices indexed by date.\n",
    "    \"\"\"\n",
    "    params = {\"symbol\": ticker, \"apikey\": API_KEY, \"serietype\": \"line\"}\n",
    "    if start_date:\n",
    "        params[\"from\"] = pd.to_datetime(start_date).date().isoformat()\n",
    "    if end_date:\n",
    "        params[\"to\"]   = pd.to_datetime(end_date).date().isoformat()\n",
    "\n",
    "    resp = requests.get(f\"{BASE_URL}/historical-price-eod/full\", params=params, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    raw  = resp.json()\n",
    "    data = raw if isinstance(raw, list) else raw.get(\"historical\", [])\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "    monthly = df.sort_index().resample(\"ME\")[\"close\"].last()\n",
    "    return monthly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855cf893-7e3c-48b6-9dee-6deb0f020e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: run_portfolio_risk.py\n",
    "\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "from typing import Optional\n",
    "\n",
    "def load_and_display_portfolio_config(filepath: str = \"portfolio.yaml\") -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Loads the portfolio YAML file, parses weights, and prints input diagnostics.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the YAML portfolio config file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed config dictionary (useful for testing or further calls).\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    # Extract components\n",
    "    start_date            = config[\"start_date\"]\n",
    "    end_date              = config[\"end_date\"]\n",
    "    portfolio_input       = config[\"portfolio_input\"]\n",
    "    expected_returns      = config[\"expected_returns\"]\n",
    "    stock_factor_proxies  = config[\"stock_factor_proxies\"]\n",
    "\n",
    "    parsed  = standardize_portfolio_input(portfolio_input, latest_price)\n",
    "    weights = parsed[\"weights\"]\n",
    "\n",
    "    # â”€â”€â”€ Print outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"=== Normalized Weights ===\")\n",
    "    print(weights)\n",
    "\n",
    "    print(\"\\n=== Dollar Exposure ===\")\n",
    "    print(parsed[\"dollar_exposure\"])\n",
    "\n",
    "    print(\"\\n=== Total Portfolio Value ===\")\n",
    "    print(parsed[\"total_value\"])\n",
    "\n",
    "    print(\"\\n=== Net Exposure (sum of weights) ===\")\n",
    "    print(parsed[\"net_exposure\"])\n",
    "\n",
    "    print(\"\\n=== Gross Exposure (sum of abs(weights)) ===\")\n",
    "    print(parsed[\"gross_exposure\"])\n",
    "\n",
    "    print(\"\\n=== Leverage (gross / net) ===\")\n",
    "    print(parsed[\"leverage\"])\n",
    "\n",
    "    print(\"\\n=== Expected Returns ===\")\n",
    "    pprint(expected_returns)\n",
    "\n",
    "    print(\"\\n=== Stock Factor Proxies ===\")\n",
    "    for ticker, proxies in stock_factor_proxies.items():\n",
    "        print(f\"\\nâ†’ {ticker}\")\n",
    "        pprint(proxies)\n",
    "\n",
    "    return config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
